{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohanbing/1brc_rust/blob/main/cs480e_2024_3f_assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 3\n",
        "**Due December 13th, 11:59 PM**\n",
        "\n",
        "GitHub Classroom assignment link: https://classroom.github.com/a/p0lgkpDj.\n",
        "\n",
        "Instructions for how to connect your Google Colab to GitHub are [here](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb)."
      ],
      "metadata": {
        "id": "tUheapJCOaxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name: Aditya Mohan<br>\n",
        "B-Number: B00929373<br>\n",
        "Email: amohan2@binghamton.edu"
      ],
      "metadata": {
        "id": "26iemMN3qq0v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following assignment, you will be using the deep learning framework, PyTorch, to perform computer vision tasks such as image classification and object detection. This will be a report-style assignment, where you will try multiple different models, optimization algorithms, and hyperparameters, and present your findings in a short report with visualizations inside the notebook.  \n",
        "\n",
        "\n",
        "Functions and cells that need to be implemented are marked with a bold **implement** keyword or clearly marked in the experiments section.\n",
        "\n",
        "The experiments section for each classifier also need to be implemented. You should follow the instructions above the cell. You may also add additional cells.\n",
        "\n",
        "Cells marked **run** need to be run to set up the appropriate infrastructure, but do not need to be modified. Make sure you have run the previous cells before running the current cell, or you may get an error.\n",
        "\n",
        "It is standard practice in ML to share notebooks to discuss the workflow and results in a professional setting. So, the code quality also matters. You should make sure your code is readable and conforms to standard practices. Your figures should be intelligable and include proper axis labels, titles, and legends. Unreadable and poorly written code may result in a points deduction.  \n",
        "\n",
        "Submission will be via GitHub Classroom. **You are required to have at least 10 commits for this assignment.**"
      ],
      "metadata": {
        "id": "FANk9dekbYM0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uploading and Downloading Data from Colab\n",
        "\n",
        "Unlike the previous assignments, you will downloading and uploading additional data from and into the Colab environment.\n",
        "\n",
        "You can mount directories from your Google Drive and use the session storage for your work.\n",
        "\n",
        "[Take a look here for an example notebook on handling data download and upload on Colab. ](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=hauvGV4hV-Mh)"
      ],
      "metadata": {
        "id": "WAzKOfYiS5JK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import statements\n",
        "\n",
        "**Run** the cell to import the packages needed for the code below. You may other packages but ask first."
      ],
      "metadata": {
        "id": "u6edQRQycJJv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "cny_JSAkGykH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)  # Set the seed for the random number generator\n",
        "torch.set_default_dtype(torch.float64)"
      ],
      "metadata": {
        "id": "SBvLHg2PeHa6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUDA Runtime\n",
        "\n",
        "You will want to make use of the GPU runtimes on Colab to speed up your training. You can change your runtime by going to:\n",
        "\n",
        "`Runtime > Change runtime type` and selecting GPU.\n",
        "\n",
        "You will have to explicitly use the send Torch tensors to GPUs, by calling `.cuda()`  on the tensors and modules to utilize them on the GPU.\n",
        "\n",
        "[Take a look at the quickstart for PyTorch](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html)"
      ],
      "metadata": {
        "id": "tVBtO8uWVqua"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AHalgZKOVrMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Data Handling in PyTorch (20 pts)"
      ],
      "metadata": {
        "id": "31UCwNBSercl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset class\n",
        "\n",
        "A large part of any machine learning workflow is the proper and efficient handling of data. Datasets are often large, scattered across filesystems, and require transformations and augmentation. Deep learning libraries such as `PyTorch` provide utilities to help in this process. In the next section, you will write a custom MNIST dataset and add data augmentation to your data pipeline for your traininig."
      ],
      "metadata": {
        "id": "i_2o6fS-e8ze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to define some helper functions to load the MNIST data."
      ],
      "metadata": {
        "id": "M0gworgQibYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _data_parser_helper(csv_file_name):\n",
        "  '''\n",
        "  Reads CSV file and converts it into numpy arrays.\n",
        "\n",
        "  Args:\n",
        "    csv_file_name (string): String of the path of csv file.\n",
        "\n",
        "  Returns:\n",
        "    (np.array(float), np.array(int)): Returns a tuple of numpy arrays.\n",
        "  '''\n",
        "  X = []\n",
        "  Y = []\n",
        "  with open(csv_file_name,'r') as _file:\n",
        "      csv_reader = csv.reader(_file, delimiter=\",\")\n",
        "      for row in csv_reader:\n",
        "          Y.append(int(row[0]))\n",
        "          X.append([float(i)/255.0 for i in row[1:]])\n",
        "  return (np.array(X), np.array(Y))\n",
        "\n",
        "def get_mnist_train_data(path):\n",
        "  X_train, Y_train = _data_parser_helper(path)\n",
        "  return X_train, Y_train\n",
        "\n",
        "def get_mnist_test_data(path):\n",
        "  X_test, Y_test = _data_parser_helper(path)\n",
        "  return X_test, Y_test"
      ],
      "metadata": {
        "id": "12py4n6GiYOB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Implement*** the `MNIST` class to serve as a container for our PyTorch MNIST data. [Take a look at this tutorial on PyTorch datasets, dataloading, and transforms.](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class)\n",
        "[This second, more important tutorial specifically covers custom datasets and dataloaders.](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files)\n",
        "\n",
        "The MNIST data on Colab is pre-installed on all notebooks as a CSV.\n",
        "Your class must read the data and store it as PyTorch float tensors.\n",
        "Use the helper functions above (already written) to read the data,\n",
        "which will return the data as NumPy arrays.\n",
        "\n",
        "You should implement:\n",
        "\n",
        "- `__init__()` to read the appropriate CSV file, and store it in the class as a `torch.Tensor` with float dtype.\n",
        "- `__len__()` to return the number of samples in the dataset.\n",
        "- `__getitem__(i)` to return the i-th sample and label from the data you have stored."
      ],
      "metadata": {
        "id": "3-Gm0Tyeigj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MNIST(Dataset):\n",
        "  \"\"\"MNIST custom dataset that reads the CSV file and transforms them into PyTorch Tensors\"\"\"\n",
        "\n",
        "\n",
        "  def __init__(self, is_training=True, transform=None, path=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      is_training (bool): If true loads\n",
        "        the training dataset. If false, loads the test dataset.\n",
        "        Use the functions above.\n",
        "      transform (callable): Transform to be applied on a sample.\n",
        "        These will be used for data augmentations.\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "\n",
        "    if is_training:\n",
        "      if not path:\n",
        "        path = \"sample_data/mnist_train_small.csv\"\n",
        "\n",
        "      self._data, self._label = get_mnist_train_data(path)\n",
        "    else:\n",
        "      if not path:\n",
        "        path = \"sample_data/mnist_test.csv\"\n",
        "\n",
        "      self._data, self._label = get_mnist_test_data(path)\n",
        "\n",
        "    self._data = torch.from_numpy(self._data.reshape((-1, 1, 28, 28)))\n",
        "    self._label = torch.from_numpy(self._label)\n",
        "    self.transform = transform\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    \"\"\"Returns the size (the number of samples) of the dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    # raise NotImplementedError(\"The __len__() method was not implemented.\")\n",
        "    return self._data.shape[0]\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    \"\"\"Returns the i-th sample and label and applies any transforms defined.\n",
        "\n",
        "      Args:\n",
        "        i (int): The index of sample in the data array to retrieve.\n",
        "    \"\"\"\n",
        "\n",
        "    # return NotImplementedError(\"The __getitem__() method was not implemented\")\n",
        "\n",
        "    sample = self._data[i]\n",
        "    label = self._label[i]\n",
        "    if (self.transform):\n",
        "      semple = self.transform(sample)\n",
        "    return sample, label"
      ],
      "metadata": {
        "id": "FF0eE-oge8F1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "composed = transforms.Compose([transforms.RandomRotation(15)])\n",
        "mnist_dataset = MNIST(transform=composed)"
      ],
      "metadata": {
        "id": "wPQKDhWwyiz8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import perf_counter"
      ],
      "metadata": {
        "id": "yd-nczuCzfTu"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DataLoader(mnist_dataset, batch_size=512, num_workers=2)"
      ],
      "metadata": {
        "id": "xeCymG38zH3A"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = perf_counter()\n",
        "for _data, label in loader:\n",
        "  x = _data.shape[0]\n",
        "end = perf_counter()"
      ],
      "metadata": {
        "id": "p1JutL6nzRv_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHUCp0GgzqxX",
        "outputId": "fff99487-9e6c-4b59-befc-28e097050762"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.425673836999522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Implement*** the following cell to visualize the data in the dataset. Use `Matplotlib` or your favorite visualization package to plot 5 images of each class in a single figure.\n",
        "\n",
        "You should initialize a MNIST dataset object for the training class. Visualize this dataset. This will not be used in the future.  \n",
        "\n"
      ],
      "metadata": {
        "id": "fy6B1261lufJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5\n",
        "prev_label = {}\n",
        "mnist_obj = MNIST(True)\n",
        "fig, axs = plt.subplots(1, num_classes, figsize=(10, 8))\n",
        "for i, (sample, label) in enumerate(mnist_obj):\n",
        "  if not prev_label.get(label):\n",
        "    axs[i].imshow(sample[0], cmap='gray')\n",
        "    axs[i].set_title(f\"{label}\")\n",
        "\n",
        "    prev_label[label] = 1\n",
        "\n",
        "    if i>=num_classes-1:\n",
        "      break\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fGhUhWsLervV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "86a44a95-c1bc-4bf7-b0b8-98268415ee25"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Implement***\n",
        "the following cell to create a PyTorch transform object and\n",
        "assign it to a variable.\n",
        "You may name the variable whatever you wish;\n",
        "you will use the object to construct train and test MNIST datasets.\n",
        "\n",
        "You will use the transformations defined in `torchvision`,\n",
        "which can be found [here](https://pytorch.org/vision/stable/transforms.html#transforms-on-pil-image-and-torch-tensor).\n",
        "\n",
        "Add the `RandomRotation` and `Normalize` transformations to the dataset. You will need to [compose the two transforms](https://pytorch.org/vision/0.9/transforms.html#torchvision.transforms.Compose). Restrict the rotations to +/- 15 degrees.\n",
        "\n",
        "The mean and standard deviation of the training set is 0.13 and 0.31 respectively.\n",
        "\n",
        "At the end of the cell, construct a training and test dataset.\n",
        "Name these carefully, these datasets will be used in the next sections."
      ],
      "metadata": {
        "id": "Y14bBS2fmbEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform  = transforms.Compose([\n",
        "    transforms.RandomRotation(degrees = (15)),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "mnist_train = MNIST(is_training=True, transform=transform)\n",
        "mnist_test = MNIST(is_training=False, transform=transform)"
      ],
      "metadata": {
        "id": "jtKGgyI3mbPA"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Implement*** the following cell to visualize the data in the dataset with the transformations similar to the previous visualization."
      ],
      "metadata": {
        "id": "ANOuWwmSnPkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5\n",
        "prev_label = {}\n",
        "fig, axs = plt.subplots(1, num_classes, figsize=(10, 8))\n",
        "for i, (sample, label) in enumerate(mnist_train):\n",
        "  if not prev_label.get(label):\n",
        "    axs[i].imshow(sample[0], cmap='gray')\n",
        "    axs[i].set_title(f\"{label}\")\n",
        "\n",
        "    prev_label[label] = 1\n",
        "\n",
        "    if i>=num_classes-1:\n",
        "      break\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G9D3b2wpnUTV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "be69d04b-f822-45c7-c3c4-96c3e489b21f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 5 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzYAAADHCAYAAADLacZgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAnzUlEQVR4nO3daXgUVfr38TsBEoIkYU+IEMIl2yiLyGYABSSyiCwKoiIDKIpg0AGcPwqCjAoGEVRgWC9ZRgVBkEVREWUHCTuDDIqyCCgkLEoStgSSel7wEK0+B9KddHdVpb+f66oX9eN05w7cqc6hu84JMgzDEAAAAABwsGCrCwAAAACAgmJiAwAAAMDxmNgAAAAAcDwmNgAAAAAcj4kNAAAAAMdjYgMAAADA8ZjYAAAAAHA8JjYAAAAAHI+JDQAAAADHY2IDAAAAwPGY2NjUrl27pFOnTlKmTBkpUaKE1K5dWyZNmmR1WQgA69atk6CgIO2RnJxsdXko5Pr06XPD/gsKCpLffvvN6hJRyO3cuVPatWsnEREREh4eLm3atJE9e/ZYXRYCBK/BBVPU6gKgWrVqlXTs2FHq168vI0eOlJIlS8qhQ4fk119/tbo0BJAXXnhBGjVqZMqqVatmUTUIFM8++6wkJCSYMsMwpH///hIXFye33nqrRZUhEOzatUuaN28ulStXllGjRklOTo5MnTpVWrRoIdu2bZOaNWtaXSICBK/B+cPExmbS09OlV69e0qFDB1m8eLEEB/OmGqxxzz33SLdu3awuAwEmPj5e4uPjTdmmTZvk4sWL8sQTT1hUFQLFyJEjJSwsTLZs2SJly5YVEZGePXtKjRo1ZPjw4fLpp59aXCECBa/B+cNvzTYzf/58SU1NlTFjxkhwcLBcuHBBcnJyrC4LASojI0OuXr1qdRkIcPPnz5egoCDp0aOH1aWgkNu4caMkJCTkTmpERCpWrCgtWrSQFStWyPnz5y2sDoGG12DPMbGxmW+//VYiIiLkt99+k5o1a0rJkiUlIiJCBgwYIJcvX7a6PASQJ598UiIiIqR48eLSqlUr2bFjh9UlIQBduXJFPvnkE2natKnExcVZXQ4KuczMTAkLC1PyEiVKSFZWluzbt8+CqhCIeA3OHz6KZjM///yzXL16VTp37ix9+/aVpKQkWbdunUyePFnOnTsnH3/8sdUlopALCQmRrl27ygMPPCDlypWT/fv3y/jx4+Wee+6R7777TurXr291iQggX3/9tZw9e5aPocEvatasKcnJyZKdnS1FihQREZGsrCzZunWriAiLV8DneA0umCDDMAyri8CfbrvtNjl8+LD0799fpk2blpv3799fZsyYIT/99JNUr17dwgoRiA4ePCh169aVe++9V1auXGl1OQggPXr0kMWLF8vJkydNHw8CfGH69OkyYMAA6d27twwdOlRycnJk9OjRsmTJErly5Yp8+OGH0rNnT6vLRIDhNdh9fBTNZq6/Bf7444+b8uufLd+yZYvfawKqVasmnTt3lrVr10p2drbV5SBAnD9/XpYvXy5t27ZlUgO/6N+/vwwfPlzmz58vd9xxh9SpU0cOHTokQ4cOFRGRkiVLWlwhAhGvwe5jYmMzMTExIiISFRVlyitUqCAiIn/88YffawJERCpXrixZWVly4cIFq0tBgFi2bBmrocHvxowZI6mpqbJx40bZu3evbN++PXcRnxo1alhcHQIVr8HuYWJjMw0aNBAR9XO8J06cEBGR8uXL+70mQETk8OHDUrx4cf7HEn4zb948KVmypHTq1MnqUhBgSpcuLc2bN5c6deqIyLWFfSpVqiS1atWyuDIEKl6D3cPExma6d+8uIiKzZs0y5e+//74ULVpUWrZsaUFVCCSnT59Wsv/+97/y2WefSZs2bdhbCX5x+vRp+fbbb+Whhx6SEiVKWF0OAtjChQtl+/btMmjQIK5/8DlegwuGVdFspn79+vLUU0/J7Nmz5erVq9KiRQtZt26dLFq0SIYNG5b7UTXAVx599FEJCwuTpk2bSoUKFWT//v0yc+ZMKVGihIwdO9bq8hAgFi5cKFevXuVjaPCrDRs2yOuvvy5t2rSRsmXLSnJyssyZM0fatWsn//jHP6wuDwGA1+CCYVU0G7py5Yq8+eabMmfOHDlx4oRUqVJFEhMTZdCgQVaXhgAwadIkmTdvnhw8eFDS09OlfPny0rp1axk1apRUq1bN6vIQIOLj4+Xw4cNy4sSJ3GV3AV87dOiQPPfcc7Jr1y7JyMiQqlWrSu/evWXIkCESEhJidXkIALwGFwwTGwAAAACOxwf1AAAAADgeExsAAAAAjsfEBgAAAIDjMbEBAAAA4HhMbAAAAAA4ns8mNlOmTJG4uDgpXry4NGnSRLZt2+arLwUo6D9Yif6D1ehBWIn+g1V8stzzwoULpVevXjJ9+nRp0qSJvPfee7Jo0SI5cOCAVKhQ4aaPzcnJkRMnTkh4eLgEBQV5uzQ4lGEYkpGRITExMXnuuluQ/hOhB6Gi/2A1f/Ug/QcdroGwkif9J4YPNG7c2EhMTMw9z87ONmJiYoykpKQ8H3v8+HFDRDg4tMfx48d92n/0IMfNDvqPw+rD1z1I/3Hc7OAayGHl4U7/ef2jaFlZWbJz505JSEjIzYKDgyUhIUG2bNmijM/MzJT09PTcw2C/UNxEeHj4Tf/c0/4ToQfhPvoPVvN2D9J/8ATXQFgpr/4T8cE9NmfOnJHs7GyJiooy5VFRUZKSkqKMT0pKksjIyNwjNjbW2yWhEMnrbWlP+0+EHoT76D9Yzds9SP/BE1wDYSV3Pppo+apow4YNk7S0tNzj+PHjVpeEAEMPwkr0H6xE/8Fq9CC8qai3n7BcuXJSpEgRSU1NNeWpqakSHR2tjA8NDZXQ0FBvl4EA5Wn/idCD8B76D1bjNRhW4hoIq3n9HZuQkBBp0KCBrF69OjfLycmR1atXS3x8vLe/HGBC/8FK9B+sRg/CSvQfLOfWEhUeWrBggREaGmrMnTvX2L9/v9GvXz+jVKlSRkpKSp6PTUtLs3zVBQ77HmlpaT7tP3qQ42YH/cdh9eHrHqT/OG52cA3ksPJwp/98MrExDMOYPHmyERsba4SEhBiNGzc2kpOT3XocDc1xs8Odpi5I/9GDHDc76D8Oqw9f9yD9x3Gzg2sgh5WHO/3nkw06CyI9PV0iIyOtLgM2lZaWJhERET79GvQgboT+g9V83YP0H26GayCs5E7/Wb4qGgAAAAAUFBMbAAAAAI7HxAYAAACA4zGxAQAAAOB4TGwAAAAAOB4TGwAAAACOx8QGAAAAgOMxsQEAAADgeExsAAAAADheUasLKIyio6OV7I477sjzcbt371ay33//3Ss1AQAAIDCUK1dOyVatWqVkRYuqU4G6dev6pCZ/4B0bAAAAAI7HxAYAAACA4zGxAQAAAOB4TGwAAAAAOB6LB/hAYmKikg0bNizPx91///1KtnbtWq/UBFSqVMl0XqVKFWXMpUuXlGzXrl1KFhUVpWSpqal51hAXF6dk/fr1U7I6deqYzjt06KCM2bNnj5I1bdpUyS5fvpxnXQAAOEW9evWUbPTo0aZz3e+Uutf4cePGea8wG+AdGwAAAACOx8QGAAAAgOMxsQEAAADgeExsAAAAADgeiwcU0Jw5c5TsiSeeULIzZ86Yzhs3bqyMCQ5mnomb0+0Q3LNnTyV7+eWXlax06dKm8/LlyytjsrKylOzIkSNKVqpUKSU7d+6ckrnSfc0yZcoo2dWrV03nX331lTJGt+gACwXgOt1CFa1atVKyhx9+WMlcF6s4evSoMmbAgAFKtnLlSg8qBFAYdOrUScmGDBmiZK6L4ujorjW6hX5KliypZMWKFTOdp6WlKWPGjx+vZElJSXnW5ST8Jg0AAADA8ZjYAAAAAHA8JjYAAAAAHI97bDwQGRmpZC1atFAy3b0yrhsnHTt2zHuFIWD0799fySZNmuTWYzMzM03ny5cvz3cdQUFBSmYYRp6Pu3jxopJt3LhRySZMmGA637RpkwfVoTAJDw9XsoYNGyqZ631ld911lzJGdz+XO70cGxurjBk1apSScY+N/1WsWFHJHnvsMSVLSEgwndeoUUMZU61aNSXTXXu++eYbJbty5YrpfNasWcqYU6dOKRmc5c4771SyadOmKZmuL12dPXvWrefXWbZsmZK5vpYuXLhQGXPixAm3nt/JeMcGAAAAgOMxsQEAAADgeExsAAAAADgeExsAAAAAjsfiAR5wXQBARH9Tqe7GwhkzZvikpoIqV66ckt1///15Pk63GaNuE0V4l+5Ge51Lly4pWZ8+fUznixYt8kZJHilevLiSsalm4aO7Cbts2bKm861btypjmjdvrmQfffSRklWuXDlfdel+ft555x0l+/e//206v/XWW5UxERER+aoB+de+fXslGzdunJKFhoYqma4nXekW9alQoYKS9ejRQ8lce1K3geIrr7ySZw2wt8TERCXTLRQwZswYJZs7d67p/Pz588oYXd/oHDp0yK1xgYh3bAAAAAA4HhMbAAAAAI7HxAYAAACA4zGxAQAAAOB4LB5wA7rdX59++mm3HpuSkqJkrrsSW6Fz585KptsduVSpUnk+V3Z2tpLt3LlTyR544AEl0y08APcMGDDArXG6HYetWCzAFQsFFD666+KoUaOUzHWhkgULFihjHn/8cSULCQlRsjNnziiZ6/XnrbfeUsZs3rxZyXTX5r59+5rOdYsH7NixQ8mQf3Xr1jWdN23aVBnTtWtXJbv99tuV7Mcff1SyN954w3SuW+zmhx9+ULK0tDS1WI3u3bubznW70X///fdKpvs5gD2EhYUpWceOHZXs1KlTSua6AImISGpqap5f050xuDnesQEAAADgeExsAAAAADgeExsAAAAAjufxxGbDhg3SsWNHiYmJkaCgIFm2bJnpzw3DkFdffVUqVqwoYWFhkpCQID///LO36kWA27x5M/0Hy9B/sBo9CCvRf7A7jxcPuHDhgtSrV0+eeuopefjhh5U/HzdunEyaNEn+85//SNWqVWXkyJHStm1b2b9/v3bXcbuoVauW6XzixInKmGLFiinZ9u3bleyll17yXmFuct2tVrfD8eDBg5WsaNH8rR9RpEgRJWvcuLGSdevWTcnef//9fH1NEZGLFy8Wyv7Tcd2pXUTkscceU7KgoCAlGzt2bJ7P79rzIiIlSpRQsl27duX5XIEikPpP58EHH1SymTNnKplhGHk+V69evdz6mhs3blSy559/Xsn27t3r1vO5o3r16nmO2bdvn9e+nicKQw8+9NBDSubaR7rrn47utVr3WudrK1asMJ3rFgXQ7VDvNIWh/9w1fPhwJatQoYKSvfPOO0qmWwTA9fe0Bg0aKGPOnz+vZLoFqX777TclwzUe/1bbvn17ad++vfbPDMOQ9957T0aMGJG7AtcHH3wgUVFRsmzZMu0vZYAn7r//fu3KOCL0H3yP/oPV6EFYif6D3Xn1HpsjR45ISkqKJCQk5GaRkZHSpEkT2bJli/YxmZmZkp6ebjqA/MhP/4nQg/AO+g9W4zUYVuIaCDvw6sTm+ttlUVFRpjwqKkr7VpqISFJSkkRGRuYelStX9mZJCCD56T8RehDeQf/BarwGw0pcA2EHlq+KNmzYMElLS8s9jh8/bnVJCDD0IKxE/8FK9B+sRg/Cm/J35/gNREdHi8i1m6b+epNcamqq3HnnndrHhIaGSmhoqDfLyJfmzZubzps1a+bW43Q3Lup2ofWmW265RcnmzJljOtfdnKnzxx9/KNmmTZtM57qFAh544AG3nn/EiBFKVpDFA24mP/0nYp8edPXXt/Ovi4iIUDLdjdrjx49XMtcbonW7qet2eT9y5IiS6XZ1//zzz03nZ8+eVcYUZoWt/3Tq1KmjZLrFK9yh25n7k08+UTLX65G36X6mXBfR0H2PukUNrOaU12Dd66Y7iwW0a9dOydasWeOVmgrq0qVLpvOGDRsqY+666y4l092MHh8fbzqPi4tTxuj+Dq1W2K6BZcqUcWuc7qNzrr9TiogMGjTIdK5bfMFdusUpFi1aZDpfvXq1MiYQPubn1XdsqlatKtHR0aa/zPT0dNm6davygwp4G/0HK9F/sBo9CCvRf7ADj9+xOX/+vBw8eDD3/MiRI7Jnzx4pU6aMxMbGyqBBg2T06NFSvXr13KX+YmJipEuXLt6sGwHq/Pnzcvjw4dxz+g/+RP/BavQgrET/we48ntjs2LFDWrVqlXs+ZMgQERHp3bu3zJ07V4YOHSoXLlyQfv36yblz56R58+aycuVKx61fDnvavXu3aS8N+g/+RP/BavQgrET/we6CDHd2UvOj9PR0iYyM9OnX0D3/hg0bTOd33HGHMkZ3z8Btt92mZLoNlvJL97nU1157Tck6dOiQ53P9/e9/V7L169cr2YkTJ0znwcHqJxY/+ugjJevevXueNYjkf1NQEZG0tDTtZ+K9yR896A7XHZ1FRDp16pTv53Pd/Xn//v3KGNcNxEREWrdu7dbzZ2Vlmc51/eb6GWCnCaT+u74PxV/pfu519/xduHBByYYOHWo6123smZ2d7UmJXrFq1Solc+153c7puvslLl686L3CbsDXPeiP/jt27JiSVapUKc/H6fbQ091HoNt8uH79+qbzq1ev5vn1RPT9obtPwfV+jJUrVypjypUr59bXdL3/UffzpHu9/eqrr9x6/oIIpGvglClTlGzAgAFKplvx7fr9Rn/l2nO61+A9e/Yo2SOPPKJkuvthXe+H1t1DrbvuTpgwQcnOnDmjZHbgTv9ZvioaAAAAABQUExsAAAAAjsfEBgAAAIDjMbEBAAAA4Hhe3aDTKXSbV9auXTvPx+k2U/LmQgG6m3B1CwXobiDPyckxnffu3VsZ8/HHH+erLtfnFtHfzKjbxO6NN97I19fEtZvkXGVmZiqZbgPNp556Ssm+//5707nu31C3GWupUqWUbPbs2UrWtm1b0/mHH36ojNH9nI0dO1bJXDe7g/89+uijSua6ceWN6DbfnDZtWoFr8gXdRriua+pMnjxZGeOPhQIKq6NHjyqZO4sH6G6O122UWrNmTSXTbYSZX8nJyUp29913e+35Xel+N2jatKmS+WPxAKh0CwVkZGQoWWJioulctxiLTp8+fZRMtwGs6++2L774ojLmpZdeUrIePXooWceOHU3ne/fuzatM2+AdGwAAAACOx8QGAAAAgOMxsQEAAADgeExsAAAAADheQC4eUK9ePSVzvVlUZ/fu3V6rQbfD+5w5c5SsQ4cOSnbgwAElmzp1qul8+fLlBajOTHdDue5mudOnTyvZ9OnTvVZHoBk8eLCSvfvuu0qm26k4v3Q7v589e1bJdLvSu948u2DBAmXMyJEjlez2229XMt1Oy/CtV1991XTu7r+BbqGAESNGeKUmb9PtGq7jurDG119/7YtyAlaXLl2UbNasWabzZs2aKWPKli2rZPfcc4/X6nKXLxcKcJddd4Yv7HSLJKWnpyuZ7ne3TZs2ea2OHTt25JlNnDhRGaNb0OmZZ55RMtdan332WWVMfhek8jXesQEAAADgeExsAAAAADgeExsAAAAAjsfEBgAAAIDjBeTiAe5YsmSJkl2+fNlrz//KK68omeuusSIi//vf/5TsvvvuUzLdDd7eEhYWpmTt27dXsqSkJCVLSUnxSU2B4Pfff3crswvX3bjj4uKUMbp+7tatm5INGzbMdK7rLeRf8eLFlcx1QYjgYPX/vX766SclGzNmjJLpFqHwtypVqijZm2++6dZjXfvt4MGDXqkJ1+her1wXFKhYsaIy5umnn1aykJAQJdP927do0cJ0fvHiRWXM4sWLlaxNmzZKtmrVKiWrUaOG6bxWrVrKmDp16iiZO3Q/d/PmzcvXc8F9umvbqVOnlEy3WJM3F/XJL12tut89dVwXFBg3bpwyhsUDAAAAAMBHmNgAAAAAcDwmNgAAAAAcj4kNAAAAAMcLMgzDsLqIv0pPT5fIyEiffo3MzEwlK1KkiOlcd5Pi3Llz8/01y5cvbzo/fvy4MiYnJ0fJateurWSHDx/Odx2uihUrpmRNmjQxnesWUtBliYmJSubtm4jT0tIkIiLCq8/pyh89GKh69uypZB988IGSbd682XRuxe7iOoWl/z777DMle/DBB03nFy5cUMb06dNHyT799FOv1VUQrrvSf/nll8qYRo0aKZlrr4mofxdpaWkFrM57fN2DXP+8Y+HChUr2yCOPuPXYX375xXTesmVLZcyxY8fyU1aBFZZrIP7keu0UURc/0C3m0bx5cyVzXUTI29zpP96xAQAAAOB4TGwAAAAAOB4TGwAAAACOF5AbdBYtqn7brrca7dixw6tfc8SIEXnWMHDgQCXL7/00devWVbLWrVsrWdu2bZUsISHBdD5jxgxlzIQJE5TMDpvywd68/XOFvFWqVEnJGjdurGSu18C33npLGWOX+2l0m4e+8MILpvOGDRsqY3S3lLreTyNir3tq4AyuG4Xqfsbc9fnnn5vOrbqfBoFBt2HuuXPnTOe33nqrMkb3e6wd8I4NAAAAAMdjYgMAAADA8ZjYAAAAAHA8JjYAAAAAHM+ed/7YQPXq1ZVs3759bj22SpUqStarV688H3fgwAElq1mzppLdddddSuZ6A2ynTp2UMWFhYUqmu2ns9ddfN50nJSUpY65cuaJkQF4GDBhgdQkB5+LFi0p2/vx5Jfvuu+9M5xMnTvRZTQXVvXt3JXNdoEVn1qxZSsZCAfAG18V5dL8H6MycOVPJXn75Za/UBAQi3rEBAAAA4HhMbAAAAAA4HhMbAAAAAI7HxAYAAACA4wXk4gFXr15VsiJFipjOP/jgA2XM22+/rWTHjx9Xsrp16ypZeHh4nnUtXrw4z7pu9FyuO2pfunRJGfPZZ58pWd++fZXsjz/+uGmd8A/dzae6m58HDRqkZO4udOFLut7q37+/W4/98ssvvV1OwPr999+VrEGDBkpm15voS5QooWSPPvpono87deqUkr322mteqQmBLThY/T/hUaNG5fm4nJwcJVu4cKGS6V6/AV+58847ley2224znWdkZChjfv31V1+VVCC8YwMAAADA8ZjYAAAAAHA8JjYAAAAAHM+jiU1SUpI0atRIwsPDpUKFCtKlSxdlU8nLly9LYmKilC1bVkqWLCldu3aV1NRUrxaNwNWyZUv6D5aZMGEC10BYimsgrMQ1EHYXZLjedX4T7dq1k8cee0waNWokV69eleHDh8u+fftk//79csstt4jItZ3Fv/jiC5k7d65ERkbKwIEDJTg4WDZv3uzW10hPT5fIyMj8fTdueumll5TMdadfd272t8rJkyeVbM+ePabzXr16KWMKw6IAU6dOlXvvvddn/Sfinx50h26xiueee07JmjRpomRWLB4wfvx40/mQIUPcelxSUpKSvfLKK16pydtat24tPXv2dPw10EnefPNNJdNdw11NmDBByYYOHeqVmqzk62sg/Ze3Z555RslmzJiR5+MmTpyoZIMHD/ZKTf4S6NfAuLg4JdMtHLFt2zYlmzZtmi9K8sjtt9+uZEuXLlWy6tWrm86/+OILZUzHjh29V5ib0tLSJCIi4qZjPFoVbeXKlabzuXPnSoUKFWTnzp1y7733SlpamsyaNUvmz58v9913n4iIzJkzR/72t79JcnKy3H333cpzZmZmSmZmZu55enq6JyUhwDzxxBO5Te2N/hOhB+G+JUuWmC6qXAPhb96+BtJ/8ATXQNhdge6xub48aJkyZUREZOfOnXLlyhVJSEjIHVOrVi2JjY2VLVu2aJ8jKSlJIiMjc4/KlSsXpCQEEG/0nwg9iPzjGggr0X+wGj0Iu8n3xCYnJ0cGDRokzZo1k9q1a4uISEpKioSEhEipUqVMY6OioiQlJUX7PMOGDZO0tLTcQ7cvDODKW/0nQg8if7gGwkr0H6xGD8KO8r1BZ2Jiouzbt082bdpUoAJCQ0MlNDS0QM/hqbfeekvJvvrqK9N52bJl/VWOxw4ePKhkgXYh8Fb/iVjTgzqlS5c2nT/77LPKmBUrViiZN++nKVpUvSQ0btxYyWbPnq1kus8eu9JtRjd69Gj3irMZJ18D7apr165KNmzYMCXT3Ro6c+ZM03lhuJ/mZug/65w+fTpfj3O9F9bpCnsPxsTEKNmqVauUrFq1akq2YMECn9R0M9ffNbtO9zuE7n6gkJAQJXNdEKJHjx4FrM5/8vWOzcCBA2XFihWydu1aqVSpUm4eHR0tWVlZcu7cOdP41NRUiY6OLlChwHX0H6xGD8JK9B+sRg/Crjya2BiGIQMHDpSlS5fKmjVrpGrVqqY/b9CggRQrVkxWr16dmx04cECOHTsm8fHx3qkYAe2f//wn/QfLcA2E1bgGwkpcA2F3Hn0ULTExUebPny/Lly+X8PDw3M9LRkZGSlhYmERGRkrfvn1lyJAhUqZMGYmIiJDnn39e4uPjb7giFeCJTz75hP6DZV588UVZvHgxPQjLcA2ElbgGwu48mthcX4O7ZcuWpnzOnDnSp08fERF59913JTg4WLp27SqZmZnStm1bmTp1qleKBdLS0ug/WGbWrFkiwjUQ1uEaCCtxDYTdebRBpz/YeWMmWM+dzZkKyqoedP2+fvzxR2XMoUOHlMx1Y0wRkaNHjypZlSpV8qyhX79+Sta+ffs8Hycipn0IRET+7//+TxnjeoO3iEhWVpZbz28Hhbn//E23QMv27duVTLcoxfr165XMdbO48+fP5784G/N1DwZK/xXE9V/u/+rJJ580nf/www/KmEaNGinZxYsXvVeYHwTSNbBmzZpKptt4U7eh+969e5XMdYNW3WufboGJRx55RMl0H+u7vm/QdUWKFFHG5OTkKNm3336rZN26dTOd2+V66k7/FWgfGwAAAACwAyY2AAAAAByPiQ0AAAAAx2NiAwAAAMDxPFoVDYDvpKenm87btGmjjFm4cKGSLV26VMlcb+QXEa/u7LxhwwYlu74iznW//PKL174eCp+hQ4cqmTsLXIiIJCcnK5ldbm5F4RIVFaVknTp1yvNx//rXv5TMaQsFBLoDBw4o2cCBA5VsypQpSla3bl0l0y064Us7duxQspEjRyrZ119/7Y9y/IZ3bAAAAAA4HhMbAAAAAI7HxAYAAACA4zGxAQAAAOB4LB4A2NS+ffuUrGHDhko2YsQIJdPd8Fq9enXT+U8//aSMSUtLU7IlS5Yo2XfffadkgCdcd2r3RI0aNbxYCXBjrVq1UrKyZcsqWXZ2tun8zJkzPqsJ1vnwww/dymAd3rEBAAAA4HhMbAAAAAA4HhMbAAAAAI7HxAYAAACA47F4AOAgly5dUrJXXnnFgkqAgvniiy+UrFevXkq2ceNGJXvttdd8UhPgql27dm6Nmz17tul87dq1vigHQB54xwYAAACA4zGxAQAAAOB4TGwAAAAAOB732AAA/E63QWdBNu0EfOGbb75RMt2mnUOHDvVHOQDywDs2AAAAAByPiQ0AAAAAx2NiAwAAAMDxmNgAAAAAcDwWDwAAANCYN2+eWxkAe+AdGwAAAACOx8QGAAAAgOMxsQEAAADgeLab2BiGYXUJsDF/9Ac9iBuh/2A1X/cH/Yeb4RoIK7nTG7ab2GRkZFhdAmzMH/1BD+JG6D9Yzdf9Qf/hZrgGwkru9EaQYbOpcU5Ojpw4cULCw8MlIyNDKleuLMePH5eIiAirS/NIenq6Y2sXsV/9hmFIRkaGxMTESHCwb+fj13vQMAyJjY21zd+Bp+z2b+gpO9VP/3nOTv9++WG3+v3Vg7wG24Pd6uca6Dm7/Rt6yk71e9J/tlvuOTg4WCpVqiQiIkFBQSIiEhERYflfan45uXYRe9UfGRnpl69zvQfT09NFxF5/B/lB/d5B/+UP9XuPP3qQ12B7sVP9XAPzh/q9w93+s91H0QAAAADAU0xsAAAAADierSc2oaGhMmrUKAkNDbW6FI85uXYR59fvDU7/O6B+Z3P690/9zufkvwMn1y7i/Pq9wel/B9RvDdstHgAAAAAAnrL1OzYAAAAA4A4mNgAAAAAcj4kNAAAAAMdjYgMAAADA8ZjYAAAAAHA8205spkyZInFxcVK8eHFp0qSJbNu2zeqStDZs2CAdO3aUmJgYCQoKkmXLlpn+3DAMefXVV6VixYoSFhYmCQkJ8vPPP1tTrIukpCRp1KiRhIeHS4UKFaRLly5y4MAB05jLly9LYmKilC1bVkqWLCldu3aV1NRUiyr2L3rQ9+jBG6P/fI/+uzH6z/fov5ujB32vMPagLSc2CxculCFDhsioUaNk165dUq9ePWnbtq2cOnXK6tIUFy5ckHr16smUKVO0fz5u3DiZNGmSTJ8+XbZu3Sq33HKLtG3bVi5fvuznSlXr16+XxMRESU5Olm+++UauXLkibdq0kQsXLuSOGTx4sHz++eeyaNEiWb9+vZw4cUIefvhhC6v2D3rQP+hBPfrPP+g/PfrPP+i/G6MH/aNQ9qBhQ40bNzYSExNzz7Ozs42YmBgjKSnJwqryJiLG0qVLc89zcnKM6Oho4+23387Nzp07Z4SGhhoff/yxBRXe3KlTpwwRMdavX28YxrVaixUrZixatCh3zA8//GCIiLFlyxaryvQLetAa9OA19J816L9r6D9r0H9/ogetURh60Hbv2GRlZcnOnTslISEhNwsODpaEhATZsmWLhZV57siRI5KSkmL6XiIjI6VJkya2/F7S0tJERKRMmTIiIrJz5065cuWKqf5atWpJbGysLev3FnrQOvQg/Wcl+o/+sxL9dw09aJ3C0IO2m9icOXNGsrOzJSoqypRHRUVJSkqKRVXlz/V6nfC95OTkyKBBg6RZs2ZSu3ZtEblWf0hIiJQqVco01o71exM9aA168Br6zxr03zX0nzXovz/Rg9YoLD1Y1OoCYA+JiYmyb98+2bRpk9WlIEDRg7AS/Qcr0X+wWmHpQdu9Y1OuXDkpUqSIsuJCamqqREdHW1RV/lyv1+7fy8CBA2XFihWydu1aqVSpUm4eHR0tWVlZcu7cOdN4u9XvbfSg/9GDf6L//I/++xP953/0nxk96H+FqQdtN7EJCQmRBg0ayOrVq3OznJwcWb16tcTHx1tYmeeqVq0q0dHRpu8lPT1dtm7daovvxTAMGThwoCxdulTWrFkjVatWNf15gwYNpFixYqb6Dxw4IMeOHbNF/b5CD/oPPaii//yH/lPRf/5D/+nRg/5TKHvQ0qULbmDBggVGaGioMXfuXGP//v1Gv379jFKlShkpKSlWl6bIyMgwdu/ebezevdsQEeOdd94xdu/ebRw9etQwDMMYO3asUapUKWP58uXG3r17jc6dOxtVq1Y1Ll26ZHHlhjFgwAAjMjLSWLdunXHy5Mnc4+LFi7lj+vfvb8TGxhpr1qwxduzYYcTHxxvx8fEWVu0f9KB/0IN69J9/0H969J9/0H83Rg/6R2HsQVtObAzDMCZPnmzExsYaISEhRuPGjY3k5GSrS9Jau3atISLK0bt3b8Mwri31N3LkSCMqKsoIDQ01WrdubRw4cMDaov8/Xd0iYsyZMyd3zKVLl4znnnvOKF26tFGiRAnjoYceMk6ePGld0X5ED/oePXhj9J/v0X83Rv/5Hv13c/Sg7xXGHgwyDMPwzns/AAAAAGAN291jAwAAAACeYmIDAAAAwPGY2AAAAABwPCY2AAAAAByPiQ0AAAAAx2NiAwAAAMDxmNgAAAAAcDwmNgAAAAAcj4kNAAAAAMdjYgMAAADA8ZjYAAAAAHC8/wcYik8k75WeGgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Implement*** the following cell to randomly split the training dataset previously defined, and make a training and validation set. Do an 80-20 split for the training and validation set. Name these sets carefully, they will be used in the next section to train your models.\n",
        "\n",
        "You can use the utilities in `torch.utils.data`."
      ],
      "metadata": {
        "id": "FqND0a-DngYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "train_len = int(0.8 * len(mnist_train))\n",
        "val_len = len(mnist_train) - train_len\n",
        "train_set, val_set = random_split(mnist_train, [train_len, val_len])"
      ],
      "metadata": {
        "id": "QIT0omqUngq8"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: MNIST Classification (40 pts)"
      ],
      "metadata": {
        "id": "naiZzb4OcipT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Classifiers\n",
        "\n",
        "The linear classifiers you implemented in the last assignment will serve as our baseline for more powerful convolutional neural networks. You will ***implement*** the multi-class SVM and  Softmax classifiers in the following cells.  "
      ],
      "metadata": {
        "id": "VHaGaWsQcuWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** a LinearSVM classifier in the following cell. Your implementation should be a python class that inherits from `torch.nn.Module`.\n",
        "\n",
        "You should use classes and functions defined in `torch.nn` and `torch.nn.Functional`.   "
      ],
      "metadata": {
        "id": "Rrg6BMCWdaTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearSVM(nn.Module):\n",
        "  ''' Implements the linear SVM using Torch.\n",
        "  '''\n",
        "  def __init__(self, num_classes, *args, **kwargs):\n",
        "    '''\n",
        "      num_classes (int): The number of output classes\n",
        "    '''\n",
        "    super().__init__()\n",
        "    self.input_dim = kwargs[\"input_dim\"]\n",
        "    self.num_classes = num_classes\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_cls = torch.nn.Linear(self.input_dim, self.num_classes, True)\n",
        "    # raise NotImplementedError(\"LinearSVM forward not implemented\")\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''\n",
        "      x (torch.Tensor): Input image as a torch tensor.\n",
        "    '''\n",
        "    # raise NotImplementedError(\"LinearSVM forward not implemented\")\n",
        "    x = self.flatten(x)\n",
        "    out = self.linear_cls(x)\n",
        "    return out"
      ],
      "metadata": {
        "id": "VdQU1itSctyR"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Implement*** using any PyTorch defined optimizer, code to train your LinearSVM classifier on the training dataset. You will want to try different optimizers, learning rates, and batch sizes.\n",
        "\n",
        "PyTorch provides implementations of various optimization algorithms in the `torch.optim` package. You can use any of the first order methods such as:\n",
        "\n",
        "- SGD (with or without momentum)\n",
        "- AdaDelta\n",
        "- ADAM\n",
        "- RProp\n",
        "- RMSProp\n",
        "\n",
        "***Note:*** You should keep track of the performance of the optimizers, batch sizes, and learning rates. You should justify the choice of your hyperparameters in the report at the end of this section. You will be asked to quantify and visualize the differences between these hyperparameters.\n",
        "\n",
        "You should use `Torch.utils.data.DataLoader` to do the data loading. Make sure to use the correct loss function. You may use the predefined loss functions available in `Torch.nn`.\n",
        "\n",
        "***Note:*** As the optimization procedure for training different models is often the same, you should write helper functions that are reusable. This will make your code more readable and reduce the possibility of unexpected bugs.  \n",
        "\n",
        "To train a single model, you will need to:\n",
        "\n",
        "- Iterate through the data in batches using your training or validation dataloader\n",
        "- Perform the forward pass\n",
        "- Compute the loss\n",
        "- Perform the backward pass\n",
        "- Take an optimizer step\n",
        "- Repeat the process till network converges or some other criterion\n",
        "- Every n iterations, go through the validation set and calculate the loss and accuracy of the validation set to check your training performance"
      ],
      "metadata": {
        "id": "9zwabAUlda_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dataloader, val_dataloader, model, loss_fn, optimizer, device):\n",
        "  size = len(train_dataloader.dataset)\n",
        "  model.train()\n",
        "\n",
        "  train_loss_list = []\n",
        "  val_loss_list = []\n",
        "  val_acc_list = []\n",
        "  for batch, (X, y) in enumerate(train_dataloader):\n",
        "    # Compute prediction error\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(X)\n",
        "      print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "      # run validation\n",
        "      val_loss, acc = val(val_dataloader, model, loss_fn)\n",
        "      train_loss_list.append(loss)\n",
        "      val_loss_list.append(val_loss)\n",
        "      val_acc_list.append(acc)\n",
        "\n",
        "    if batch == len(train_dataloader) - 1:\n",
        "      val_loss, acc = val(val_dataloader, model, loss_fn)\n",
        "      train_loss_list.append(loss.item())\n",
        "      val_loss_list.append(val_loss)\n",
        "      val_acc_list.append(acc)\n",
        "\n",
        "  return train_loss_list, val_loss_list, val_acc_list\n",
        "\n",
        "def val(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  val_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      val_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  val_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Val Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg Val loss: {val_loss:>8f} \\n\")\n",
        "\n",
        "  accuracy = correct/size\n",
        "\n",
        "  return val_loss, accuracy"
      ],
      "metadata": {
        "id": "tg9aAl_JchSr"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LinearSVM model with SGD as the optimizer"
      ],
      "metadata": {
        "id": "b2z4rjJoE3Hw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "  \"cuda\" if torch.cuda.is_available()\n",
        "  else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "model = LinearSVM(10, input_dim=784).to(device)\n",
        "train_dataloader = DataLoader(train_set, batch_size=32)\n",
        "val_dataloader = DataLoader(val_set, batch_size=32)\n",
        "loss_fn = torch.nn.MultiMarginLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "num_epochs = 10\n",
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "val_acc_list = []\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  print(f\"Epoch {i+1}\\n-------------------------------\")\n",
        "  train_loss, val_loss, val_acc = train(train_dataloader, val_dataloader, model, loss_fn, optimizer, device)\n",
        "\n",
        "  train_loss_list.extend(train_loss)\n",
        "  val_loss_list.extend(val_loss)\n",
        "  val_acc_list.extend(val_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACTriGQpLRvt",
        "outputId": "b72eb091-d6b1-4f6a-f770-a1a4d1c88c4b",
        "collapsed": true
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.963311  [   32/16000]\n",
            "Val Error: \n",
            " Accuracy: 9.1%, Avg Val loss: 0.910683 \n",
            "\n",
            "loss: 0.087622  [ 3232/16000]\n",
            "Val Error: \n",
            " Accuracy: 85.5%, Avg Val loss: 0.095176 \n",
            "\n",
            "loss: 0.032564  [ 6432/16000]\n",
            "Val Error: \n",
            " Accuracy: 87.5%, Avg Val loss: 0.077855 \n",
            "\n",
            "loss: 0.083134  [ 9632/16000]\n",
            "Val Error: \n",
            " Accuracy: 88.0%, Avg Val loss: 0.071530 \n",
            "\n",
            "loss: 0.136465  [12832/16000]\n",
            "Val Error: \n",
            " Accuracy: 88.6%, Avg Val loss: 0.066044 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 88.6%, Avg Val loss: 0.062739 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.120785  [   32/16000]\n",
            "Val Error: \n",
            " Accuracy: 88.6%, Avg Val loss: 0.062684 \n",
            "\n",
            "loss: 0.038588  [ 3232/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.2%, Avg Val loss: 0.061649 \n",
            "\n",
            "loss: 0.016626  [ 6432/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.2%, Avg Val loss: 0.059868 \n",
            "\n",
            "loss: 0.066984  [ 9632/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.4%, Avg Val loss: 0.058783 \n",
            "\n",
            "loss: 0.132094  [12832/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.3%, Avg Val loss: 0.056964 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 89.4%, Avg Val loss: 0.055471 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.107748  [   32/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.4%, Avg Val loss: 0.055452 \n",
            "\n",
            "loss: 0.025700  [ 3232/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.0%, Avg Val loss: 0.055216 \n",
            "\n",
            "loss: 0.014074  [ 6432/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.8%, Avg Val loss: 0.054393 \n",
            "\n",
            "loss: 0.062344  [ 9632/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.9%, Avg Val loss: 0.053828 \n",
            "\n",
            "loss: 0.124052  [12832/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.5%, Avg Val loss: 0.053371 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 89.9%, Avg Val loss: 0.052257 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.099966  [   32/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.9%, Avg Val loss: 0.052256 \n",
            "\n",
            "loss: 0.021181  [ 3232/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.2%, Avg Val loss: 0.052099 \n",
            "\n",
            "loss: 0.012677  [ 6432/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.0%, Avg Val loss: 0.051642 \n",
            "\n",
            "loss: 0.061697  [ 9632/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.2%, Avg Val loss: 0.051364 \n",
            "\n",
            "loss: 0.118189  [12832/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.9%, Avg Val loss: 0.051128 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 90.1%, Avg Val loss: 0.050425 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.094599  [   32/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.1%, Avg Val loss: 0.050431 \n",
            "\n",
            "loss: 0.018259  [ 3232/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.4%, Avg Val loss: 0.050333 \n",
            "\n",
            "loss: 0.011502  [ 6432/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.3%, Avg Val loss: 0.050179 \n",
            "\n",
            "loss: 0.061014  [ 9632/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.2%, Avg Val loss: 0.049977 \n",
            "\n",
            "loss: 0.112579  [12832/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.1%, Avg Val loss: 0.049703 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 90.4%, Avg Val loss: 0.049185 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.091007  [   32/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.3%, Avg Val loss: 0.049222 \n",
            "\n",
            "loss: 0.016153  [ 3232/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.5%, Avg Val loss: 0.049278 \n",
            "\n",
            "loss: 0.011154  [ 6432/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.5%, Avg Val loss: 0.049115 \n",
            "\n",
            "loss: 0.060474  [ 9632/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.4%, Avg Val loss: 0.048850 \n",
            "\n",
            "loss: 0.107391  [12832/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.2%, Avg Val loss: 0.048794 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 90.4%, Avg Val loss: 0.048201 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.087483  [   32/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.4%, Avg Val loss: 0.048231 \n",
            "\n",
            "loss: 0.015020  [ 3232/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.5%, Avg Val loss: 0.048456 \n",
            "\n",
            "loss: 0.010973  [ 6432/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.5%, Avg Val loss: 0.048530 \n",
            "\n",
            "loss: 0.059096  [ 9632/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.5%, Avg Val loss: 0.048033 \n",
            "\n",
            "loss: 0.103790  [12832/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.2%, Avg Val loss: 0.048117 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 90.4%, Avg Val loss: 0.047636 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.084198  [   32/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.4%, Avg Val loss: 0.047656 \n",
            "\n",
            "loss: 0.014056  [ 3232/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.5%, Avg Val loss: 0.047799 \n",
            "\n",
            "loss: 0.010589  [ 6432/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.6%, Avg Val loss: 0.047824 \n",
            "\n",
            "loss: 0.057884  [ 9632/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.5%, Avg Val loss: 0.047419 \n",
            "\n",
            "loss: 0.101613  [12832/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.1%, Avg Val loss: 0.047628 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 90.6%, Avg Val loss: 0.047048 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.082147  [   32/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.6%, Avg Val loss: 0.047078 \n",
            "\n",
            "loss: 0.013092  [ 3232/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.7%, Avg Val loss: 0.047202 \n",
            "\n",
            "loss: 0.010375  [ 6432/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.7%, Avg Val loss: 0.047389 \n",
            "\n",
            "loss: 0.056391  [ 9632/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.8%, Avg Val loss: 0.046916 \n",
            "\n",
            "loss: 0.099237  [12832/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.2%, Avg Val loss: 0.047329 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 90.6%, Avg Val loss: 0.046651 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.080513  [   32/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.5%, Avg Val loss: 0.046676 \n",
            "\n",
            "loss: 0.012549  [ 3232/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.7%, Avg Val loss: 0.046765 \n",
            "\n",
            "loss: 0.010211  [ 6432/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.6%, Avg Val loss: 0.047097 \n",
            "\n",
            "loss: 0.055371  [ 9632/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.8%, Avg Val loss: 0.046504 \n",
            "\n",
            "loss: 0.096521  [12832/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.3%, Avg Val loss: 0.046912 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 90.6%, Avg Val loss: 0.046351 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss_list, label=\"training loss\")\n",
        "plt.plot(val_loss_list, label=\"validation loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss vs Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "dTIRRdErIzPI",
        "outputId": "9d7084c8-7d5e-4429-f766-339d6a4717b0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LinearSVM model with Adam as the optimizer"
      ],
      "metadata": {
        "id": "yFDBCys8E_OZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "  \"cuda\" if torch.cuda.is_available()\n",
        "  else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "model = LinearSVM(10, input_dim=784).to(device)\n",
        "train_dataloader = DataLoader(train_set, batch_size=32)\n",
        "val_dataloader = DataLoader(val_set, batch_size=32)\n",
        "loss_fn = torch.nn.MultiMarginLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "num_epochs = 10\n",
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "val_acc_list = []\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  print(f\"Epoch {i+1}\\n-------------------------------\")\n",
        "  train_loss, val_loss, val_acc = train(train_dataloader, val_dataloader, model, loss_fn, optimizer, device)\n",
        "\n",
        "  train_loss_list.extend(train_loss)\n",
        "  val_loss_list.extend(val_loss)\n",
        "  val_acc_list.extend(val_acc)"
      ],
      "metadata": {
        "id": "bc366VceCcba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4595571-1d1c-4058-c21a-fe7a191bf496"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.857171  [   32/16000]\n",
            "Val Error: \n",
            " Accuracy: 29.8%, Avg Val loss: 0.640599 \n",
            "\n",
            "loss: 0.054024  [ 3232/16000]\n",
            "Val Error: \n",
            " Accuracy: 88.1%, Avg Val loss: 0.065796 \n",
            "\n",
            "loss: 0.018202  [ 6432/16000]\n",
            "Val Error: \n",
            " Accuracy: 87.2%, Avg Val loss: 0.065608 \n",
            "\n",
            "loss: 0.037563  [ 9632/16000]\n",
            "Val Error: \n",
            " Accuracy: 87.9%, Avg Val loss: 0.057935 \n",
            "\n",
            "loss: 0.124346  [12832/16000]\n",
            "Val Error: \n",
            " Accuracy: 84.5%, Avg Val loss: 0.080560 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 88.3%, Avg Val loss: 0.059233 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.105958  [   32/16000]\n",
            "Val Error: \n",
            " Accuracy: 88.6%, Avg Val loss: 0.058762 \n",
            "\n",
            "loss: 0.043036  [ 3232/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.2%, Avg Val loss: 0.058305 \n",
            "\n",
            "loss: 0.011585  [ 6432/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.1%, Avg Val loss: 0.061011 \n",
            "\n",
            "loss: 0.042232  [ 9632/16000]\n",
            "Val Error: \n",
            " Accuracy: 88.3%, Avg Val loss: 0.061676 \n",
            "\n",
            "loss: 0.103317  [12832/16000]\n",
            "Val Error: \n",
            " Accuracy: 86.8%, Avg Val loss: 0.074687 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 88.6%, Avg Val loss: 0.062458 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.093539  [   32/16000]\n",
            "Val Error: \n",
            " Accuracy: 88.8%, Avg Val loss: 0.062179 \n",
            "\n",
            "loss: 0.038685  [ 3232/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.0%, Avg Val loss: 0.063500 \n",
            "\n",
            "loss: 0.007788  [ 6432/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.0%, Avg Val loss: 0.065629 \n",
            "\n",
            "loss: 0.032152  [ 9632/16000]\n",
            "Val Error: \n",
            " Accuracy: 87.9%, Avg Val loss: 0.066843 \n",
            "\n",
            "loss: 0.091176  [12832/16000]\n",
            "Val Error: \n",
            " Accuracy: 87.0%, Avg Val loss: 0.075046 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 88.8%, Avg Val loss: 0.062891 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.070485  [   32/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.2%, Avg Val loss: 0.062244 \n",
            "\n",
            "loss: 0.033378  [ 3232/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.6%, Avg Val loss: 0.063808 \n",
            "\n",
            "loss: 0.004808  [ 6432/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.0%, Avg Val loss: 0.068590 \n",
            "\n",
            "loss: 0.030162  [ 9632/16000]\n",
            "Val Error: \n",
            " Accuracy: 88.7%, Avg Val loss: 0.066116 \n",
            "\n",
            "loss: 0.088197  [12832/16000]\n",
            "Val Error: \n",
            " Accuracy: 87.9%, Avg Val loss: 0.074440 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 88.1%, Avg Val loss: 0.070015 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.083378  [   32/16000]\n",
            "Val Error: \n",
            " Accuracy: 88.3%, Avg Val loss: 0.069650 \n",
            "\n",
            "loss: 0.012048  [ 3232/16000]\n",
            "Val Error: \n",
            " Accuracy: 88.8%, Avg Val loss: 0.071044 \n",
            "\n",
            "loss: 0.006861  [ 6432/16000]\n",
            "Val Error: \n",
            " Accuracy: 88.8%, Avg Val loss: 0.074756 \n",
            "\n",
            "loss: 0.031228  [ 9632/16000]\n",
            "Val Error: \n",
            " Accuracy: 88.2%, Avg Val loss: 0.070798 \n",
            "\n",
            "loss: 0.100239  [12832/16000]\n",
            "Val Error: \n",
            " Accuracy: 87.2%, Avg Val loss: 0.078031 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 89.0%, Avg Val loss: 0.070176 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.079432  [   32/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.1%, Avg Val loss: 0.070182 \n",
            "\n",
            "loss: 0.018640  [ 3232/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.0%, Avg Val loss: 0.072498 \n",
            "\n",
            "loss: 0.006071  [ 6432/16000]\n",
            "Val Error: \n",
            " Accuracy: 88.2%, Avg Val loss: 0.081339 \n",
            "\n",
            "loss: 0.032282  [ 9632/16000]\n",
            "Val Error: \n",
            " Accuracy: 87.3%, Avg Val loss: 0.078846 \n",
            "\n",
            "loss: 0.087937  [12832/16000]\n",
            "Val Error: \n",
            " Accuracy: 86.8%, Avg Val loss: 0.087949 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 89.0%, Avg Val loss: 0.072311 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.073180  [   32/16000]\n",
            "Val Error: \n",
            " Accuracy: 88.9%, Avg Val loss: 0.072774 \n",
            "\n",
            "loss: 0.021828  [ 3232/16000]\n",
            "Val Error: \n",
            " Accuracy: 88.8%, Avg Val loss: 0.073477 \n",
            "\n",
            "loss: 0.001151  [ 6432/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.2%, Avg Val loss: 0.078719 \n",
            "\n",
            "loss: 0.025922  [ 9632/16000]\n",
            "Val Error: \n",
            " Accuracy: 88.6%, Avg Val loss: 0.076238 \n",
            "\n",
            "loss: 0.082042  [12832/16000]\n",
            "Val Error: \n",
            " Accuracy: 86.3%, Avg Val loss: 0.093203 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 87.9%, Avg Val loss: 0.077025 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.065194  [   32/16000]\n",
            "Val Error: \n",
            " Accuracy: 88.0%, Avg Val loss: 0.077793 \n",
            "\n",
            "loss: 0.029593  [ 3232/16000]\n",
            "Val Error: \n",
            " Accuracy: 88.9%, Avg Val loss: 0.076395 \n",
            "\n",
            "loss: 0.011119  [ 6432/16000]\n",
            "Val Error: \n",
            " Accuracy: 88.3%, Avg Val loss: 0.084281 \n",
            "\n",
            "loss: 0.021872  [ 9632/16000]\n",
            "Val Error: \n",
            " Accuracy: 87.7%, Avg Val loss: 0.082480 \n",
            "\n",
            "loss: 0.070549  [12832/16000]\n",
            "Val Error: \n",
            " Accuracy: 86.3%, Avg Val loss: 0.093832 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 88.9%, Avg Val loss: 0.074320 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.060530  [   32/16000]\n",
            "Val Error: \n",
            " Accuracy: 88.8%, Avg Val loss: 0.074539 \n",
            "\n",
            "loss: 0.024349  [ 3232/16000]\n",
            "Val Error: \n",
            " Accuracy: 88.6%, Avg Val loss: 0.082746 \n",
            "\n",
            "loss: 0.003747  [ 6432/16000]\n",
            "Val Error: \n",
            " Accuracy: 87.8%, Avg Val loss: 0.089648 \n",
            "\n",
            "loss: 0.020871  [ 9632/16000]\n",
            "Val Error: \n",
            " Accuracy: 87.5%, Avg Val loss: 0.086331 \n",
            "\n",
            "loss: 0.105745  [12832/16000]\n",
            "Val Error: \n",
            " Accuracy: 87.8%, Avg Val loss: 0.084820 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 89.0%, Avg Val loss: 0.078711 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.086589  [   32/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.1%, Avg Val loss: 0.079186 \n",
            "\n",
            "loss: 0.002427  [ 3232/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.1%, Avg Val loss: 0.084317 \n",
            "\n",
            "loss: 0.004252  [ 6432/16000]\n",
            "Val Error: \n",
            " Accuracy: 88.4%, Avg Val loss: 0.088928 \n",
            "\n",
            "loss: 0.025082  [ 9632/16000]\n",
            "Val Error: \n",
            " Accuracy: 87.8%, Avg Val loss: 0.087566 \n",
            "\n",
            "loss: 0.089984  [12832/16000]\n",
            "Val Error: \n",
            " Accuracy: 86.4%, Avg Val loss: 0.096828 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 88.1%, Avg Val loss: 0.082598 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss_list, label=\"training loss\")\n",
        "plt.plot(val_loss_list, label=\"validation loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss vs Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "npCQZPkk4zhD",
        "outputId": "a0a7a0ee-2770-4169-e9c7-ec46b8ab73eb"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LinearSVM model with RMSProp as the optimizer"
      ],
      "metadata": {
        "id": "a_vqfECZcmGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "  \"cuda\" if torch.cuda.is_available()\n",
        "  else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "model = LinearSVM(10, input_dim=784).to(device)\n",
        "train_dataloader = DataLoader(train_set, batch_size=32)\n",
        "val_dataloader = DataLoader(val_set, batch_size=32)\n",
        "loss_fn = torch.nn.MultiMarginLoss()\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.01)\n",
        "num_epochs = 10\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  print(f\"Epoch {i+1}\\n-------------------------------\")\n",
        "  train(train_dataloader, val_dataloader, model, loss_fn, optimizer, device)"
      ],
      "metadata": {
        "id": "isjhgEI2bOl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** a Softmax classifier in the following cell. Your implementation should be a python class that inherits from `torch.nn.Module`."
      ],
      "metadata": {
        "id": "VeL39QqOnako"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftmaxClassifier(nn.Module):\n",
        "  ''' Implements the softmax classifier using Torch.\n",
        "  '''\n",
        "  def __init__(self, num_classes, *args, **kwargs):\n",
        "    '''\n",
        "      num_classes (int): The number of output classes\n",
        "    '''\n",
        "    super().__init__()\n",
        "    self.input_dim = kwargs[\"input_dim\"]\n",
        "    self.num_classes = num_classes\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_cls = torch.nn.Linear(self.input_dim, self.num_classes, True, dtype=torch.double)\n",
        "    self.act = nn.Softmax(dim=1)\n",
        "    # raise NotImplementedError(\"LinearSVM forward not implemented\")\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''\n",
        "      x (torch.Tensor): Input image as a torch tensor.\n",
        "    '''\n",
        "    # raise NotImplementedError(\"LinearSVM forward not implemented\")\n",
        "    x = self.flatten(x)\n",
        "    x = self.linear_cls(x)\n",
        "    out = self.act(x)\n",
        "    return out"
      ],
      "metadata": {
        "id": "u5p2C_1QHSb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Implement*** using any PyTorch defined optimizer, train your Softmax classifier on the training dataset and validate on the validation dataset, as you did before.\n",
        "\n",
        "***Note:*** You should keep track of the performance of the optimizers, batch sizes, and learning rates. You should justify the choice of your hyperparameters in the report at the end of this section. You will be asked to quantify and visualize the differences between these hyperparameters.\n",
        "\n",
        "You will want to try different optimizers, learning rates, and batch sizes. You should use `Torch.DataLoader` to simplify the data loading. Make sure to use the correct loss function. You may use predefined loss functions available in `Torch.nn`.\n",
        "\n",
        "Same as before, to train a single model, you will need to:\n",
        "\n",
        "- Iterate through the data in batches using your training or validation dataloader\n",
        "- Perform the forward pass\n",
        "- Compute the loss\n",
        "- Perform the backward pass\n",
        "- Take an optimizer step\n",
        "- Repeat the process till network converges or some other criterion\n",
        "- Every n iterations, go through the validation set and calculate the loss and accuracy of the validation set to check your training performance"
      ],
      "metadata": {
        "id": "LgLiSrkvov7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "  \"cuda\" if torch.cuda.is_available()\n",
        "  else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "num_epochs = 10\n",
        "softmax_model = SoftmaxClassifier(10, input_dim=784).to(device)\n",
        "train_dataloader = DataLoader(train_set, batch_size=32)\n",
        "val_dataloader = DataLoader(val_set, batch_size=32)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(softmax_model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  print(f\"Epoch {i+1}\\n-------------------------------\")\n",
        "  train(train_dataloader, val_dataloader, softmax_model, loss_fn, optimizer, device)"
      ],
      "metadata": {
        "id": "LFAf4i-cowF_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "outputId": "e9e9ceca-44c4-4c17-edfd-5939e1d73b86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.301602  [   32/16000]\n",
            "Val Error: \n",
            " Accuracy: 9.8%, Avg Val loss: 2.304067 \n",
            "\n",
            "loss: 2.008221  [ 3232/16000]\n",
            "Val Error: \n",
            " Accuracy: 51.0%, Avg Val loss: 2.075118 \n",
            "\n",
            "loss: 1.871152  [ 6432/16000]\n",
            "Val Error: \n",
            " Accuracy: 63.3%, Avg Val loss: 1.910411 \n",
            "\n",
            "loss: 1.805711  [ 9632/16000]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-3afdb7b8d155>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {i+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftmax_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-44-bccee85bdfac>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_dataloader, val_dataloader, model, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0;31m# run validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-bccee85bdfac>\u001b[0m in \u001b[0;36mval\u001b[0;34m(dataloader, model, loss_fn)\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m       \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-589e34df9aeb>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m       \u001b[0msemple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mangle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(img, angle, interpolation, expand, center, fill)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;31m# we need to set -angle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_inverse_affine_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(img, matrix, interpolation, expand, fill)\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;31m# grid will be generated on the same device as theta and img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gen_affine_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_apply_grid_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\u001b[0m in \u001b[0;36m_gen_affine_grid\u001b[0;34m(theta, w, h, ow, oh)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0mrescaled_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m     \u001b[0moutput_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescaled_theta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Implement*** visualizations in the following cell to show performance differences of the different hyperparameters.\n",
        "\n",
        "***Include*** visualizations for the effect of different batch sizes, learning rates, and optimizers. You are free to choose any method of visualization as long as it is able to succintly convey your justifications."
      ],
      "metadata": {
        "id": "AjBRu6jJp4Jx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XbKSedbmp3lB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolutional Neural Networks"
      ],
      "metadata": {
        "id": "WWSOkLP69Tv3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Implement*** the following cell to implement a convolutional neural network. Similar to before, your implementation should be a Python class that inherits from `torch.nn.Module`.\n",
        "\n",
        "Your model can use any of the building blocks defined in `torch.nn` including but not limited to:\n",
        "\n",
        "- Conv2D\n",
        "- Linear\n",
        "- Activation layers:\n",
        "  - ReLU\n",
        "  - Tanh\n",
        "  - Sigmoid\n",
        "  - Softmax\n",
        "- Normalization layers:\n",
        "  - BatchNorm\n",
        "  - LayerNorm\n",
        "  - GroupNorm\n",
        "- Pooling layers:\n",
        "  - MaxPool\n",
        "  - AvgPool\n",
        "- Dropout\n",
        "\n",
        "Make sure to chose the correct dimensional versions of the layers, i.e for images use MaxPool2d and vectors use MaxPool1d\n"
      ],
      "metadata": {
        "id": "tFAJcXU-owUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example LeNet implementation:\n",
        "\n",
        "```python\n",
        "class LeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(LeNet, self).__init__()\n",
        "        \n",
        "        # num_classes number of output classes\n",
        "        self.num_classes = num_classes\n",
        "        # 1 input image channel,\n",
        "        # 6 output channels\n",
        "        # 5x5 square convolution kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        # ReLU activation function\n",
        "        self.act1 = nn.ReLU()\n",
        "        # Max pooling with 2x2 square kernel\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        \n",
        "        # Second convolution with 6 input image channels\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "\n",
        "        # 3 Layer fully connected layer\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.act3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.act4 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        # First Convolution -> Activation -> Max Pooling\n",
        "        x = self.conv1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        # Second Convolution -> Activation -> Max Pooling\n",
        "        x = self.conv2(x)\n",
        "        x = self.act2(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        # flatten all dimensions except the batch dimension\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # Three layer MLP with ReLU activations\n",
        "        x = self.act3(self.fc1(x))\n",
        "        x = self.act4(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "AU2zciw2y9tZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cells, perform experiments using the CNN you defined. You may need to reshape your data in order to 2D convolutions.\n",
        "\n",
        "Your objective is to find the best architecture that minimizes the error but using as few a parameters and FLOPS as possible.\n",
        "\n",
        "***Performance matters!*** The model with the best combination of high accuracy, parameter, and compute efficiency will get extra credit (15 pts)."
      ],
      "metadata": {
        "id": "8TT1pSu2ppPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  ''' Implements the CNN using Torch.\n",
        "  '''\n",
        "  def __init__(self, num_classes, *args, **kwargs):\n",
        "    '''\n",
        "      num_classes (int): The number of output classes\n",
        "    '''\n",
        "    super().__init__()\n",
        "    self.num_classes = num_classes\n",
        "\n",
        "    # First convolution block\n",
        "    self.conv1 = nn.Conv2d(1, 8, 3)\n",
        "    self.act1 = nn.SiLU()\n",
        "    self.pool1 = nn.MaxPool2d(2)\n",
        "\n",
        "    # Second convolution block with 8 input image channels\n",
        "    self.conv2 = nn.Conv2d(8, 16, 3)\n",
        "    self.act2 = nn.SiLU()\n",
        "    self.pool2 = nn.MaxPool2d(2)\n",
        "\n",
        "    # Third convolution block with 32 input image channels\n",
        "    self.conv3 = nn.Conv2d(16, 32, 3)\n",
        "    self.act3 = nn.SiLU()\n",
        "    self.pool3 = nn.MaxPool2d(2)\n",
        "\n",
        "    # 3 Layer fully connected layer\n",
        "    self.fc1 = nn.Linear(32 * 1 * 1, 120)\n",
        "    self.act4 = nn.SiLU()\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.act5 = nn.SiLU()\n",
        "    self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''\n",
        "      x (torch.Tensor): Input image as a torch tensor.\n",
        "    '''\n",
        "    x = self.conv1(x)\n",
        "    x = self.act1(x)\n",
        "    x = self.pool1(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.act2(x)\n",
        "    x = self.pool2(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = self.act3(x)\n",
        "    x = self.pool3(x)\n",
        "\n",
        "    # print (x.shape)\n",
        "\n",
        "    x = torch.flatten(x, 1)\n",
        "\n",
        "    x = self.act4(self.fc1(x))\n",
        "    x = self.act5(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "5bzZVDfwppcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the following cell to compute and compare the test set performance (accuracy) of the linear classifiers and CNN."
      ],
      "metadata": {
        "id": "tQGx_PUwdLlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\" if torch.cuda.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "cnn_model = CNN(10).to(device)\n",
        "train_dataloader = DataLoader(train_set, batch_size=16)\n",
        "val_dataloader = DataLoader(val_set, batch_size=16)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.01)\n",
        "num_epochs = 10\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  print(f\"Epoch {i+1}\\n-------------------------------\")\n",
        "  train(train_dataloader, val_dataloader, cnn_model, loss_fn, optimizer, device)\n",
        "\n",
        "PATH = \"drive/MyDrive/MNIST_580E/cnn_model.pth\"\n",
        "torch.save(cnn_model, PATH)"
      ],
      "metadata": {
        "id": "kzt_M3dqdLzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "608688e5-47c5-4cbc-fd7f-6469d2c899ea",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.315459  [   16/16000]\n",
            "Val Error: \n",
            " Accuracy: 9.6%, Avg Val loss: 2.307856 \n",
            "\n",
            "loss: 0.455291  [ 1616/16000]\n",
            "Val Error: \n",
            " Accuracy: 69.6%, Avg Val loss: 0.917252 \n",
            "\n",
            "loss: 0.430206  [ 3216/16000]\n",
            "Val Error: \n",
            " Accuracy: 86.2%, Avg Val loss: 0.529377 \n",
            "\n",
            "loss: 0.091157  [ 4816/16000]\n",
            "Val Error: \n",
            " Accuracy: 80.4%, Avg Val loss: 0.636751 \n",
            "\n",
            "loss: 0.068776  [ 6416/16000]\n",
            "Val Error: \n",
            " Accuracy: 92.0%, Avg Val loss: 0.319475 \n",
            "\n",
            "loss: 0.127143  [ 8016/16000]\n",
            "Val Error: \n",
            " Accuracy: 91.7%, Avg Val loss: 0.272881 \n",
            "\n",
            "loss: 0.471498  [ 9616/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.1%, Avg Val loss: 0.326559 \n",
            "\n",
            "loss: 0.222792  [11216/16000]\n",
            "Val Error: \n",
            " Accuracy: 91.1%, Avg Val loss: 0.301136 \n",
            "\n",
            "loss: 0.280418  [12816/16000]\n",
            "Val Error: \n",
            " Accuracy: 87.0%, Avg Val loss: 0.391601 \n",
            "\n",
            "loss: 0.083192  [14416/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.7%, Avg Val loss: 0.198668 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 93.7%, Avg Val loss: 0.234071 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.130553  [   16/16000]\n",
            "Val Error: \n",
            " Accuracy: 93.8%, Avg Val loss: 0.228940 \n",
            "\n",
            "loss: 0.265918  [ 1616/16000]\n",
            "Val Error: \n",
            " Accuracy: 93.4%, Avg Val loss: 0.253294 \n",
            "\n",
            "loss: 0.010674  [ 3216/16000]\n",
            "Val Error: \n",
            " Accuracy: 93.5%, Avg Val loss: 0.249861 \n",
            "\n",
            "loss: 0.226260  [ 4816/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.9%, Avg Val loss: 0.345387 \n",
            "\n",
            "loss: 0.000902  [ 6416/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.9%, Avg Val loss: 0.196380 \n",
            "\n",
            "loss: 0.097690  [ 8016/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.1%, Avg Val loss: 0.209423 \n",
            "\n",
            "loss: 0.044957  [ 9616/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.8%, Avg Val loss: 0.354693 \n",
            "\n",
            "loss: 0.364504  [11216/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.9%, Avg Val loss: 0.364732 \n",
            "\n",
            "loss: 0.382713  [12816/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.8%, Avg Val loss: 0.198301 \n",
            "\n",
            "loss: 0.104856  [14416/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.5%, Avg Val loss: 0.195261 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 94.5%, Avg Val loss: 0.207091 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.041407  [   16/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.2%, Avg Val loss: 0.211236 \n",
            "\n",
            "loss: 0.007090  [ 1616/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.2%, Avg Val loss: 0.210418 \n",
            "\n",
            "loss: 0.002418  [ 3216/16000]\n",
            "Val Error: \n",
            " Accuracy: 96.5%, Avg Val loss: 0.157866 \n",
            "\n",
            "loss: 0.192247  [ 4816/16000]\n",
            "Val Error: \n",
            " Accuracy: 96.0%, Avg Val loss: 0.149176 \n",
            "\n",
            "loss: 0.024442  [ 6416/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.6%, Avg Val loss: 0.248175 \n",
            "\n",
            "loss: 0.078130  [ 8016/16000]\n",
            "Val Error: \n",
            " Accuracy: 93.9%, Avg Val loss: 0.293212 \n",
            "\n",
            "loss: 0.172927  [ 9616/16000]\n",
            "Val Error: \n",
            " Accuracy: 90.8%, Avg Val loss: 0.338858 \n",
            "\n",
            "loss: 0.103390  [11216/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.0%, Avg Val loss: 0.197462 \n",
            "\n",
            "loss: 0.493010  [12816/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.3%, Avg Val loss: 0.231959 \n",
            "\n",
            "loss: 0.196235  [14416/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.6%, Avg Val loss: 0.233247 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 93.1%, Avg Val loss: 0.248567 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.003951  [   16/16000]\n",
            "Val Error: \n",
            " Accuracy: 92.8%, Avg Val loss: 0.257785 \n",
            "\n",
            "loss: 0.087593  [ 1616/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.0%, Avg Val loss: 0.241179 \n",
            "\n",
            "loss: 0.001734  [ 3216/16000]\n",
            "Val Error: \n",
            " Accuracy: 96.3%, Avg Val loss: 0.149744 \n",
            "\n",
            "loss: 0.115554  [ 4816/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.7%, Avg Val loss: 0.184209 \n",
            "\n",
            "loss: 0.028321  [ 6416/16000]\n",
            "Val Error: \n",
            " Accuracy: 96.0%, Avg Val loss: 0.188746 \n",
            "\n",
            "loss: 0.141797  [ 8016/16000]\n",
            "Val Error: \n",
            " Accuracy: 93.0%, Avg Val loss: 0.238139 \n",
            "\n",
            "loss: 0.066664  [ 9616/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.5%, Avg Val loss: 0.211847 \n",
            "\n",
            "loss: 0.297696  [11216/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.2%, Avg Val loss: 0.270062 \n",
            "\n",
            "loss: 0.109234  [12816/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.2%, Avg Val loss: 0.191353 \n",
            "\n",
            "loss: 0.121496  [14416/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.7%, Avg Val loss: 0.233954 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 94.5%, Avg Val loss: 0.221235 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.010013  [   16/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.3%, Avg Val loss: 0.231685 \n",
            "\n",
            "loss: 0.015426  [ 1616/16000]\n",
            "Val Error: \n",
            " Accuracy: 92.7%, Avg Val loss: 0.290027 \n",
            "\n",
            "loss: 0.007450  [ 3216/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.2%, Avg Val loss: 0.186367 \n",
            "\n",
            "loss: 0.021098  [ 4816/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.2%, Avg Val loss: 0.217057 \n",
            "\n",
            "loss: 0.000577  [ 6416/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.2%, Avg Val loss: 0.212525 \n",
            "\n",
            "loss: 0.161767  [ 8016/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.4%, Avg Val loss: 0.195801 \n",
            "\n",
            "loss: 0.151694  [ 9616/16000]\n",
            "Val Error: \n",
            " Accuracy: 89.3%, Avg Val loss: 0.454417 \n",
            "\n",
            "loss: 0.121323  [11216/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.2%, Avg Val loss: 0.260753 \n",
            "\n",
            "loss: 0.089475  [12816/16000]\n",
            "Val Error: \n",
            " Accuracy: 93.8%, Avg Val loss: 0.248581 \n",
            "\n",
            "loss: 0.168193  [14416/16000]\n",
            "Val Error: \n",
            " Accuracy: 91.8%, Avg Val loss: 0.382782 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 95.2%, Avg Val loss: 0.198972 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.122992  [   16/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.0%, Avg Val loss: 0.202997 \n",
            "\n",
            "loss: 0.009180  [ 1616/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.5%, Avg Val loss: 0.175512 \n",
            "\n",
            "loss: 0.235901  [ 3216/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.2%, Avg Val loss: 0.207227 \n",
            "\n",
            "loss: 0.026715  [ 4816/16000]\n",
            "Val Error: \n",
            " Accuracy: 96.2%, Avg Val loss: 0.205687 \n",
            "\n",
            "loss: 0.009670  [ 6416/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.3%, Avg Val loss: 0.260715 \n",
            "\n",
            "loss: 0.080337  [ 8016/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.5%, Avg Val loss: 0.203529 \n",
            "\n",
            "loss: 0.054441  [ 9616/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.0%, Avg Val loss: 0.263928 \n",
            "\n",
            "loss: 0.357634  [11216/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.4%, Avg Val loss: 0.192587 \n",
            "\n",
            "loss: 0.085053  [12816/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.4%, Avg Val loss: 0.206313 \n",
            "\n",
            "loss: 0.182666  [14416/16000]\n",
            "Val Error: \n",
            " Accuracy: 92.7%, Avg Val loss: 0.307942 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 94.0%, Avg Val loss: 0.273508 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.004525  [   16/16000]\n",
            "Val Error: \n",
            " Accuracy: 93.6%, Avg Val loss: 0.291047 \n",
            "\n",
            "loss: 0.001068  [ 1616/16000]\n",
            "Val Error: \n",
            " Accuracy: 96.0%, Avg Val loss: 0.200674 \n",
            "\n",
            "loss: 0.007269  [ 3216/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.8%, Avg Val loss: 0.182350 \n",
            "\n",
            "loss: 0.011971  [ 4816/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.4%, Avg Val loss: 0.188294 \n",
            "\n",
            "loss: 0.018138  [ 6416/16000]\n",
            "Val Error: \n",
            " Accuracy: 96.3%, Avg Val loss: 0.215186 \n",
            "\n",
            "loss: 0.137898  [ 8016/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.2%, Avg Val loss: 0.207042 \n",
            "\n",
            "loss: 0.262285  [ 9616/16000]\n",
            "Val Error: \n",
            " Accuracy: 96.2%, Avg Val loss: 0.167756 \n",
            "\n",
            "loss: 0.125636  [11216/16000]\n",
            "Val Error: \n",
            " Accuracy: 96.0%, Avg Val loss: 0.203058 \n",
            "\n",
            "loss: 0.032633  [12816/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.0%, Avg Val loss: 0.208457 \n",
            "\n",
            "loss: 0.025695  [14416/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.8%, Avg Val loss: 0.224262 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 94.4%, Avg Val loss: 0.255779 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.008043  [   16/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.4%, Avg Val loss: 0.260329 \n",
            "\n",
            "loss: 0.055362  [ 1616/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.8%, Avg Val loss: 0.276706 \n",
            "\n",
            "loss: 0.008024  [ 3216/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.7%, Avg Val loss: 0.325363 \n",
            "\n",
            "loss: 0.002645  [ 4816/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.7%, Avg Val loss: 0.175495 \n",
            "\n",
            "loss: 0.009334  [ 6416/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.5%, Avg Val loss: 0.235050 \n",
            "\n",
            "loss: 0.135799  [ 8016/16000]\n",
            "Val Error: \n",
            " Accuracy: 96.0%, Avg Val loss: 0.185934 \n",
            "\n",
            "loss: 0.503173  [ 9616/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.8%, Avg Val loss: 0.184466 \n",
            "\n",
            "loss: 0.103610  [11216/16000]\n",
            "Val Error: \n",
            " Accuracy: 96.2%, Avg Val loss: 0.151871 \n",
            "\n",
            "loss: 0.371542  [12816/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.1%, Avg Val loss: 0.229422 \n",
            "\n",
            "loss: 0.072904  [14416/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.9%, Avg Val loss: 0.227663 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 96.4%, Avg Val loss: 0.167499 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.108251  [   16/16000]\n",
            "Val Error: \n",
            " Accuracy: 96.4%, Avg Val loss: 0.163913 \n",
            "\n",
            "loss: 0.001592  [ 1616/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.8%, Avg Val loss: 0.188000 \n",
            "\n",
            "loss: 0.003686  [ 3216/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.8%, Avg Val loss: 0.276120 \n",
            "\n",
            "loss: 0.022031  [ 4816/16000]\n",
            "Val Error: \n",
            " Accuracy: 91.8%, Avg Val loss: 0.537080 \n",
            "\n",
            "loss: 0.006789  [ 6416/16000]\n",
            "Val Error: \n",
            " Accuracy: 93.5%, Avg Val loss: 0.321879 \n",
            "\n",
            "loss: 0.217406  [ 8016/16000]\n",
            "Val Error: \n",
            " Accuracy: 92.5%, Avg Val loss: 0.260640 \n",
            "\n",
            "loss: 0.210364  [ 9616/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.9%, Avg Val loss: 0.199713 \n",
            "\n",
            "loss: 0.181791  [11216/16000]\n",
            "Val Error: \n",
            " Accuracy: 96.0%, Avg Val loss: 0.174193 \n",
            "\n",
            "loss: 0.028557  [12816/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.5%, Avg Val loss: 0.197501 \n",
            "\n",
            "loss: 0.055369  [14416/16000]\n",
            "Val Error: \n",
            " Accuracy: 96.8%, Avg Val loss: 0.161458 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 95.2%, Avg Val loss: 0.233643 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.053211  [   16/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.3%, Avg Val loss: 0.228476 \n",
            "\n",
            "loss: 0.002842  [ 1616/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.5%, Avg Val loss: 0.228758 \n",
            "\n",
            "loss: 0.032593  [ 3216/16000]\n",
            "Val Error: \n",
            " Accuracy: 96.5%, Avg Val loss: 0.187233 \n",
            "\n",
            "loss: 0.091053  [ 4816/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.7%, Avg Val loss: 0.264988 \n",
            "\n",
            "loss: 0.005417  [ 6416/16000]\n",
            "Val Error: \n",
            " Accuracy: 94.8%, Avg Val loss: 0.297691 \n",
            "\n",
            "loss: 0.145490  [ 8016/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.5%, Avg Val loss: 0.201348 \n",
            "\n",
            "loss: 0.271031  [ 9616/16000]\n",
            "Val Error: \n",
            " Accuracy: 93.4%, Avg Val loss: 0.272553 \n",
            "\n",
            "loss: 0.022600  [11216/16000]\n",
            "Val Error: \n",
            " Accuracy: 96.1%, Avg Val loss: 0.201084 \n",
            "\n",
            "loss: 0.212231  [12816/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.8%, Avg Val loss: 0.182530 \n",
            "\n",
            "loss: 0.001708  [14416/16000]\n",
            "Val Error: \n",
            " Accuracy: 95.7%, Avg Val loss: 0.204820 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 95.0%, Avg Val loss: 0.232826 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZTrFO9vARcAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"drive/MyDrive/MNIST_580E/cnn_model.pth\"\n",
        "cnn_model = torch.load(PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5yEuJmJSA__",
        "outputId": "1c650cc9-c1f1-4d54-e63d-6aea48931259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-d9c4f1be226b>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  cnn_model = torch.load(PATH)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cells ***write*** a short justification on how you came up with your final model and architecture. You may include details like:\n",
        "\n",
        "- Which optimizer did you use? Why did you use that?\n",
        "- What about the other hyperparameters?\n",
        "- Did you base your model on an existing architecture?\n",
        "- What changes did you make to improve accuracy?\n",
        "- What changes did you make to improvde performance?\n",
        "\n",
        "***Include*** visualizations for the effect of different batch sizes, learning rates, and optimizers. You are free to choose any method of visualization as long as it is able to succintly convey your justifications."
      ],
      "metadata": {
        "id": "uhb5-NPKr6RQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tpaxF_nWr6go"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Real World Data (40 pts)"
      ],
      "metadata": {
        "id": "KzbKJhaarIae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While test set accuracy is meant to approximate the perfomance in real world data, biases in data collection and processing often result in inaccurate performance estimates. In this section, you will be using the previously defined models to re-train on the data the class has collected.\n",
        "\n",
        "In user systems, noisy inputs are often likely. To make your model robust to faulty input, you will need to add an additional class to your model which corresponds to the label 10. This label is reserved for inputs that are **not** digits.\n"
      ],
      "metadata": {
        "id": "xlqE7pdPtiMG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Implement*** the following cells to load and convert the new dataset and combine the new dataset with old dataset.  \n",
        "\n",
        "Make sure you have downloaded the `MNIST580E_training.csv` and `MNIST580E_test.csv` files from the shared drive and uplodaded it to your GDrive. You will be combining our collected data with the MNIST dataset available with Colab.\n",
        "\n",
        "You will need to:\n",
        "\n",
        "\n",
        "- Mount your GDrive\n",
        "- Load the `MNIST580E_training.csv` and `MNIST580E_test.csv` files\n",
        "- Parse the files and create train and test datasets as you did previously\n",
        "  - Make sure to normalize the data and add data augmentation. You are free to use any augmentation you'd like.\n",
        "- Combine the new datasets with the dataset available on Colab.\n",
        "  - You can use the `ConcatDataset` or `ChainDataset`.  \n",
        "- Visualize the newly created data. This should serve as a sanity check for your newly written data pipeline.\n",
        "\n",
        "**Data Augmentation:**\n",
        "\n",
        "The collected data will have more variability compared to the original dataset.\n",
        "So you should make heavy use of data augmentation on the collected dataset. You can use augmentations such as as:\n",
        "\n",
        "- Rotation\n",
        "- Resize\n",
        "- Blur\n",
        "- Perspective shift\n",
        "\n",
        "**Another hint:** Since we are adding an additional class type (not a digit), our dataset will be imbalanced. There will be fewer samples with that label compared to other labels. You may want to \"double count\" (i.e duplicate) the not-a-digit samples in your collected dataset."
      ],
      "metadata": {
        "id": "twnfeBTdwjPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9--R1a9dwjZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4fa170e-11ac-471f-a463-bd7d96085e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_mnist_train_data():\n",
        "#   X_train, Y_train = _data_parser_helper(\"MyDrive/MNIST_580E/MNIST580E_training.csv\")\n",
        "#   return X_train, Y_train\n",
        "\n",
        "# def get_mnist_test_data():\n",
        "#   X_test, Y_test = _data_parser_helper(\"MyDrive/MNIST_580E/MNIST580E_test.csv\")\n",
        "#   return X_test, Y_test\n",
        "\n",
        "transform  = transforms.Compose([\n",
        "    transforms.RandomRotation(degrees = (15)),\n",
        "    transforms.GaussianBlur(3),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "mnist_custom_train = MNIST(True, transform, \"drive/MyDrive/MNIST_580E/MNIST580E_training.csv\")\n",
        "\n",
        "mnist_custom_test = MNIST(False, transform, \"drive/MyDrive/MNIST_580E/MNIST580E_test.csv\")\n",
        "\n",
        "train_len = int(0.8 * len(mnist_custom_train))\n",
        "val_len = len(mnist_custom_train) - train_len\n",
        "train_set, val_set = random_split(mnist_custom_train, [train_len, val_len])\n",
        "\n",
        "train_dataloader = DataLoader(train_set, batch_size=32)\n",
        "val_dataloader = DataLoader(val_set, batch_size=32)"
      ],
      "metadata": {
        "id": "aqOlLJ4XAZ3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the following cell to use your previously trained CNN as a feature extractor. This is an example of [transfer learning](https://en.wikipedia.org/wiki/Transfer_learning).\n",
        "\n",
        "You will need to:\n",
        "- Freeze the layers of convolutional model you trained\n",
        "- Change the final linear layer have an additional output for the additional class.  \n",
        "\n",
        "Here's an example of taking the previously defined LeNet and updating the final layer to have 11 classes instead of 10. This also freezes the other weights in the LeNet.\n",
        "\n",
        "```python\n",
        "# model_conv is a trained LeNet example from above\n",
        "\n",
        "# Freeze the weights of the model\n",
        "# The gradients will not be calculated and the optimizer will not\n",
        "# update the weights\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "num_ftrs = model_conv.fc3.in_features\n",
        "model_conv.fc3 = nn.Linear(num_ftrs, 11)\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Only parameters of final layer are being optimized not the other weights\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001)\n",
        "```\n"
      ],
      "metadata": {
        "id": "mzY-itbyZvtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in cnn_model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "num_ftrs = cnn_model.fc3.in_features\n",
        "cnn_model.fc3 = nn.Linear(num_ftrs, 11)\n",
        "cnn_model = cnn_model.to(device)"
      ],
      "metadata": {
        "id": "nBZbXC8SZv8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the following cell to train the final layer of the convolution. Also calculate the test set performance on this fine-tuned model."
      ],
      "metadata": {
        "id": "6Sp7sQjub7HY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer_conv = torch.optim.Adam(cnn_model.fc3.parameters(), lr=0.001)\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  print(f\"Epoch {i+1}\\n-------------------------------\")\n",
        "  train(train_dataloader, val_dataloader, cnn_model, loss_fn, optimizer_conv, device)\n",
        "\n",
        "PATH = \"drive/MyDrive/MNIST_580E/cnn_model_custom.pth\"\n",
        "torch.save(cnn_model, PATH)"
      ],
      "metadata": {
        "id": "Izl74Ydtb8-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76609820-2794-4479-e992-b43f5f73e511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 3.194286  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 10.6%, Avg Val loss: 3.043304 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 18.3%, Avg Val loss: 2.573497 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.599970  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 18.3%, Avg Val loss: 2.549153 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 37.3%, Avg Val loss: 2.186540 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.148580  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 37.3%, Avg Val loss: 2.167241 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 40.8%, Avg Val loss: 1.885254 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.785805  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 40.8%, Avg Val loss: 1.870120 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 44.4%, Avg Val loss: 1.650572 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.504813  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 45.1%, Avg Val loss: 1.639131 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 54.9%, Avg Val loss: 1.482409 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.329230  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 54.9%, Avg Val loss: 1.475045 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 62.7%, Avg Val loss: 1.374723 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.221208  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 63.4%, Avg Val loss: 1.369981 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 67.6%, Avg Val loss: 1.302907 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.145753  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 67.6%, Avg Val loss: 1.299575 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 69.0%, Avg Val loss: 1.251477 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.089695  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 69.7%, Avg Val loss: 1.248986 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.1%, Avg Val loss: 1.212893 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.045872  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 1.210951 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 74.6%, Avg Val loss: 1.182968 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 1.010123  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 74.6%, Avg Val loss: 1.181404 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 73.9%, Avg Val loss: 1.159125 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.979966  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 73.9%, Avg Val loss: 1.157830 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 73.9%, Avg Val loss: 1.139719 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.953920  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 73.9%, Avg Val loss: 1.138625 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 73.9%, Avg Val loss: 1.123657 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.931057  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 73.9%, Avg Val loss: 1.122716 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 73.9%, Avg Val loss: 1.110178 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.910743  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 73.9%, Avg Val loss: 1.109357 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 73.2%, Avg Val loss: 1.098736 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.892521  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 73.2%, Avg Val loss: 1.098010 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 72.5%, Avg Val loss: 1.088931 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.876051  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 72.5%, Avg Val loss: 1.088282 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 73.2%, Avg Val loss: 1.080465 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.861075  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 73.2%, Avg Val loss: 1.079879 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 73.2%, Avg Val loss: 1.073110 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.847390  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 73.2%, Avg Val loss: 1.072577 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 73.9%, Avg Val loss: 1.066690 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.834832  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 73.9%, Avg Val loss: 1.066201 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 73.9%, Avg Val loss: 1.061063 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Implement*** the following cell to retrain the linear classifiers (LinearSVM and Softmax). Note that you have an extra class as your model should also detect \"not a digit\"."
      ],
      "metadata": {
        "id": "cQyYbK6AuqUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "  \"cuda\" if torch.cuda.is_available()\n",
        "  else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "model = LinearSVM(11, input_dim=784).to(device)\n",
        "loss_fn = torch.nn.MultiMarginLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "num_epochs = 50\n",
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "val_acc_list = []\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  print(f\"Epoch {i+1}\\n-------------------------------\")\n",
        "  train_loss, val_loss, val_acc = train(train_dataloader, val_dataloader, model, loss_fn, optimizer, device)\n",
        "\n",
        "  train_loss_list.extend(train_loss)\n",
        "  val_loss_list.extend(val_loss)\n",
        "  val_acc_list.extend(val_acc)"
      ],
      "metadata": {
        "id": "UKvrkj9uupeC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b119b32e-0b33-4aa3-d749-3582c4e85cc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.867632  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 13.4%, Avg Val loss: 0.906484 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 40.1%, Avg Val loss: 0.641394 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.522251  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 44.4%, Avg Val loss: 0.621962 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 62.0%, Avg Val loss: 0.398343 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.247600  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 62.0%, Avg Val loss: 0.390150 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 62.0%, Avg Val loss: 0.310759 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.160040  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 62.0%, Avg Val loss: 0.307980 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 63.4%, Avg Val loss: 0.275121 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.130440  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 63.4%, Avg Val loss: 0.273498 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 66.9%, Avg Val loss: 0.254298 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.112234  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 66.9%, Avg Val loss: 0.253230 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 66.9%, Avg Val loss: 0.240419 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.100545  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 66.9%, Avg Val loss: 0.239683 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 66.9%, Avg Val loss: 0.229849 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.092195  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 66.9%, Avg Val loss: 0.229263 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 66.9%, Avg Val loss: 0.221382 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.085194  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 66.9%, Avg Val loss: 0.220869 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 66.9%, Avg Val loss: 0.214646 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.079770  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 66.9%, Avg Val loss: 0.214207 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 67.6%, Avg Val loss: 0.208138 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.074982  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 67.6%, Avg Val loss: 0.207742 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 69.0%, Avg Val loss: 0.202792 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.070730  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 69.0%, Avg Val loss: 0.202458 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 69.0%, Avg Val loss: 0.198531 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.067331  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 69.0%, Avg Val loss: 0.198226 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 69.0%, Avg Val loss: 0.194838 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.064164  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 69.0%, Avg Val loss: 0.194548 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 70.4%, Avg Val loss: 0.191530 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.061161  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 70.4%, Avg Val loss: 0.191290 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.1%, Avg Val loss: 0.188585 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.058770  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.1%, Avg Val loss: 0.188329 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.185492 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.056379  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.185253 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.182923 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.054256  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.182739 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 72.5%, Avg Val loss: 0.180917 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.052248  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 72.5%, Avg Val loss: 0.180736 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 73.2%, Avg Val loss: 0.178941 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.050384  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 73.2%, Avg Val loss: 0.178763 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 72.5%, Avg Val loss: 0.176968 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.048503  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 72.5%, Avg Val loss: 0.176788 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.175308 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.046755  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.175195 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.173780 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.045007  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.173657 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.1%, Avg Val loss: 0.172469 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.043372  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.1%, Avg Val loss: 0.172347 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.171059 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.041750  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.1%, Avg Val loss: 0.170920 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 72.5%, Avg Val loss: 0.169815 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.040096  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 72.5%, Avg Val loss: 0.169653 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 72.5%, Avg Val loss: 0.168748 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.038804  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.168641 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.1%, Avg Val loss: 0.167561 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.037404  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.1%, Avg Val loss: 0.167375 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.1%, Avg Val loss: 0.166397 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.036198  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.1%, Avg Val loss: 0.166314 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.1%, Avg Val loss: 0.165470 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.035199  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.1%, Avg Val loss: 0.165312 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.1%, Avg Val loss: 0.164571 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.034163  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.1%, Avg Val loss: 0.164471 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.1%, Avg Val loss: 0.163856 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.033218  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.163744 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.163070 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.032274  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.162952 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.162226 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.031361  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.162134 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.161523 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.030460  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.161402 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.160837 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.029715  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.160770 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.160221 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.028873  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.160135 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.159671 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.028318  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.159593 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.158990 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.027429  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.158931 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.158246 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.026794  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.158184 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.157753 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.026055  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.157704 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.157397 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.025517  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.157341 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.157000 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.024829  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.156949 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.156212 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.024284  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.156139 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.155848 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.023847  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.155816 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.155286 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.023350  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.155214 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.155093 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.022934  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 0.155054 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.1%, Avg Val loss: 0.154623 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.022479  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.1%, Avg Val loss: 0.154579 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.1%, Avg Val loss: 0.154152 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.022124  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.1%, Avg Val loss: 0.154085 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.1%, Avg Val loss: 0.153894 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.021733  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 71.1%, Avg Val loss: 0.153865 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.1%, Avg Val loss: 0.153684 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "  \"cuda\" if torch.cuda.is_available()\n",
        "  else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "num_epochs = 50\n",
        "softmax_model = SoftmaxClassifier(11, input_dim=784).to(device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(softmax_model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  print(f\"Epoch {i+1}\\n-------------------------------\")\n",
        "  train(train_dataloader, val_dataloader, softmax_model, loss_fn, optimizer, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stOW1MLgWYRw",
        "outputId": "135f98ea-2e17-4dcb-f52a-777806a64071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.399756  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 12.0%, Avg Val loss: 2.396536 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 19.0%, Avg Val loss: 2.394117 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.396865  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 19.7%, Avg Val loss: 2.393914 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 25.4%, Avg Val loss: 2.390018 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.392449  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 26.8%, Avg Val loss: 2.389771 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 28.9%, Avg Val loss: 2.385289 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 2.387548  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 28.9%, Avg Val loss: 2.385013 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 31.0%, Avg Val loss: 2.379974 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 2.382293  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 31.7%, Avg Val loss: 2.379664 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 31.0%, Avg Val loss: 2.373942 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 2.376678  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 31.0%, Avg Val loss: 2.373590 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 28.2%, Avg Val loss: 2.367083 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 2.370688  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 28.2%, Avg Val loss: 2.366686 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 29.6%, Avg Val loss: 2.359481 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 2.364279  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 28.9%, Avg Val loss: 2.359049 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 28.9%, Avg Val loss: 2.351205 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 2.357262  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 28.9%, Avg Val loss: 2.350738 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 28.9%, Avg Val loss: 2.342113 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 2.349379  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 29.6%, Avg Val loss: 2.341610 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 31.7%, Avg Val loss: 2.332318 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 2.340483  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 31.7%, Avg Val loss: 2.331792 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 32.4%, Avg Val loss: 2.322222 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 2.330536  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 32.4%, Avg Val loss: 2.321695 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 33.1%, Avg Val loss: 2.312182 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 2.319617  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 33.8%, Avg Val loss: 2.311667 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 35.2%, Avg Val loss: 2.302375 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 2.307985  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 35.2%, Avg Val loss: 2.301876 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 37.3%, Avg Val loss: 2.292813 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 2.295982  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 36.6%, Avg Val loss: 2.292324 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 38.0%, Avg Val loss: 2.283387 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 2.283861  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 38.0%, Avg Val loss: 2.282900 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 37.3%, Avg Val loss: 2.273969 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 2.271710  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 38.0%, Avg Val loss: 2.273477 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 39.4%, Avg Val loss: 2.264491 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 2.259512  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 39.4%, Avg Val loss: 2.263992 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 40.8%, Avg Val loss: 2.254987 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 2.247270  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 40.8%, Avg Val loss: 2.254487 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 41.5%, Avg Val loss: 2.245587 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 2.235087  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 41.5%, Avg Val loss: 2.245095 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 43.7%, Avg Val loss: 2.236462 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 2.223150  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 43.7%, Avg Val loss: 2.235986 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 43.7%, Avg Val loss: 2.227751 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 2.211628  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 43.7%, Avg Val loss: 2.227298 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 44.4%, Avg Val loss: 2.219531 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 2.200591  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 44.4%, Avg Val loss: 2.219104 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 44.4%, Avg Val loss: 2.211816 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 2.190002  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 44.4%, Avg Val loss: 2.211414 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 45.1%, Avg Val loss: 2.204579 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 2.179751  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 45.1%, Avg Val loss: 2.204201 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 46.5%, Avg Val loss: 2.197777 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 2.169704  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 46.5%, Avg Val loss: 2.197420 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 47.9%, Avg Val loss: 2.191362 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 2.159721  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 47.9%, Avg Val loss: 2.191025 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 47.9%, Avg Val loss: 2.185291 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 2.149660  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 47.9%, Avg Val loss: 2.184970 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 49.3%, Avg Val loss: 2.179522 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 2.139377  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 49.3%, Avg Val loss: 2.179215 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 50.0%, Avg Val loss: 2.174017 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 2.128735  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 50.0%, Avg Val loss: 2.173724 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 50.0%, Avg Val loss: 2.168744 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 2.117643  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 50.0%, Avg Val loss: 2.168461 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 50.0%, Avg Val loss: 2.163668 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 2.106108  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 50.0%, Avg Val loss: 2.163395 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 50.7%, Avg Val loss: 2.158761 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 2.094283  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 50.7%, Avg Val loss: 2.158496 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 50.0%, Avg Val loss: 2.153999 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 2.082438  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 50.0%, Avg Val loss: 2.153741 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 50.7%, Avg Val loss: 2.149370 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 2.070854  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 50.0%, Avg Val loss: 2.149119 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 50.0%, Avg Val loss: 2.144874 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 2.059736  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 50.0%, Avg Val loss: 2.144629 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 51.4%, Avg Val loss: 2.140517 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 2.049189  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 51.4%, Avg Val loss: 2.140280 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 51.4%, Avg Val loss: 2.136308 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 2.039253  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 51.4%, Avg Val loss: 2.136079 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 51.4%, Avg Val loss: 2.132252 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 2.029936  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 51.4%, Avg Val loss: 2.132031 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 51.4%, Avg Val loss: 2.128347 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 2.021225  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 51.4%, Avg Val loss: 2.128134 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 51.4%, Avg Val loss: 2.124589 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 2.013094  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 51.4%, Avg Val loss: 2.124383 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 52.8%, Avg Val loss: 2.120970 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 2.005507  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 52.8%, Avg Val loss: 2.120771 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 53.5%, Avg Val loss: 2.117481 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 1.998418  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 53.5%, Avg Val loss: 2.117289 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 54.2%, Avg Val loss: 2.114116 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 1.991779  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 54.2%, Avg Val loss: 2.113929 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 54.2%, Avg Val loss: 2.110865 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 1.985545  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 54.2%, Avg Val loss: 2.110684 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 54.9%, Avg Val loss: 2.107723 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 1.979672  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 54.9%, Avg Val loss: 2.107547 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 54.9%, Avg Val loss: 2.104682 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 1.974121  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 54.9%, Avg Val loss: 2.104512 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 54.2%, Avg Val loss: 2.101739 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 1.968858  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 54.2%, Avg Val loss: 2.101573 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 54.2%, Avg Val loss: 2.098888 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 1.963855  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 54.2%, Avg Val loss: 2.098727 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 54.2%, Avg Val loss: 2.096125 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 1.959087  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 54.2%, Avg Val loss: 2.095968 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 54.9%, Avg Val loss: 2.093445 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Implement*** the following cell to retrain your previously defined CNN model."
      ],
      "metadata": {
        "id": "dEKnIfUnu0DF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\" if torch.cuda.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "cnn_model = CNN(11).to(device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.01)\n",
        "num_epochs = 50\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  print(f\"Epoch {i+1}\\n-------------------------------\")\n",
        "  train(train_dataloader, val_dataloader, cnn_model, loss_fn, optimizer, device)\n",
        "\n",
        "PATH = \"drive/MyDrive/MNIST_580E/cnn_model_retrained.pth\"\n",
        "torch.save(cnn_model, PATH)"
      ],
      "metadata": {
        "id": "_ovyuauM65eA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "46aa2fd9-8afb-4946-b34e-07aa2579eed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.398932  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 16.2%, Avg Val loss: 2.380817 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 7.7%, Avg Val loss: 2.369714 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.376940  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 10.6%, Avg Val loss: 2.292456 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 28.2%, Avg Val loss: 1.862935 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.934204  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 29.6%, Avg Val loss: 1.776877 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 52.1%, Avg Val loss: 1.397007 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.190753  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 52.8%, Avg Val loss: 1.301425 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 65.5%, Avg Val loss: 1.121237 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.581115  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 62.0%, Avg Val loss: 1.133834 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 59.9%, Avg Val loss: 1.272448 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.356679  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 59.9%, Avg Val loss: 1.269560 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 74.6%, Avg Val loss: 0.812766 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.483595  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 69.0%, Avg Val loss: 0.907857 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 73.9%, Avg Val loss: 0.837195 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.331659  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 75.4%, Avg Val loss: 0.824237 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 77.5%, Avg Val loss: 0.884210 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.077183  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 76.8%, Avg Val loss: 0.867657 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 78.9%, Avg Val loss: 0.889136 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.079611  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 77.5%, Avg Val loss: 0.927559 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 78.2%, Avg Val loss: 0.991384 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.076175  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 82.4%, Avg Val loss: 0.974766 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 72.5%, Avg Val loss: 1.251270 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.169246  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 73.2%, Avg Val loss: 1.255149 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 71.8%, Avg Val loss: 1.350862 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.187988  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 77.5%, Avg Val loss: 1.415490 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 78.2%, Avg Val loss: 1.217413 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.311492  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 74.6%, Avg Val loss: 1.413546 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 80.3%, Avg Val loss: 0.777888 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.177550  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 80.3%, Avg Val loss: 0.789869 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 76.1%, Avg Val loss: 0.894734 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.027416  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 75.4%, Avg Val loss: 0.949454 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 74.6%, Avg Val loss: 0.963291 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.080449  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 76.8%, Avg Val loss: 0.931895 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 82.4%, Avg Val loss: 0.880043 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.062699  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 81.7%, Avg Val loss: 0.898946 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 80.3%, Avg Val loss: 0.955899 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.050658  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 80.3%, Avg Val loss: 0.947292 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 81.0%, Avg Val loss: 0.990420 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.004408  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 81.0%, Avg Val loss: 1.006219 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 81.7%, Avg Val loss: 1.061557 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.017818  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 81.7%, Avg Val loss: 1.051881 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 0.991888 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.000506  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 0.993113 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.003695 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.000225  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.005013 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.067437 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.000748  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.071578 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.066280 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.000087  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.067011 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.084454 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.000072  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.085605 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.105775 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.000069  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.106775 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.9%, Avg Val loss: 1.122497 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.000065  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.9%, Avg Val loss: 1.123300 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.136168 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.000061  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.136851 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.148161 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.000057  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.148775 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.159255 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.000054  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.159828 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.169594 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.000051  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.170128 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.179320 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.000048  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.179823 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.188491 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.000046  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.188966 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.197197 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.000043  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.197650 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.205537 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.000041  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.205971 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.213516 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.000039  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.213931 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.221184 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.000037  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.221582 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.9%, Avg Val loss: 1.228542 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.000035  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.9%, Avg Val loss: 1.228927 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.9%, Avg Val loss: 1.235657 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.000033  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.9%, Avg Val loss: 1.236028 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.9%, Avg Val loss: 1.242520 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.000032  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.9%, Avg Val loss: 1.242876 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.9%, Avg Val loss: 1.249138 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.000030  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.9%, Avg Val loss: 1.249483 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.9%, Avg Val loss: 1.255514 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.000029  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.9%, Avg Val loss: 1.255845 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.9%, Avg Val loss: 1.261656 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.000027  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.9%, Avg Val loss: 1.261975 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.9%, Avg Val loss: 1.267656 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.000026  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.9%, Avg Val loss: 1.267968 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.9%, Avg Val loss: 1.273458 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.000025  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.9%, Avg Val loss: 1.273758 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.9%, Avg Val loss: 1.279089 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.000024  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.9%, Avg Val loss: 1.279382 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.9%, Avg Val loss: 1.284580 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.000023  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.9%, Avg Val loss: 1.284864 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.289917 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.000022  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.290192 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.295095 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.000021  [   32/  568]\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.295364 \n",
            "\n",
            "Val Error: \n",
            " Accuracy: 85.2%, Avg Val loss: 1.300126 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** a visualization of the [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) on the **new** combined test set with the predictions from your LinearSVM, Softmax, and CNN. You should use a single `Matplotlib` figure with multiple subplots on a single row.\n",
        "\n",
        "[See here for examples on using plt.subplots.](https://matplotlib.org/stable/gallery/subplots_axes_and_figures/subplots_demo.html)"
      ],
      "metadata": {
        "id": "dhtx446K5FNI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q_rCWjbVupm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cells, write a short report about the performance of your models. You should include the effects of new data, data augmentation, and different architectures. You should also include visualizations as you did before."
      ],
      "metadata": {
        "id": "xxv4Zf51wSpx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HnMP5lDUwTd4"
      }
    }
  ]
}