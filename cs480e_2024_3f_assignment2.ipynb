{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohanbing/1brc_rust/blob/main/cs480e_2024_3f_assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2\n",
        "**Due November 10th, 11:59 PM**\n",
        "\n",
        "GitHub Classroom assignment link:\n",
        "https://classroom.github.com/a/_Q_ALLFP.\n",
        "Instructions for how to connect your Google Colab to GitHub are [here](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb)."
      ],
      "metadata": {
        "id": "tUheapJCOaxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name: Aditya Mohan<br>\n",
        "B-Number: B00929373<br>\n",
        "Email: amohan2@binghamton.edu"
      ],
      "metadata": {
        "id": "26iemMN3qq0v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following assignment,\n",
        "you will be implementing functions and their analytical derivatives to train linear classifiers and neural networks on the MNIST dataset.\n",
        "You are allowed and expected to use NumPy.\n",
        "**You are not allowed to use PyTorch.**\n",
        "\n",
        "Tasks that need to be completed are indicated with a\n",
        "right-pointing triangle (&#9658;)\n",
        "or clearly stated in the experiments section.\n",
        "\n",
        "<!--\n",
        "The experiments section for each classifier also need to be implemented. You should follow the instructions above the cell. You may also add additional cells.\n",
        "-->\n",
        "\n",
        "Cells that need to be run to set up the appropriate infrastructure are indicated with a downward-pointing triangle (&#9660;).\n",
        "Such cells do not need to be modified.\n",
        "Make sure you have run the previous cells before running the current cell, or you may get an error.\n",
        "\n",
        "DEBUGGING TIP: Do not use a random seed for any random numbers.\n",
        "This is so that your debugging output is deterministic.\n",
        "Also, make sure that your code can work for trivially-simple cases.\n",
        "For example, make sure that it can work with one sample, one feature, and one class.\n",
        "Then run with such an input and configuration.\n",
        "You can then easily manually verify that your code is working.\n",
        "\n",
        "Submission will be via GitHub Classroom. **You are required to have at least 10 commits for this assignment.**"
      ],
      "metadata": {
        "id": "jqLULe5pxwpH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import statements\n",
        "\n",
        "&#9660;Run the cell below to import the packages needed for the code below.\n",
        "Most other packages are also okay,\n",
        "but you must ask first."
      ],
      "metadata": {
        "id": "Hnw_h7A1Orc9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JLEavoS9O9g-"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Backpropagation"
      ],
      "metadata": {
        "id": "VIBNL5SMPMt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Linear Transforms\n",
        "\n",
        "A linear classifier computes a vector of scores for a single sample,\n",
        "with one score for each class.\n",
        "Let $D$ be the number of features and\n",
        "$M$ be the number of classes.\n",
        "Then the score $y_{i,k}$ for the $k$-th class of the $i$-th sample\n",
        "is computed by:\n",
        "\n",
        "$$\n",
        "y_{i,k} = \\sum_{j = 1}^{D} w_{j,k}x_{i,j} + b_k\n",
        "$$\n",
        "\n",
        "where $w_{j,k}$ is the $j$-th weight for the $k$-th class,\n",
        "$x_{i,j}$ is the $j$-th feature for the $i$-th sample,\n",
        "and $b_k$ is the bias term for class $k$.\n",
        "Note that the we are using the *second* index $k$\n",
        "of $w_{j,k}$ to denote the class, and the *first* index $j$ to denote the $j$-th weight of that class.\n",
        "\n",
        "During training,\n",
        "we often group $N$ samples into what is called a *minibatch*,\n",
        "and process the whole minibatch at once.\n",
        "This is more efficient,\n",
        "and also improves the gradient descent convergence.\n",
        "Letting each sample be a row in the $N\\times D$ matrix $X$,\n",
        "we can then write this as\n",
        "\n",
        "$$\n",
        "Y = XW + B\n",
        "$$\n",
        "\n",
        "where $W$ is the $D \\times M$ weight matrix.\n",
        "The weights for each class form a column in $W$.\n",
        "All the biases have been collected into a single matrix $B$.\n",
        "\n",
        "Although the above can work,\n",
        "we can turn it into a single matrix multiplication\n",
        "via the &ldquo;bias trick&rdquo;,\n",
        "which adds an extra dummy feature in the input sample\n",
        "that is always hard-coded to 1,\n",
        "and then adding an extra weight that is the bias term.\n",
        "\n",
        "$$\n",
        "y_{i,k} = \\sum_{j = 1}^{D + 1} w_{j,k}x_{i,j}, \\ \\ \\text{with}\\ \\ x_{i,D+1} = 1\n",
        "$$\n",
        "\n",
        "The scores for a whole minibatch can now be computed via a standard matrix\n",
        "multiplication.\n",
        "\n",
        "$$\n",
        "Y = X'W'\n",
        "$$\n",
        "\n",
        "where $X'$ and $W'$ are the augmented sample and weight matrices.\n",
        "This transformation forms the basis of a linear, fully-connected (also called &ldquo;dense&rdquo;) layer in a neural network."
      ],
      "metadata": {
        "id": "VhFZKNmUXzt4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9654; Implement `linear_forward(X, W)` in the cell below to perform the forward pass of\n",
        "a single linear layer on a batch of samples $X$,\n",
        "using the weights from $W$.\n",
        "The matrix $W$ has already had the bias added to it,\n",
        "but $X$ has not been augmented in any way."
      ],
      "metadata": {
        "id": "KszunLwwRJqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_forward(X, W):\n",
        "    \"\"\"\n",
        "    Computes the forward pass for a linear transformation.\n",
        "\n",
        "    Consider a linear layer that accepts inputs with D features,\n",
        "    and has M neurons.  Assume that our minibatch size\n",
        "    is N.  In other words, we wish to process N samples at once.\n",
        "\n",
        "    The input X has shape (N, D) and contains a minibatch of N\n",
        "    samples, where each sample X[i] has shape (D).  Each sample\n",
        "    will be transformed to an output vector of dimension M.\n",
        "\n",
        "    Inputs:\n",
        "    - X: A numpy array containing input data, of shape (N, D)\n",
        "    - W: A numpy array of weights, of shape (D+1, M)\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - out: output, of shape (N, M)\n",
        "    - cache: (X, W)\n",
        "\n",
        "    The returned (X, W) is redundant, but makes the training code\n",
        "    more concise.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    out = None # Initialize the out variable.\n",
        "\n",
        "    #\n",
        "    # PUT YOUR CODE BELOW: Below, implement the linear forward pass. Store the result in out.\n",
        "    # Make sure to do the bias trick!\n",
        "    #\n",
        "    N, D = X.shape\n",
        "    bias_trick_feature = np.ones((N, 1))\n",
        "    X = np.concatenate((X, bias_trick_feature), axis=1)\n",
        "    out = np.matmul(X, W)\n",
        "\n",
        "    # The lines below do not need to be changed.\n",
        "    cache = (X, W)\n",
        "\n",
        "    return out, cache"
      ],
      "metadata": {
        "id": "fsl6QHm_PJdi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement `linear_backward(d_upstream, cache)` that returns the downstream analytical gradients with respect to $X$ and $W$,\n",
        "given the upstream gradients and $X$ and $W$.\n",
        "See here for details on how to [backpropagate through a linear layer.](https://web.eecs.umich.edu/~justincj/teaching/eecs442/notes/linear-backprop.html)\n",
        "You do not need to understand the derivation, thought it is good practice.\n",
        "But you do need to use the result."
      ],
      "metadata": {
        "id": "VLnk9xwpRf2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_backward(d_upstream, cache):\n",
        "    \"\"\"\n",
        "    Computes the backward pass for an linear layer.\n",
        "\n",
        "    Inputs:\n",
        "    - d_upstream: Upstream derivative, of shape (N, M)\n",
        "    - cache: Tuple of:\n",
        "      - X: Input data, of shape (N, D)\n",
        "      - W: Weights, of shape (D+1, M)\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - dX: Gradient of the output of this layer with respect to X, of shape (N, D).\n",
        "          This is the downstream gradient.\n",
        "    - dW: Gradient with respect to W, of shape (D+1, M)\n",
        "    \"\"\"\n",
        "    X, W = cache\n",
        "    dX, dW = None, None\n",
        "\n",
        "    # PUT YOUR CODE BELOW: Implement the linear backward pass by calculating the\n",
        "    # gradient with respect to the cached inputs X and W. Store them in the\n",
        "    # variables dX and dW.\n",
        "\n",
        "    dX = np.matmul(d_upstream, W.T)\n",
        "    dW = np.matmul(X.T, d_upstream)\n",
        "\n",
        "    # The lines below do not need to be changed.\n",
        "\n",
        "    return dX, dW"
      ],
      "metadata": {
        "id": "41ac6dd5TSEX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Checking Gradients with Finite Differences\n",
        "\n",
        "Numerical code can be difficult to debug.\n",
        "The general approach is to compare the answer given\n",
        "by your code to the answer obtained from some other technique.\n",
        "A finite difference is a numerical approximation to the derivative which can be used to check your gradients.\n",
        "Because it is only an approximation,\n",
        "you do not use it for actual training,\n",
        "however.\n",
        "\n",
        "The multi-variate central finite difference for a function $f(x,y)$ is given by:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial  f}{\\partial x} = \\frac{f(x+h, y)-f(x-h, y)}{2h}\n",
        "$$\n",
        "\n",
        "and\n",
        "\n",
        "$$\n",
        "\\frac{\\partial  f}{\\partial y} = \\frac{f(x, y+h)-f(x, y-h)}{2h}\n",
        "$$\n",
        "\n",
        "The above pattern holds for functions with more variables.\n",
        "For our purposes,\n",
        "an $h$ of about $10^{-9}$ should be adequate."
      ],
      "metadata": {
        "id": "lk1XRA9LSKml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; In the next cell,\n",
        "implement the `finite_difference_linear(d_upstream, cache, h)` function.\n",
        "This function is analogous to `linear_backward()`\n",
        "in that it computes the derivative matrices\n",
        "$\\frac{\\partial L}{\\partial X}$ and\n",
        "$\\frac{\\partial L}{\\partial W}$,\n",
        "given an upstream gradient,\n",
        "but it actually estimates the local gradient\n",
        "using a finite difference.\n",
        "The `h` parameter corresponds to $h$ above;\n",
        "the other parameters are the same as for `linear_backward()`.\n",
        "\n",
        "Recall that the downstream gradient can be computed from\n",
        "the local gradient and upstream gradient by applying the\n",
        "chain rule.\n",
        "In this case,\n",
        "we need the multivariable chain rule,\n",
        "because the loss is a function of the output from layer,\n",
        "which we will call matrix $Y$,\n",
        "and $L$ potentially depends on\n",
        "every element $y_{k,l}$ of $Y$.\n",
        "(Any non-singleton matrix is multivariable by definition.)\n",
        "In particular,\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial x_{i,j}}\n",
        "= \\sum^{N}_{k=1}\\sum^{M}_{l=1} \\frac{\\partial L}{\\partial y_{k,l}}\n",
        "\\frac{\\partial y_{k,l}}{\\partial x_{i,j}}\n",
        "$$\n",
        "\n",
        "where the $\\frac{\\partial L}{\\partial y_{k,l}}$ form the upstream\n",
        "gradient and the $\\frac{\\partial y_{k,l}}{\\partial x_{i,j}}$ form the local gradient.\n",
        "(Note that $\\frac{\\partial y_{k,l}}{\\partial x_{i,j}} = 0$ in our case when $k \\neq i$,\n",
        "because a given sample does not affect the output for other samples\n",
        "in the same minibatch.\n",
        "This fact could be used to optimize the code,\n",
        "but there is no requirement to do so for this assignment.\n",
        "The notes from Justin Johson explain how to do this.)\n",
        "This simplifies nicely as the gradient for each variable in the matrix is the sum of the products of each upstream partial derivative\n",
        "$\\frac{\\partial L}{\\partial y_{k,l}}$\n",
        "from `d_upstream` and the corresponding element in the finite difference matrix.\n",
        "(This operation is analogous to the dot product,\n",
        "except it is performed on matrices instead of vectors,\n",
        "and is called the\n",
        "[Frobenius product](https://en.wikipedia.org/wiki/Frobenius_inner_product).)"
      ],
      "metadata": {
        "id": "Je8LC4OnT-rU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def finite_difference_linear(d_upstream, cache, h):\n",
        "    '''\n",
        "    Computes the numerical gradient for a linear layer\n",
        "\n",
        "    Inputs:\n",
        "    - d_upstream: Upstream derivative, of shape (N, M)\n",
        "    - cache: Tuple of:\n",
        "      - X: Input data, of shape (N, D)\n",
        "      - W: Weights, of shape (D+1, M)\n",
        "    - h: The h to use in the finite difference.\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - dX: Gradient with respect to X, of shape (N, D).  This is the downstream\n",
        "          gradient.\n",
        "    - dW: Gradient with respect to W, of shape (D+1, M)\n",
        "    '''\n",
        "\n",
        "    dX = None\n",
        "    dW = None\n",
        "\n",
        "    # PUT YOUR CODE BELOW: Implement the finite difference for the linear\n",
        "    # function.  Return the gradient at input (X,W) w.r.t to x and w.\n",
        "    X, W = cache\n",
        "    finite_diff_dy_dx = (linear_forward(X+h, W)[0] - linear_forward(X-h, W)[0])/ (2*h)\n",
        "    dX = np.dot(d_upstream, finite_diff_dy_dx)\n",
        "\n",
        "    finite_diff_dw_dx = (linear_forward(X, W+h)[0] - linear_forward(X, W-h)[0])/ (2*h)\n",
        "    dW = np.dot(d_upstream, finite_diff_dw_dx)\n",
        "\n",
        "    # The lines below do not need to be changed.\n",
        "    return dX, dW"
      ],
      "metadata": {
        "id": "HvUDtyAWUx7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9660; Run this cell to do a gradient check to test the analytical gradients from the `linear_backward()` function with `finite_difference_linear()`."
      ],
      "metadata": {
        "id": "iTNHRnDDvCMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_check_linear():\n",
        "    N = 16\n",
        "    D = 4\n",
        "    C = 3\n",
        "\n",
        "    test_weight = np.random.random((D+1, C))\n",
        "    test_input = np.random.random((N, D))\n",
        "    dout = np.random.random((N, C))\n",
        "\n",
        "    cache = (test_input, test_weight)\n",
        "\n",
        "    grad_x_numerical, grad_w_numerical = finite_difference_linear(dout, cache, 1E-9)\n",
        "    grad_x_analytical, grad_w_analytical = linear_backward(dout, cache)\n",
        "\n",
        "    check_input_gradient = np.allclose(grad_x_numerical, grad_x_analytical)\n",
        "    check_weight_gradient = np.allclose(grad_w_numerical, grad_w_analytical)\n",
        "\n",
        "    if not check_input_gradient:\n",
        "        print(\"The gradient with respect to x failed\")\n",
        "\n",
        "    if not check_weight_gradient:\n",
        "        print(\"The gradient respect to w failed\")\n",
        "    print()\n",
        "    print(\"gradient check for linear passed!\")\n",
        "\n",
        "gradient_check_linear()"
      ],
      "metadata": {
        "id": "jvmbfkfRPSZX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "e22a3800-d36b-46b9-f685-f28c0ef192c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "shapes (16,3) and (16,3) not aligned: 3 (dim 1) != 16 (dim 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-dbe5edb1ad12>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradient check for linear passed!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mgradient_check_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-dbe5edb1ad12>\u001b[0m in \u001b[0;36mgradient_check_linear\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mgrad_x_numerical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_w_numerical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinite_difference_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1E-9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mgrad_x_analytical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_w_analytical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-4b3916536c35>\u001b[0m in \u001b[0;36mfinite_difference_linear\u001b[0;34m(d_upstream, cache, h)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mfinite_diff_dy_dx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlinear_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlinear_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mdX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_upstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinite_diff_dy_dx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mfinite_diff_dw_dx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlinear_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlinear_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (16,3) and (16,3) not aligned: 3 (dim 1) != 16 (dim 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Linear Classifiers\n",
        "\n",
        "In this section,\n",
        "we will build upon the previously implemented layer to\n",
        "create linear classifiers.\n",
        "We will train them on high-dimensional real world data."
      ],
      "metadata": {
        "id": "i1DiweHpU-_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 MNIST Dataset\n",
        "\n",
        "The dataset we will use is MNIST,\n",
        "a set of images of handwritten digits compiled by the National Institute of Standards and Technology (NIST).\n",
        "This dataset is widely used as a an example for machine learning algorithms for image classification.\n",
        "The images are 28x28 pixels with a single grayscale channel ranging from 0 to 255.\n",
        "\n",
        "Data sets are typically split into\n",
        "[training, validation, and test sets](https://en.wikipedia.org/wiki/Training,_validation,_and_test_data_sets).\n",
        "The training set is used to adjust the weights in the model via\n",
        "gradient descent.\n",
        "The validation set is used during training to evaluate\n",
        "the progress of the training,\n",
        "and thus to\n",
        "[select the best model](https://en.wikipedia.org/wiki/Model_selection).\n",
        "The gradient is not computed when using the validation set,\n",
        "thus it does not take part in the gradient descent.\n",
        "The test set is used to evaluate\n",
        "the final results after training.\n",
        "The distinction between the\n",
        "validation and test set is that the validation set\n",
        "can be used to adjust hyperparameters (such as learning rate and model size),\n",
        "and to prevent overfitting, etc.,\n",
        "but the test set cannot be used except to evaluate the final results.\n",
        "\n",
        "You will be using 20,000 samples from the original training dataset for our next set of experiments,\n",
        "and the 10,000 sample test set.\n",
        "MNIST only splits into two sets, so we will use the test set as\n",
        "the validation set."
      ],
      "metadata": {
        "id": "38HrO_eBXjrh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9660; Run the following cell to define some helper functions for loading the MNIST data."
      ],
      "metadata": {
        "id": "dU3af5u3vY2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads and parses CSV file.\n",
        "# Each image is a row in the CSV file.  The first column is the label,\n",
        "# while the rest of the row is the image, stretched out.\n",
        "# Returns a 2-D array containing the images, and a 1-D array\n",
        "# with the labels.  In the image array,\n",
        "# each row is an image.  Pixel values are from 0 to 255.\n",
        "def mnist_data_parser_helper(csv_file_name):\n",
        "    X = []\n",
        "    Y = []\n",
        "    with open(csv_file_name,'r') as _file:\n",
        "        csv_reader = csv.reader(_file, delimiter=\",\")\n",
        "        for row in csv_reader:\n",
        "            Y.append(int(row[0])) # The label\n",
        "            X.append([int(i) for i in row[1:]]) # The image.\n",
        "    return (np.array(X, dtype='uint8'), np.array(Y, dtype='uint8'))\n",
        "\n",
        "def get_mnist_train_data():\n",
        "    X_train, Y_train = mnist_data_parser_helper(\"sample_data/mnist_train_small.csv\")\n",
        "    return X_train, Y_train\n",
        "\n",
        "def get_mnist_test_data():\n",
        "    X_test, Y_test = mnist_data_parser_helper(\"sample_data/mnist_test.csv\")\n",
        "    return X_test, Y_test"
      ],
      "metadata": {
        "id": "y6p9vHGhfBzg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9660; Run the following cell to visualize some samples from the MNIST dataset."
      ],
      "metadata": {
        "id": "nsEncnA3vh9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = get_mnist_train_data()\n",
        "\n",
        "# Visualize some examples from the dataset.\n",
        "# We show a few examples of training images from each class.\n",
        "num_classes = 10\n",
        "samples_per_class = 7\n",
        "\n",
        "for cls in range(num_classes):\n",
        "    # Find the indices of all the digits that match cls.\n",
        "    idxs = np.flatnonzero(y_train == cls)\n",
        "    # Pick samples_per_class samples of those indices.\n",
        "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
        "    for i, idx in enumerate(idxs):\n",
        "        plt_idx = i*num_classes + cls + 1\n",
        "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
        "        plt.imshow(x_train[idx].reshape(28,28), cmap='gray')\n",
        "        plt.axis('off')\n",
        "        if i == 0:\n",
        "            plt.title(cls)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "21II-zCpe-ER",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "e3742cf1-5ff5-40bc-f38c-1eaeaa0673a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 70 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGYCAYAAADfkuFKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOy9d3hcV53//5quKZqiGfXeJasXy7bcSzpxSAIJIQGSEAhhIcDCLsuyfFkCCWHZXZYFdmlLCJCEFAg4ie3EjuMi25JtWbIsWb333mdGmvb7w797sdxiO5ZmbN/X8/iJc2dkfc7Mvee8z6cdmc/n8yEhISEhISFxwyL3twESEhISEhIS/kUSAxISEhISEjc4khiQkJCQkJC4wZHEgISEhISExA2OJAYkJCQkJCRucCQxICEhISEhcYMjiQEJCQkJCYkbHEkMSEhISEhI3OBIYkBCQkJCQuIGRxIDEhISEhISNzhLLgbm5ub4+te/TlRUFFqtlhUrVrBr166lNuMDMzMzw7e//W1uvfVWQkJCkMlk/Pa3v/W3WZfN0aNH+cIXvkBWVhZ6vZ64uDjuu+8+mpqa/G3aZVFXV8dHP/pRkpKS0Ol02Gw21q1bxxtvvOFv0z4wTz/9NDKZjOzsbH+bclns3bsXmUx23j/l5eX+Nu+KOH78OFu3biUkJASdTkd2djb//d//7W+zLpmHH374gt+JTCajt7fX3yZeMs3NzXzsYx8jJiYGnU5HRkYGTz31FHa73d+mXTaVlZXceuutGI1GgoODufnmm6murl5SG5RL+ts4fTO+9tprfPnLXyY1NZXf/va33H777bz33nusWbNmqc25YkZGRnjqqaeIi4sjLy+PvXv3+tukK+IHP/gBBw8e5KMf/Si5ubkMDAzw05/+lMLCQsrLy6+ZBaizs5Pp6Wk+9alPERUVhd1u509/+hNbt27lF7/4BZ/97Gf9beIV0dPTwzPPPINer/e3KVfMk08+yfLlyxdcS0lJ8ZM1V84777zDnXfeSUFBAd/61rcwGAy0trbS09Pjb9Mumccff5wtW7YsuObz+fjc5z5HQkIC0dHRfrLs8uju7qakpASTycQXvvAFQkJCOHz4MN/+9reprKzkr3/9q79NvGSOHz/OmjVriI2N5dvf/jZer5f/+Z//Yf369Rw5coT09PSlMcS3hFRUVPgA3w9/+EPxmsPh8CUnJ/tWrVq1lKZ8YJxOp6+/v9/n8/l8R48e9QG+5557zr9GXQEHDx70zc3NLbjW1NTk02g0vgcffNBPVl0d3G63Ly8vz5eenu5vU66Y+++/37dp0ybf+vXrfVlZWf4257J47733fIDv1Vdf9bcpH5jJyUlfeHi47+677/Z5PB5/m3NVOXDggA/wPf300/425ZJ5+umnfYCvtrZ2wfVPfvKTPsA3NjbmJ8sun9tvv91nsVh8IyMj4rW+vj6fwWDw3XPPPUtmx5KGCV577TUUCsWCXVpQUBCf/vSnOXz4MN3d3UtpzgdCo9EQERHhbzM+MKWlpajV6gXXUlNTycrKor6+3k9WXR0UCgWxsbFMTEz425QrYv/+/bz22mv813/9l79N+cBMT0/jdrv9bcYV8+KLLzI4OMjTTz+NXC5ndnYWr9frb7OuCi+++CIymYyPf/zj/jblkpmamgIgPDx8wfXIyEjkcvk5c1ogc+DAAbZs2YLVahWvRUZGsn79et58801mZmaWxI4lFQNVVVWkpaVhNBoXXC8pKQFY8hiJxPnx+XwMDg5is9n8bcplMzs7y8jICK2trfzoRz9ix44dbN682d9mXTYej4cvfvGLPPbYY+Tk5PjbnA/EI488gtFoJCgoiI0bN3Ls2DF/m3TZ7N69G6PRSG9vL+np6RgMBoxGI0888QROp9Pf5l0xLpeLV155hdLSUhISEvxtziWzYcMGAD796U9TXV1Nd3c3L7/8Mv/7v//Lk08+eU2F1ebm5tBqtedc1+l0zM/PU1tbuyR2LGnOQH9/P5GRkedcF6719fUtpTkSF+CFF16gt7eXp556yt+mXDZf/epX+cUvfgGAXC7nnnvu4ac//amfrbp8fv7zn9PZ2cnu3bv9bcoVo1aruffee7n99tux2WycOnWKf//3f2ft2rUcOnSIgoICf5t4yTQ3N+N2u7nrrrv49Kc/zfe//3327t3LT37yEyYmJnjppZf8beIV8fbbbzM6OsqDDz7ob1Mui1tvvZXvfve7PPPMM2zbtk28/s1vfpPvfe97frTs8klPT6e8vByPx4NCoQBgfn6eiooKgCVL6lxSMeBwONBoNOdcDwoKEl+X8C8NDQ383d/9HatWreJTn/qUv825bL785S/zkY98hL6+Pl555RU8Hg/z8/P+NuuyGB0d5f/9v//Ht771LUJDQ/1tzhVTWlpKaWmp+P9bt27lIx/5CLm5uXzjG99g586dfrTu8piZmcFut/O5z31OrB645557mJ+f5xe/+AVPPfUUqampfrby8nnxxRdRqVTcd999/jblsklISGDdunXce++9WK1W3nrrLZ555hkiIiL4whe+4G/zLpnPf/7zPPHEE3z605/mH//xH/F6vXzve9+jv78fWMJ1ccmyE3w+X1ZWlm/Tpk3nXK+rq/MBvp///OdLac5V41pOIDyT/v5+X1JSki82NtbX29vrb3OuCjfddJNv+fLlPq/X629TLpnPfe5zvpSUlAWJnddiAuGF+NjHPuZTq9U+t9vtb1MumaysLB/g27dv34Lr+/bt8wG+559/3k+WXTnT09M+nU7n+9CHPuRvUy6bl156yafVan3d3d0Lrj/88MM+nU63IBnvWuCf//mffSqVygf4AF9xcbHvm9/8pg/wvf7660tiw5LmDERGRopq50yEa1FRUUtpjsQZTE5OcttttzExMcHOnTuvm+/iIx/5CEePHr1m+iY0Nzfzy1/+kieffJK+vj46Ojro6OjA6XTicrno6OhgbGzM32Z+IGJjY5mfn2d2dtbfplwywvNwdsJaWFgYAOPj40tu0wflL3/5C3a7/ZoLEQD8z//8DwUFBcTExCy4vnXrVux2O1VVVX6y7Mp4+umnGRwc5MCBA9TU1HD06FExQTUtLW1JbFhSMZCfn09TU5OYCSogxEby8/OX0hyJ/x+n08mdd95JU1MTb775JsuWLfO3SVcNwcU2OTnpZ0sujd7eXrxeL08++SSJiYnin4qKCpqamkhMTLwmcznOpK2tjaCgIAwGg79NuWSKioqAc+O3Qp7TtRjOeeGFFzAYDGzdutXfplw2g4ODeDyec667XC6Aa7JyxWKxsGbNGjFhePfu3cTExJCRkbEkv39JxcBHPvIRPB4Pv/zlL8Vrc3NzPPfcc6xYsYLY2NilNEeC01nr999/P4cPH+bVV19l1apV/jbpihgaGjrnmsvl4ne/+x1arfaaETjZ2dm8/vrr5/zJysoiLi6O119/nU9/+tP+NvOSGB4ePufaiRMn2LZtGzfffDNy+bXTDV2Iqf/f//3fguu//vWvUSqVYnb7tcLw8DC7d+/m7rvvRqfT+ducyyYtLY2qqqpzPH4vvfQScrmc3NxcP1l2dXj55Zc5evQoX/7yl5fsOVnSBMIVK1bw0Y9+lG984xsMDQ2RkpLC888/T0dHxzkP2bXAT3/6UyYmJsTdwRtvvCF2I/viF7+IyWTyp3mXxFe/+lW2bdvGnXfeydjYGH/4wx8WvP7QQw/5ybLL4/HHH2dqaop169YRHR3NwMAAL7zwAg0NDfzHf/zHNbMLtdlsfPjDHz7nutBr4HyvBSr3338/Wq2W0tJSwsLCOHXqFL/85S/R6XQ8++yz/jbvsigoKODRRx/lN7/5DW63m/Xr17N3715effVVvvGNb1xzYbWXX34Zt9t9TYYIAP7hH/6BHTt2sHbtWr7whS9gtVp588032bFjB4899tg19X3s37+fp556iptvvhmr1Up5eTnPPfcct956K1/60peWzpAlyUw4A4fD4fva177mi4iI8Gk0Gt/y5ct9O3fuXGozrgrx8fFiwsfZf9rb2/1t3iWxfv36C47BD7fHFfPSSy/5tmzZ4gsPD/cplUqfxWLxbdmyxffXv/7V36ZdFa7FBMIf//jHvpKSEl9ISIhPqVT6IiMjfQ899JCvubnZ36ZdEfPz875//dd/9cXHx/tUKpUvJSXF96Mf/cjfZl0RK1eu9IWFhV1TSZxnU1FR4bvtttt8ERERPpVK5UtLS/M9/fTTPpfL5W/TLouWlhbfzTff7LPZbD6NRuPLyMjwff/73z+nM+xiI/P5fL6lkx4SEhISEhISgca1E7STkJCQkJCQWBQkMSAhISEhIXGDI4kBCQkJCQmJGxxJDEhISEhISNzgSGJAQkJCQkLiBkcSAxISEhISEjc4l9x0SCaTLaYdV5WLVUteL+OA62cs18s44PoZy/UyDrh+xnK9jAOun7FcL+MAyTMgISEhISFxwyOJAQkJCQkJiRucJT2bQEJCQuJ6Rq1WYzAYiIiIQK1WA6ePbNbpdHi9Xg4ePCieZSIhEUgEnBhQKBRiHMbn8+H1et831hFIyGQyZDIZcrn8mrX/fFwLYxA+92v5/pG4dpHJZBgMBuLi4lizZg3BwcEA3H777YSHh+NyuXjyySclMSARkASMGLBYLERHR/OlL32JxMREoqKiePvttzly5AgvvfSSv827ZFatWsXWrVvZvHkzdXV1/Pa3v+XYsWPMzMz427QLIpPJUCqVREZGEhcXt+AoaZ/Px8jICENDQ7S1tWG32/F6vX609sJs3bqVjRs3smnTJiYnJxkaGuK1117j5MmT1NbW+ts8iesYuVzOLbfcwooVK7j99tuRyWSMj49TW1tLfX099fX1TExMMDAw4G9TJSTOi9/FgFwuJyEhgdTUVHJzcyksLMRqtaLRaAgPD8dsNvvbxEtCJpMREhJCYmIiRUVFLFu2DI1GQ2dnJ42NjQEtBqKiooiMjGT58uUYjUb0ej1utxuDwYDZbGZ8fJyBgQGio6Oprq5mYmICh8Phb7PPQaVSYTAYSE9Px+FwMDo6yujoKOHh4YSGhlJXV8f09HTA2C6Xy8nMzMRqtRIcHExVVdV1s2uUyWSo1WoiIiIIDQ0lNjb2ss9lt9vt9Pb2MjExwezsLKOjo4tk7ZWhUCiIjIzEZrMRGxvLhg0bSEtLIzIykiNHjtDZ2cnJkycB8Hq9zMzMMD4+7merr3+Cg4MxGAwL/muz2fB4PIyPj3Pq1CkmJiZwuVz+NjWg8LsYUKlU3Hbbbdx000186EMfwuVyMTAwwPHjx7Hb7f4275KRy+Wkp6eTn59PUVERarWa9PR0nnzySf70pz/R39/vbxPPi1wup6SkhC1btvDpT3+ajo4OmpubmZmZITU1lcLCQgBGR0dpbm7mO9/5DnV1dfT09PjZ8nMZGRmhs7MTj8eD0WjEaDTy2GOPide/+c1v0tDQQFdXl79NRS6Xo9Fo+PjHP05paSkZGRk88cQT/OUvf/G3aVcFuVyOyWRi06ZNbNiwgQceeACVSnVZIZv+/n5eeeUVqquraW1t5eDBgwET8hG+v9LSUjZv3sydd96J1WrF4XAwMDDAr371K2pqaq4bcXetoFAoiI6OJjU1laysLJKTk8nIyGDNmjU4nU6OHDnCU089RWVlJRMTE/42N6DwqxgoLS1l/fr1PPTQQ2i1WlpaWvjFL35BS0sLzc3NuN1uZmdn/WniJaNWq/nEJz5BcXExBoMBuVwu7k7dbre/zTsvMpkMvV7PqlWruOOOO3j77bfZu3cvBw8exOl0EhISQmxsLI8++iixsbFkZ2fz6KOPsn//fn72s5/52/xzaG9vx+fzERoaisvlwu1288ADDxAcHExGRgb/9m//Rl1dHbt372b79u2MjIzg8Xj8YmtCQgKPPPIId9xxBzExMdfNLkXI2wgJCeEzn/kMGzZsIDc3F4VCcdkLudVq5b777sNsNqPT6Th48OAiWX3pKBQKkpOTCQkJISIigq9//etER0djNpsZHR3l8OHDPPfccwGx2Gg0GjQaDSaTieTkZKKjoykqKiIpKYnw8HAxt8bj8dDc3ExnZyfNzc3s27eP8fHxgPZmwuk5NygoCJPJxN13301cXBzR0dHEx8cTHByM0WhEo9Gg1Wrx+Xyo1Wri4uK499576ezs9Pv3A6fvJ6vVyubNmykpKaGkpETMNwNwOBxMTk7yzDPP0NnZyfDw8KLZ4hcxoFAoSExMpKCggFWrVhEXF8fQ0BBNTU00NzeLcbWZmZlrwjsgl8tRq9XEx8djs9lQKBQATE9P09zczNzcnJ8tPD9CsqNarUahUHD48GGOHz9OQ0MDLpcLnU5HT08PaWlp5OfnY7VaSUtLY2hoiLCwMMbHxwNqEZucnKS7u5uDBw8yPz+Px+MhMjKS6OhoIiMjSUxMRK1W43Q66e3tpaWlhba2Nr/YqtPpyM3NJTw8HIPBwMTEBCqVCpVKFVCf6aWiUCjQarXExMSgVCoxGAzMz8/jdDpxOp3Mz89jt9uZmZnB6XRe0r+pVqsJDw8nODgYnU6HTCbzq2dAJpOh0WjIysoiNjaW2NhYUlNTkclkDA8PU11dzZEjR8RQmr++R+HzT0pKwmq1EhERIeZh5efnk5CQQFhYmCgGvF4vNpuNmJgYIiIicLlcDA0NMTw8TGdnJw6HI6A2NAqFAp1OR2FhIcHBwVgsFtasWUNMTAyRkZGEhYXh9XrFz18IT8lkMhQKBRqNRpyj/YnRaMRisVBQUEBpaSklJSUUFRUtEANOp5OJiQny8/Pxer3XnxjQ6XQ8/vjjrF27luLiYubm5mhsbGTbtm14PB7y8/MpKSlhx44dNDc3B3zyl1qtFuNTGo1GvN7W1sbvfvc7xsbG/GjdhfH5fMzNzdHd3U1lZSW/+MUvmJqaEnfLgmfjBz/4AZs3b8ZsNpOTk4Pb7Wbjxo3s2bNnUW/Oy2ViYoKJiYkFC/y2bdvIyMhg9erV/L//9/9Et2FsbCx79uzh2Wef9YutQUFBxMXFodVqRTFpNBoxm80B9ZleKnq9noSEBD7/+c+j1+uZmJjgO9/5Dm1tbaxevZqPfexjNDQ0UFNTQ2dn5yUloUZFRXHfffcxMzPD/Py830MEKpUKi8XCpz71KbKzs0lMTASgoaGBQ4cO8bOf/Yzu7m6/5zYYDAby8/P57Gc/S2FhIampqee8x+fzLfg8U1JSSElJYePGjWzdupWBgQFaWlr4wQ9+QGtra0DlOuh0OpKTk3n++eexWq3o9XrxNWFMPT09tLS0oFAoCAsLIyMjAzi9YThx4kRAeD2WLVtGcXEx3/jGNzAajeh0OmDhd6PRaAgNDeWhhx7CbDZz/PjxRbNnycVARkYGWVlZ3HHHHQQHB9PT08MLL7zAsWPHOHr0qOg2yc3NxWq1cuzYMTo6OnA4HH5z6V4ImUyGVqtl/fr13HTTTaSlpWEymcTXBwcHOXDgQEDceOfD5/Phcrk4deoUXq9XVM5nf84Oh4Pm5mb+9Kc/ER8fj06nIzY2lqCgID9Zfnl0d3fzzjvv4HK5KC0t5Z577iEnJwetVsvs7Cx//vOf6e3t9auNSqWS4OBgTCYTIyMjF1z4goKCMBgMZGRkiMLT5XIxOjpKXV3dUpoM/K0S5dOf/jQrV65k5cqVeDweent7SUlJoaGhgdraWrZt28bMzIzoGbiUhV2j0fDWW28xNjbG1NSU38SA4BFYt24dq1atoqioCLPZjNvtprOzkwMHDvDaa6/R2dkZEM+62Wxm/fr1LFu2jOjoaOD0s+5wOMTKpjO9MwqFQvQiCEnbOp2O8PBwHnvsMQ4fPszzzz/vr+GcQ0FBAStWrBATzd1uNw6Hg9raWmpqaqisrGRwcJD+/n70ej0333wz3/jGNwCYn5+nr6/Pr95ag8FAYWEhn/jEJ1i5ciUWiwWlUikmmQr3uRBulsvlZGVl0dvbS3Z2Ni0tLZfsXbscllQMyOVyoqOjycnJIT4+nqGhIZqbmykrK6OxsZGenh70ej0zMzN4vV7S0tKYnZ3FZrPR398fcGIAQKvVkpKSQmlpKWazGZVKBcD4+DjDw8MMDAwElIvtbLxer7gQCmGDs/F4PIyNjVFbW4vT6SQoKIiwsDBxrIHO7OwsdrudgwcPig9Wfn4+ycnJrFu3jvfee4+BgYElu7+USiUajQalUrmgJ8LZu7WzUSgUhIaGkpSUxPLly0Ux5nK56OzspLe3l5mZmSW/3+RyOSkpKeTk5BATE8P8/Dxer5fY2FgqKytpa2ujsbHxiv7tpqamq2zt5SGE0eLj48nPz2flypWEhYXhcDjo6+vj2LFjVFVVUV9fv8Cr5k+USqW4Y1YqlczNzTE6OsrQ0BDl5eVMTk4uWEyEMEdkZCQxMTEkJiai1WoxGAwUFRUxNTWFVqtlbm7Or2XFgvBMTk4mJycHpVLJyMgI4+PjDA4Ocvz4cSorKzl8+DDj4+NMTk4SHBxMeno6AHNzc0xPTzMyMuK3EI7RaCQiIoLly5dTUFBARkYGXq+X2dlZZmZmaGpqwuPxiJVGQojMYrEQFxdHcXExo6OjizKGJRMDMpkMnU5HQUEBN910E2q1msOHD/PCCy+wZ88eUanNzs7S1NTEX/7yF774xS+SnZ3NypUr2bNnD0NDQ0tl7iUhl8ux2WxkZGSwfPly8brX62X37t0cO3YsICaH96OhoYHW1lbUavUFmw6Nj49z8uRJnE4n4eHhZGVliW6tawGfz0draytOp5PR0VF+9KMfkZiYyJ133snvfvc7enp6liyhyGazERYWJopHn8+H0+mkv7+fnp6e8woCmUyG2Wzmlltu4YknniAjI0PscOfz+aiursblcrFv3z5GRkaWZBwCXq+XqakpJicngdNhM4vFwqpVq+jt7fVbXsbVQCiP/PKXv8yaNWvIzMzE6/Vy/Phx9uzZw49//GOmp6f9beYC3G632BtEqVTidDp5+eWXOXz4MLt3777ggq7T6bDZbPzv//4vy5YtIzY2lsLCQmZmZkhMTKSjo8OvOVxKpZKIiAhuuukmbrnlFsbGxnjxxRfZuXMn+/fvx+12n/fZEUR2Z2cnTU1NNDQ0+K28eNWqVZSUlPDEE09gMpnw+XzMzMxw9OhRjh49yjPPPIPT6USn0/Hss8+KeQQAxcXFZGZmMj4+zvHjx+nu7r6qti2ZGDCbzTz22GNs2bKFuLg4MWu9pqbmHIVzZvJHcHAwWVlZlJeXL5WpHxiv1yuWsPk7znkpuN1uPB4PLpfrfcWLz+dDpVIREhKCUun3ytTLZnJykvr6eoaHhwkLCxPjj319fVRWVi6JDRMTE2K2ttlsFpOZLnYCmkwmIzQ0lJiYGBISElCr1QsSo5RK5YJrS4XP58PtdjM0NLRArLvdbrq7uwPCbf5BWLNmDcXFxWzatImwsDDm5+fZt28fO3fuZPfu3QHTs+JMhoeH+fOf/0x1dTV6vR673U57eztDQ0MXfb4Fobx3717cbrfYfEyn0xEfH8/AwEDAJHTb7XZ2797NwYMHqa2tvaAQEPD5fOzatYtDhw4xMTGx5N4zk8lEVlYWd999N/n5+ZhMJrxeLz09Pfzwhz+kvb2dnp4e5ubm8Pl8eDwehoeHFwhNpVKJXq9fkF9wNVmS2Vyr1RIWFsbmzZtJSkpCoVBQXl5OXV0d/f395yhVt9stdroTMoqFXVAgIeQMnM9dPjw8HFBJNxdD+Pwv1YshZPNea2JALpejUChQKpW43W5xAtFqtWi12iWzw+l0YrfbRberkKuh1WrR6/XnjWfK5XIxU/rsRlxCOd/FPDuLic/nEysFBLxeLxMTEwFbSXOppKamUlJSQlJSEgBTU1McP36cqqoqv+RoXAqzs7PU1tbS0dGBQqEQqwHez8UvbMIGBgYWzF1yuZygoKAlF5pnIzwncrkct9tNQ0MDHR0dDA4OLnifUqkkKCgInU6H2WzGYrEAcOrUKRobGxcl3v5+dhuNRgoLCyksLCQ9PR2VSkVfXx9NTU1imbNQRq9SqcR15cz2/F6vd8G8dbVZktm8qKiIlStXsnbtWurq6nj33Xf5z//8T6anp8+r0KampmhqamJubm5Bdn6goVarWb58uZikcyYqleqaWyyvdwwGA6tWreKxxx4jKysLrVbL8PAwx44d48SJE0tqi3Bmgs/nQ6FQYLFYKCoqYnR0lLfeeuuciVulUnHXXXdRUFBw3n9L+DeulTyOa4WoqCiSk5ORyWRMTEzQ3d3Nn//8Zzo7O/1t2vtyuV4ZvV6PzWZj5cqVYpwdTouL5uZmv3tBlEolYWFhYi7EzMzMOV5luVxOTEwMBQUFbNiwgaSkJOLj4/H5fHR0dPilWZpGoyE5OZkvfOELREdHExQUxOzsLM899xxvv/023d3dC5736OhosrOz+dSnPkVoaKh4fXx8nMbGRo4fP05zc/NVt3NRVyuZTIZKpWL58uVs3LgRgJMnT7Jr1y5mZ2cvuBN1OBz09vYyOzvrdzV6IYTEovT0dGw224LXfD4fs7OzS65AFxOj0Uhqaqp4Izc3NweMy/BshEYjer0eg8FAUFAQer2eu+66i/T0dHJycvB6vdTV1fHHP/4xICY6QKyZPpuQkBCioqLEMMDZuwIhn2DFihXs3Llzqcy9ITgzqba6upqysjJ6enqu+fDH+QgKCsJms4kJ3mfyfsmtS4FCoUCv1xMUFIRWqyUjI4O6ujrR05ebm0tBQQErV64kJiaG+Ph4jEYj09PTvPPOO/T29volvyMiIoKYmBjCw8PRaDQ4nU7xvIq2tja8Xi8GgwGTyURJSQk5OTnk5ORgNpsXbChHRkbEapBrzjMgZLVmZWWRk5PD9PQ0jY2NHDt2DJfLdcEBOZ1ORkZGmJmZCcjwAJxecIxGI0lJSYSEhCx4zev1BkwPfMGFLJzmJ5fLUalUC/4u5Aw4nc4LuhOFOnK1Wo3D4aC9vT3gxI5er0en0xEcHIzZbMZkMhEaGoperyckJISPfexjhISE4PP56O/vp6amhldeeYXBwUG/VHyc7e4zm82EhYWhVqvFjPygoCBiYmLIzMwUd0TnQ8iaPrPmOpAQ3J1C4yCv1xuwB17B38S+Wq0Wy76ampo4ePBgQHcV/SAI/VKEpkRwOnS4mK7py0WYrwDS0tKwWCwoFArcbjdpaWl86EMfYsOGDQQHB6NWq3G73dTU1HDo0CGGh4f9MmeZzWZCQ0MJDg5GJpOJ5Y1jY2M4nU7CwsKw2WyEh4dz8803k5eXx7Jly9BqtQsabS12E7tFFQNhYWF85StfobS0lKCgIH7yk5+wZ8+e902sc7lcTExM0NjYSFRU1GKaeMUIoY/NmzcvSOaw2+2Mj4/T0NAQEH3JLRYLBoMBm80mLpK5ubmEhIRgNpvJysqivb2djo4O3nrrLdra2s7rSgsJCaGgoACtVktfXx/Hjx8PuN3Ro48+yj333EN8fDwajUZsVyp4l3p7ezl8+DBVVVW88847dHZ20t3d7ZdJzuFw0NLSQlRUFEajEYDNmzeTnJxMWVkZbW1tTE1Nceedd3L33Xdz2223MT8/f830djgThUJBQkICWq2WoKAg8cCes2O9gYTRaGTt2rWUlJSQkpLC6Ogo3d3d57h0r3daW1vFsm9/5384HA7x2Z2bm+PWW29l586dqFQq5ubmyMjI4NZbb2VgYEDsqtjR0UF1dTXvvvuuX3tVnElQUBDJycl87GMf47bbbuPOO+8kKCgItVqNyWQS8yKWmkUTA3q9noiICFasWIFGo2FgYIDDhw/T399/SV+IsHsI1NK84OBgcRd35hc3MTFBc3OzeOOFhIQwOTm5pOOQyWSEhYWxbNkyli9fjtVqRafTiUrU7XbjcrnEcraIiAji4+MJCwujp6eH7u5uTpw4QV9fH729vYSGhpKWlkZJSQkOh4Ouri7q6uoC7twIoR43ODiYgYEB+vv7aWtrw+Px4PV6aW1tZXh4WGxF7M/JYXh4mNdff534+HjMZjNBQUHiSZ2f/OQnxV2M4DIU2vsGQhvV92Nubo7JyUm6urrEbngf/vCHMZlMaLVaZmZmGBoaoqenRzxqWuhyFyg7brVaTUJCAgaDAZ/Px8TEBKOjo4yNjZGQkIBOpxM3AXFxcaSmpjIwMEBzczMVFRUBs5O+HMLCwiguLhbztHw+n5hPI2S5+xOPx8P09LTYaVShULBixQqx98maNWsICgrCYrHgcrno6urixRdf5MSJE3R1dTE/P+8XuycmJhgZGWF6elpMvI6IiKCoqIj5+XnCw8NRKpUoFAox5+d8n7XT6WRoaGjRnpFFEwNms5no6Gjy8/MZHByks7OTqqoqpqamLunnBTd2oE5+wcHBhIaGnpO9PTExQUtLC9PT08hkMiwWCzMzM0sqBoKCgoiNjeX2229n69at2Gw25ubmqKyspKuri5qaGjweD7Ozs4yPj7N27VoyMjLIyMhgdHSUwcFBXn/9daqqqsQa48zMTIqKisSeBPX19QEzcZ+JcN/09fVx6NAh3nzzTbHjXXt7u98bpwiMjIywbds27rzzThITEwkKCkKhUGA2m/nYxz4mLibCjkGhUBAUFHTefIFAY25uTjxyODIykqSkJD71qU+Jomd6eloUZd3d3eK95HA4mJ2d9fuiA6fDgImJiej1ejHsNz09jcvlIjMzU3TtApSUlHDLLbdw4sQJ3n33XRoaGvxSvvZBUKvVxMbGsmLFCvE+c7vdVFZWUlNTExBjEfpxCD0tfD4fJSUlJCYmEhkZiclkEk/L7OnpoaGhgT/+8Y90dXX5Nb9J8IINDQ0REREh9nM4O9cM/laqKyRGnpmILjSPuubEwLp161i3bh06nY6ysjLee+89JicnL2kgKpVKjIGGhIQE3HG5SqWSgoICbr311otWDMzPzy+5V0Aul/Pwww9TWlrKhz/8YeB04tM//dM/0dHRIVZwCPFbmUzGz372M8xmMwUFBVgsFmw2G0888YR4YIlGo8FisSCTyXjxxRcpLy8PyMN0Dh48iEwm41vf+hZer5exsbEFiY6BMKEJeL1enE4n27ZtY2xsjC9+8YvAaZe6EDbw+XyiuDmzvMjj8Sy4Lvw3UISBVqslISGBH/7wh8TGxoqHMQ0PD9Pe3o7H4yEkJITS0lJRBDz88MN8/vOfp7a2NiDOZjAYDGzcuJHw8HDkcjlms5nPfOYz3HfffRQWFqLVasV8JrVajUajYfny5YSHh5OcnMyzzz5LW1tbQOQNvR9KpZKbb76ZO++8k9tvvx21Ws3k5CSdnZ3s2bOH+vp6f5u4gMHBQTHUHBMTQ3R0tJiT4vV6aW5u5i9/+Qu//vWv6enp8ftcNTU1xcmTJ/nud7/L/fffz7Jly85J0ATEBkSHDh3i8OHDzM/PU1payoc+9CHg9AY0NTWVkydPLkqIdtHEQHJyMklJSeJOub6+/pIXxaCgIEJDQ885+CcQUCqVhIeHY7VaMZlM50zAgitHSLyx2+1LutORyWQsW7aMtLQ01Go1O3bsoKKigpaWFsbHx8/rKnM6nWL3OIPBgNlsZtmyZSQmJoqnsgkTX1BQkLiLDbQQzsTEBD09PXg8HiwWCwkJCaLSDlROnTqFUqlky5YtYv6AcE+deW8JE0Vvby+dnZ1kZmZiNBoxGo0BsZM+E6FnQlpamlgCduzYMdra2ujq6hJbjRcWFpKQkIBer0ej0VBSUgLAgQMH8Hg8fh2XXC4XT7c7s2zT5XIRFhaGUqlc0PQJTouC0NBQ8vPzsVgsaLXaa0YMrFixgrS0NHG+7enpYdu2bQwNDfl9MT2bmZkZsVvomZux/v5+uru7efPNNzly5AgDAwMXTVRfKnw+H1NTU1RXV6NSqTh27BjJycnMzMwsyMMQPB/Nzc10dHSIVU9ntixfzLlsUcSATCYjJSWF5ORkBgYGqK+vp66u7pK/FK1WS1RUFHq9HpVKFVCZx0qlksTERGw223mTuaampuju7hYz9JfaPSWTycjOziY+Pp7Z2Vmef/55jh49etFkLZfLhcvloq6uTjyUJSwsjDvuuIPCwkJxNzo3N0d4eDiRkZHodDrm5ubweDwBIwomJiYYGBhgfn6esLAwcnNzA77uvq6ujunpaQ4ePMi6devQ6/XiIiPkzQgZxcPDwxw/fpzdu3fzyU9+koSEBIKDg8X3+nvSExAW0qioKLq6uujo6ODFF1/k5MmTNDc34/V6WbVqFTMzM2Jyq7ATl8vlHDlyBIfDEVDjCQkJWVA1dGZO05nVOkajkYyMDGw225I2srpShIZCQvIqnB5bS0sLzz33XECeuCo0uDp7I9bR0cGePXv4r//6r4BLbhYaQdXW1ooJhELOzPnQaDQUFRUtWGM8Hg8Oh2PR1sKrLgaEhyEhIQG5XM5LL71EY2PjZS2KRqOR9PR0NBoNExMTVFRUBMyXazKZePzxx8nOzj7v6wMDAxw5csSvZXdWq5WBgQFefPFFKisrGRgYuKSfUygU5OTkUFRUxFe/+lUiIiLwer1s376d3t5e+vr6yMnJ4VOf+hRf+cpX2LNnD3V1dezYsUNUuf7cRQiHQlVUVBAdHU1ERETA9qk4k/7+fr7zne/wkY98hFWrVrF582a8Xi92u52dO3diMpnQ6XT813/9F93d3YyPj7NmzRpMJpPYMjbQcDqdVFZW8tJLL/Hee++JJ8UJO7WysjJOnDhBXV0d69ev57777mP16tV4PB5eeuklBgYGAq50VUBITmttbeV3v/sdGRkZbNq0icLCwmuu2mPNmjVs2bKF9PR00cvU0tJCS0sLg4ODAeUVUKlURERE8Pjjj7Nly5Zznu2pqSmxkiCQmZubo7m5+X13+WcLfKH8+5oRA3q9nmXLlmE2m/H5fPT29l62q9xgMIgxlYmJCVpbWwPG3aZWq8X61vMhxED9uauZnJxEpVJhMBjEONr5ELwAZrMZs9lMYmIiOTk55OXlERERgcPhoLW1lT179tDX18fo6CiTk5NiUphCoSA6Opp169aJJZWHDh3y29iFz35gYIDQ0FAxyUtITAtUXC4Xg4ODVFZWis2qvF4vDoeD/fv3o9PpCAoKoqGhgcnJSfGUwvN1vvQXnZ2dHD9+HIPBAJye8Gpqajhx4gSdnZ3nPL92ux2n0ynWW8PpahCtVrvgNEd/EBISIp5bcWYCs8/nE8dVW1vLqVOncDqdYkmYXC4Xc0Eupf2vP5HL5VitVtLS0sSSYSGsWVFRQX19fUC42M9Eq9WSlZVFWloasbGxyGQyZmZmmJ+fx2KxEBoaSkZGBiaTCbfb7bfqgffD5/Ndlm3CdyAkES/WBueqiwGTycTq1auxWq3Mzc0xNjZ2WfWpCoUCq9VKdnY2Ho+HgYEBampqAmYyV6lUpKSkiJNeoOHz+WhrayMuLo7S0lL+/Oc/i67zsxGy13Nzc8nKyuKjH/0o8fHxREREYLfbqa6uZseOHTz//PNir/J3331XbLa0Zs0aEhMTeeyxx/B4PHR0dHD48GG/TiBer5e+vj7S0tIwGo0kJibidDoD5v65EG63m7KyMsrLy9m1a5cYHzxfKa5cLqempoaIiAg/WXsuFRUVnDx5kh07dgCIhxfZ7faLTnxTU1MB18kyISGBjIwMrFbrgpwlobTttddeo6ysjNraWj73uc+Rl5dHdna2KBamp6eZm5sL6FwVpVJJeno6RUVFlJaWolKpmJycpKenhz/+8Y+XleO1VAQHB7NlyxaSk5PFE/+GhoYYGxsjPz9frPJ4/vnnmZ+fZ3R01N8mfyDOTgoWTgNdrAq7qy4GfD4fLpcLr9cr1lNequtMLpezceNGbrrpJtauXcvevXs5cuQI09PTAXdjng+73Y7D4fBrTa7P56OqqoqgoCBuu+02/uu//ovOzk6qq6txOp3i52g0GgkJCWH9+vViYyKZTEZNTQ2/+93vOHLkCN3d3XR1dZ1TDjozMyM2IlGr1Wi1WlHt+ns3JJfLiYqKwmAwiJ6CQN0hnI8zBUAg5QG8H1NTU8zMzIgTsCBm/H0/XAlCdcCZh8TA6ft+YGCAo0ePEhYWxiOPPMLjjz9OeHi4uEs9cuQIv//976mpqQnYg8oEz973v/99MYGztbWVo0ePsmfPHiorK5fsOO/LQaVSERMTg1wup6Ojg+9973tiY7ef/exnhIaGYrFY2Lp1K++99x7vvfeeny2+chQKBUVFRSQkJCzZ77zqYsDhcIjnXhsMBiIjIy8pkUZo77t8+XJSU1PxeDycPHmSxsbGa0II+Hw+RkdHGR8fX/IKgrPtqK+vx2g0kpmZidVqFXv0Cwl/cNrlJnTpm5+fZ2xsjM7OTiorKzl+/Dg1NTVMTEycty+E4MIOlNCNgNlsJiYmhri4OAwGAy6Xi6mpqYCz8/24VPFyZnmovznz9MVA3xW/H0IiamtrKzExMWKFh1wuR6vVkp+fT2hoKCkpKeLBM0Lopr6+nsrKyksuo15KZDIZBoOB7OxsiouLxTwBmUxGR0cHDQ0N1NTUMDk5GZACWjiZ0+v1MjU1xdGjRxkbGyMoKIjJyUlMJhPBwcHExsaet4b/WkIulxMWFiYmCMPpzWZfX9+i5XFcdTEgnLp26623kpWVRW5uLrt3717QY/l8WK1W0tPTeeihh9DpdJw6dYq//vWvNDQ0XG0TFwWPx0N9fT2tra0LznVfanw+H++8846YAHTXXXeRkpLC3XffveB909PTDAwM8Nxzz+F0OpmZmWHPnj2MjIxccmOoQCM9PZ2VK1eKiWhCqVGg7tCuBmcKAn+KAqVSKVYB9fX1XbP3ECA2DUpKSuLee+8lJycHpVIplnL+6Ec/WvB+Ida+Z88e9u/fT21trZ8svzgqlYrExEQ+/vGPc++994rnWDidTg4dOsTBgweprKz0s5Xvj9DhsrGxEZfLRUhICMPDw1itVoxGIzExMRfM6bpWELrICj1HAIaGhti/f/+iJdMvimegvb2dtrY2YmJiWLNmDR0dHVitVrZv376gTaeQEHHrrbeyfPlyVq9eTVdXF1VVVbzyyisBlTgIp/v8h4WFneM+hNMTwt69ewNCvAiJm9u2baO8vFzslginEzxzcnLo6uqir6+PyspKsV3v+Ph4QGUPn8nmzZtJTU2lqKiIPXv20NbWRktLi9gW+rbbbqOgoIDU1FQADh06xK5duwIuHn21EZ4lf4UUBG/AQw89REFBAdnZ2VRUVFBTU8PLL798wTBBVFQUaWlpPPLII2RlZQGnWzQPDQ1d9ETTpWJ0dJQXXnhBPGkuPT39nFit2+3myJEj1NXVUVlZycGDB/26EXg/goKCKCwsJDo6WvTWtrW1UVdXx5///OeAOEvlYni9XmZnZ9HpdJjNZj71qU9RVlZGb28v7733HhqNhtjYWPLy8igvL/e3uVeFM0W+y+Va1JD5VRcDQklUfX09oaGhbNq0iWXLlomxULvdLrrPdDodJpOJNWvWkJKSgs1m4+jRo1RWVlJdXX21TfvAmEwmwsPDzxEDXq+Xubk5Ojs7GRkZ8aOFf0M4d2BwcBCVSiXuAgwGg9icRzh85VogLS2N4uJi1qxZg91ux2q1irXfYWFhrFu3jri4OCwWC83NzVRXV4unY16PCL0hvF5vQJRPRkdHk56eTnFxMXK5HKPRSHNzsxg2OxPh6O+ioiJycnLEw8iamppobm5e1PKpS0UoH6yqqiI4OBiNRiOePDc+Pi4mpZaXl1NTU0NlZSUtLS0B6V6H0899WFgYOTk5hIWFIZfLcbvddHd3c/z4cbq7u/1yvO/lICSlejwezGYzq1evZnp6GqVSKVagCMd5n3l4nL9RKpWo1Wpx7n2/e0QImQunywpck02HAH71q19x8OBB4uLiKCkpYcOGDdxxxx0MDw+LjRYSEhJITExEp9Nx4sQJ3njjDX7+858H7GlmqampFBQUoNFoFkzADoeD0dFR2traAkYMCAhCRajoGBsbo6ury89WXT6rVq2itLSUpKQkzGYz8/PzqNVqjEajmPE9ODhIW1sb//Ef/0F1dTWNjY1+tnpx8Pl8jI+Pi3FpfzZW8vl8eDweMb9Er9ezZs0aSkpKuPnmm9m3b98Ct7lMJiMqKoqCggLWrl0rdpDz+Xz87//+L0ePHg2osM7zzz/Ptm3bePjhh7nnnnsoLCxk//79dHR00N7ezm9+85trwvuUlZVFcXExn/70p9HpdHi9XiYmJigrK+O3v/0t09PTfhdg78f09DR79uyhqKiIjIwMPvWpT5GSkkJLSwtFRUUBVV1zJhaLhfDwcJYvX84777xDb2/vRd8fGRlJZmYmJpMJjUazwPu3mCyaGLDb7XR0dPDf//3frFmzhrS0NNLS0rBareJNNzIyQkVFBUePHuXUqVNUVVUxMDDg96MyL0RtbS0+nw+Hw4FOp0MmkzE7O8vx48epqKigs7Pzmo6VBjL19fWYTCYsFgs6nQ61Wk1fXx+tra1MTU3R1NRES0uLmAQZiNnQVwufz0dDQwPp6enMzs6KgigqKork5GSGhoaW1OPj8/nYs2cPo6Oj5OfnEx4ejlarJSIigs2bN7N8+XLxvTKZjKCgIPGo1pGREaqqqnj99depqKgISDf7zMwM27Zt4+jRo1gsFgYHB8UueIE6VwnI5XL0ej1r165l06ZNYuXPxMQETz/9NBUVFQwPDwe8EIDTa8rx48c5cOAAKpWKlStXkpmZSVxcHGazGY1Gg9frpaWlJaDuIyEh0+l0XpLQ1Wg0mEymBS2vhT4vi8miiQG32834+DgHDx5EoVAwOTm5oGQHTp+V3dDQwK5du2hvb6ejo2OxzLkqCIf21NbWotPpkMvlTE1NUVlZSUVFxSW5gCSujJaWFnQ6HUajEZPJJB5JPDg4yMjICCdOnKC1tZX+/n7GxsaumZK8K2VsbIze3l7q6+vJyMgQ23ZrNBq/nOfR3t6OXC6nqqpKDPlptVrCw8OJi4sD/nbI0tTUFG63m76+Ppqamjh8+DBvvfVWQPbBh9Mhg9bWVlpbW/1tymWjUqkIDw8nLS2NzMxMlEolLpcLu93O3r176e7uDqi8rIshNOeqra0lJCSErKwssUQa/tbMp729PaA8tPPz8+KR8ZdyfyuVygXeZ6Fcf7GrUxZNDMDprE8hDnihbOdrqZ5aaKyzbt26BdevpTFcq7z22mv86U9/Ouce8ncCnT/Zv38/9913Hz/60Y8IDQ0Vjwnv7OxcclscDgd1dXU89NBDFBYWkpaWxvLly1m3bp3Yuls41vj1119ncHCQ4eFh3njjjYAsw7teMJvN3HPPPRQXF4uizOVyiYnegZ4ncDZCe/S6ujqSk5NZtmwZMTExAGIX1DfffJMTJ0742dKFCA2prgSZTEZ8fDzh4eFX2aqFLKoYELjeJmp/ZzrfiFxv99DVYH5+nvHxcX7+858TFBTEzMwMPT09fltYhR1Ma2srw8PDNDU18e6774plXi6Xi7m5Odrb23E6nTidTvFIbYnFYX5+nq6uLnp7e8XjmKuqqqiqqrpmvZgOh4Oenh7+8z//E7PZLCZHCy2IT5w4ERDHYF8pgvejqamJhIQErFYr7777LseOHVvU37skYkBCQuLqI/TB37t3r79NERFOVxweHr4m3erXGy6Xi56eHpqbm8Wjx8vLy6moqLhmNzVut5uJiQneeecdf5uyKExNTdHV1cXJkydxOp1ER0ezf/9+6uvrF/X3ynyXuN0KhC5nl8rFhnS9jAOun7FcL+OA62cs18s44PoZy5WOQy6XL0hGE/qKLKYYkL6TD45arRaPxna73eL3dqW833cieQYkJCQkrmO8Xu81GxK4kVnq78z/3UokJCQkJCQk/MolhwkkJCQkJCQkrk8kz4CEhISEhMQNjiQGJCQkJCQkbnAkMSAhISEhIXGDI4kBCQkJCQmJGxxJDEhISEhISNzgSGJAQkJCQkLiBkcSAxISEhISEjc4khiQkJCQkJC4wZHEgISEhISExA2OJAYkJCQkJCRucCQxICEhISEhcYMjiQEJCQkJCYkbnEs+wlg6f3rpkc4EDzyk7yTwkL6TwEP6TgKP9/tOJM+AhISEhITEDY4kBiQkJCQkJG5wLjlMICEhISEBSqWSsLAwwsLCUCqV6PV6dDoddXV1TExMMDU15W8TJSQuG0kM3IDIZDLkcrn49/Ph8/nwer3vG2fyJ8I4hDH4fL4FfySubc7+fj0ej9+/V5lMhlarJTs7m5UrVxIUFERUVBSxsbH8+Mc/pqGhQRIDEtckMt8lPl3XS6LE9TIOuPyxyOVyjEYjy5cv5+abb2bZsmUkJCQgk8mQyWTi73O5XLz77rscOXKE/fv3Mzg4iMfjueJxwNX/TgwGA8XFxTz66KMUFBQwMzNDfX09zc3NHDhwgJ6eHgYHB3E4HB/E7HOQEqOWhoyMDNLS0rjnnntIS0tjdnaWb33rW7S0tDAyMrLgvUv1nWi1WqxWK48//jgrVqwgLy8PmUyGSqVCoVCwb98+Dh06xJ/+9Cc6OzuZm5u77N8RyN/J5SA9J4HH+30nkmfgKhAcHIzZbCY/P5/5+XkmJiaora3F4XDg9Xr9bR5qtRqr1Up8fDzR0dGsWLGCFStWkJiYSFRUlOglEG4Wt9vN1NSUOMlVVlYyMjJyziTsT7xeLzMzM8hkMgwGAxqNhqSkJAwGAzqdjr6+Pvr6+mhtbWV4eJjBwUF/myxxATQaDUajEZPJhNlsJj4+noSEBOLj4ykqKiI+Pp7R0VH0ej1KpX+mLIVCQXp6Ojk5OaxcuZKUlBRsNht2u52xsTEGBwcZHx/HbrfjdDoD4rm/UZDL5VitVkJDQwkNDSUkJAS5XC5+B263G4fDQVVVFVNTU7hcLj9bHJhIYuAqEB0dTVFRET/96U8ZHR3l+PHj/NM//RO9vb1XtDu42gjegIceeoicnBzS0tIWvH72xKVQKCgtLSU7O5ubbrqJX/3qV1RWVnLgwIEP7CG4WtjtdqqqqigrK8Pj8WCxWIiIiKC4uJh77rmH2dlZRkZGeOWVV9i7dy9vv/22v02WuAAWi4XMzEyKioooLCzkgQceOOc9o6OjfltgZTIZQUFBfPjDH+aBBx4gKSlJXGyGhoYoLy9n165dOJ1O2tvb6erq8oudNyoqlYrc3Fw2bNjA+vXrWblyJSqVSrxfJicn6enp4fOf/zynTp1ibGzMzxYHJksmBpRKJZGRkSQlJZGQkMCWLVswm83odLpz3tvX10ddXR07d+6kr6+PoaGhpTLzspDJZJhMJjZu3MhDDz2EVqslKioKrVaL0WhkaGjI72LAZDKRkZHBY489Rl5eHjab7ZJ/Vq/XExsbyxe+8AWqqqqIjY1lx44djI6O+j12C6djyK+//jq7du1CqVSi1WoxmUxs3bqV4uJicnNzefDBB7HZbMzOznLs2DGcTqe/zb4iZDIZYWFhFBYWsm7dOl5++eVLejYUCgUmk4nZ2Vm/34uFhYUUFhYCEBoaSlxcHMuWLcNgMKDVatHr9ej1+nN+bvfu3ZSXl1NVVcXs7OyS2myz2YiJieHxxx9n5cqVxMbGIpfLGR8fp7e3l6997Wt0d3eLYsXfn/GNguARzMvLIycnh0cffZTQ0FDMZjMKhWKBcNTr9SQmJvLtb3+bw4cP84tf/ILh4WHm5+f9OILAY0nEQHh4ODabjdzcXJKTk0lISKC0tBSj0XheMTAwMIDZbGZycpKWlhZOnjzJ2NhYwH15SqWStLQ0MjMzSU1NRalUIpPJsFgs4t/9hUwmQ6lUUlhYSElJCRkZGYSEhBAUFLTgfT6fj/n5eZxOJ0NDQyiVStRqNZGRkSgUChQKBXFxcbhcLoaGhjhy5AgzMzMBs6gODQ2JC6JCoUCn0xESEiJ6MIR7bvXq1TQ1NeF2u3G73f40+bKQy+UoFArUajV5eXnk5eWRlpaGUqm8qCCTy+WEhoZisVhIS0ujurraLztWrVaLTqcjJiaGFStWsHLlSuBvi2xGRgZqtfq8Pzs3N0d/fz/Hjh3j2LFjTE5OLqkIVSgUxMTEkJ2dzYoVK4iJiUGlUjEwMEBzczMnT56kqqqK8fHxgPGYnU1QUJAYPvN6vTQ0NOB0Os/7DAi5Q8HBwbjdbux2e0CI/vMhVHTk5ORQWlpKRkYGQUFBYsgT/hb2VCgUaLVaYmNjaW9vD7gxqdVqzGYzRqMRm82GWq1GoVBc8P3t7e1MTk4yPj5+Ve1YEjGwadMmNmzYwH333YdWq0WlUl30/QkJCSQkJFBcXExtbS2///3vefvttwMu7qvT6Xj00UdZsWIFVqvV3+YsQKVSERwczLPPPktxcfEF3+f1ehkcHKSnp4dXX32V4OBgIiIiePjhhxcIteTkZBITE9m+fTvT09P09fUtxTAuC4/Hw/T0NH/5y18oKysjLi6On/70p6SkpJCbm8vevXvFnI5rBY1Gg06nw2az8dWvfhW1Ws3Y2Bg9PT0MDw+f92dkMhlqtZpNmzZRWlrK/fffz5e+9CW/iIHo6GgyMjL4whe+QEZGBvHx8Zf8s8PDwzz//PP88Y9/pKGhYRGtPBe5XE5QUBAbNmxg06ZN5OTkIJfLsdvt7Nq1i7/85S9s37494DYoZxMREcE3vvEN8vLy8Hg8PPzww3R1dZ2zkMhkMhQKBUqlkuzsbKanp2loaMDtdgdk/oNGo2H58uXcddddbNmy5ZJ+RsjtCKS5S6FQYLVaWbt2LcuXL2fr1q2EhYVhNpvP+36fz8d3vvMdDh06xO7du6+qsFk0MRAaGkpiYiKf+cxnWLZsGVFRUeh0uosqnrMxm82iazs5OZnjx4/z17/+dbFMviLeT8X5i6ioKDZv3kxISMh5X7fb7TgcDjo7O3n11VfZu3cvg4ODGAwGQkND0Wq15ObmkpeXJyZtyWQyioqKmJubY2BgICAnCYHJyUna2tr41a9+xa233sqHPvQhVCqV3xLQLhe5XI7JZOKLX/wiqampxMXFYbFYqK2tZd++fdjt9vP+nEwmIyYmhocffpiNGzcSFRVFa2sr09PTSzyC08TExJCTk0NeXt4FJ7gz6evrY8+ePezatYvOzk56e3vp7+9ffEPPIiQkhI985CPcdttt5OXlIZfLOXXqFKdOneLnP/85nZ2dAZ+IZjabSUhIYMOGDZhMJmZmZrj99tvZs2cPNTU1wGmRn5KSIgq1pKQkTCYTLpeL2dlZXnrpJerq6qisrAyYHbVGoyEsLIw77riDxMTEBa95vV4GBgaYmJhgYmKCnJwctFotCoUCg8FATEwMpaWlFBQUEB4eTnh4OB6Ph6GhIf7v//6P0dHRCz5bVxOZTEZWVhYJCQlkZ2dTWlpKVlYWYWFhqNXqi37WDz74IFFRURw7dozp6emr5um86jOjXC5HrVaTmppKXl4eW7ZswWq1otVqF2Stz8zM4PF4xKxwIear0+lQKpWia9RqtRISEsLw8DBKpVLMbPe3m1pQ0md7OjweD3Nzc36v0Q8KCiImJuaCLtixsTEGBgY4duwY5eXlHDlyBDjt7RgbG+PgwYNoNBpSUlIIDg4Wv7vMzExGR0c5ePAgDocjYN2jLpeLmZkZcRck7HquhVIgIUyTkJDAunXrSEtLIyoqisOHD9PZ2UldXd0Fd6Th4eGkp6ezfv16li1bhkKhYP/+/X5LmhLK8UJCQhbciy6XC6fTSUdHx4JFtauri7KyMnbt2uUXEQAL49GJiYmEhoYC0NPTQ1VVFXV1dQHtQhcICgoiODiYqKgo8b4vKipiYmJCnLPS09PJzMwkOzubxMREUlNTxZ/3+Xz09PQgk8moqanB5XIFxJiDgoIwm81kZmZisVjE68LcW1dXx+DgoOg5i4yMJCoqCr1eT3R0NKtWraKkpISoqCiioqJwu910d3ezc+dOHA7HoosBlUqF1WolJyeH7OxssrKyyM7OXuA1u9jnnJycTEdHBxqNhpmZmatm11UXA0FBQcTFxfH3f//3lJaWEh4efs57XC4XFRUVTE9PMz09zeHDhwkPDycjI4Pi4mKsVuuCL1kmk7Fx40YyMjLQarX85je/oba29mqbflkI4iU6Ohqj0Shen5mZobe3F7vd7tedg1AeeKHFeu/evbz33nv84Q9/WKAs7XY7drud5557DrvdTlpaGjk5OWg0GmQyGffeey/h4eHs37+flpaWq3ozXm3kcvmCyfxaQKlUEhMTw9/93d9x9913Ex8fj1wux+Fw8Pvf/54jR45QXV19wZ//5Cc/ydq1a9m8eTPT09OcOnWK733vewFVFgowODhIfX09jz76KL29vQte8/eCIyw22dnZC7wZ1dXVvPnmm8zOzga0V0xApVItEGAGg4F77rmHu++++5z3nk8ky2QyHn30UeLi4tixYwdjY2MB4Q2x2WzEx8eTlZW1YCM2NTVFd3c3//iP/0h3dzeTk5NkZGRw00038aUvfYnIyEji4+PZuHHjOeMNDg5mw4YNzMzMLOqzIpfLsdlsfOxjH+PBBx8kPz8/YDYoV10MxMXF8fWvf538/PwFD5LX62VycpKmpiZaWlp46aWXxAznkZERgoKCMJlM5OTkiLEgk8kkuuDlcjkWi4Vbb72VmZkZEhMTefPNN/02cej1ekJDQ4mPjxfHKZPJcDgcDA8P43Q6/bprHhwc5O233yYrK4vCwkLy8vIWvJ6UlMTo6OhF/40LfbahoaHcdNNNjI6OBqwYkMvlaLVaVqxYQUJCAi6XK2Djn3D63klLSyMlJYUHH3yQnJwcrFYrPT09VFRUcOjQIcrKyi6YNxMUFITNZhOrKACxCc7o6GjAZLm73W527tzJsWPH2LdvX8BUppzJmjVrKCkpIS0tjeDgYFwuF21tbbjdbmJiYs6pyDGbzdhsNpqbm+nt7aWlpcVPli+kpKSENWvWnHP9chcfYeOjUCgCQgxciPb2dg4fPszAwAAulwuz2cwtt9xCSUkJwcHB4lpy9vjHx8fp6uqivLz8gnk4Vwur1Up6ejoPPvggiYmJC2zx+XzY7Xba2tpob29nfHycxMREcnJyMJlMC5IjF4OrKgZMJhOJiYliaECj0Yivud1u+vv7qamp4ejRoxw4cOAcN7NMJmNoaAi32012djYZGRno9XrxQ9DpdKSlpbFq1SpkMhlvvfWW3yYSo9FIeHj4ORn6Ho+H+fl5v4cJpqenaWxs5NixY8jlcsLDwwkODkatVqNSqcSQzMUQXO1nixqdTkdqaiparXYxh/CBEMRaamoqJpOJiYmJC2ZR+xO9Xo9GoxHd0nl5edx2223odDp8Pp/YUXH79u309vZecDLW6/Wkp6eTmJhIWFgYMzMzVFdXc/ToUb+6tA0GAxaLBZlMhtvtZnp6mkOHDnHw4EH279/vF5suhkKhIDs7m+XLl4uL/tzcHNPT05jNZtLT09FqtQsm8dDQUKKiokRB4Ha7xSqd6elpv4TT5HK5mAtwKYu/YJ/P50OhUCz4GZVKhc1mY3R01O/h2YsxMTFBd3c3BoMBo9GI2Wxm+fLlpKenn1Np4PF4cLvdzM7O0tHRQUNDAy0tLYueWxMWFkZiYuICj8D8/DwOh4PZ2VmGh4epqanh5MmTomc3JSVlgfd5bm5ODEVfTa6qGHjggQdYvXo1ERER56iY2dlZ3njjDbZt28aRI0fOOxCfz0draysTExPU1dXxgx/8gMzMzAWZ+jKZjLVr12I2m/nXf/3Xq2n+ZbFs2TI2bty4IHnQ5/NhNBpJTEzEYDCgUqn86h3weDz85je/Yfv27bz33nt85CMfISMjg7i4ON59913eeeedi9rX2dnJrl27yM3NfV/hEGjk5eVx0003UVBQQFdXF7t27aKrq4vJyUl/m7aAjRs3kpOTw8aNG8nKyiI8PByFQoHb7WZ4eJinnnqKlpYW+vv7L7qgp6en88wzz5Ceno7dbufAgQPs2rWLI0eO+FWUrl27locffhi5XE5nZyenTp3iV7/61ft6pfyBSqXCYrGwZcsWNmzYIF5Xq9Xk5OSQk5MDcM5iKZTkffjDH8bhcDA5OcnY2BiNjY288sorHDhwYEnDNMLhSRkZGWRkZLzv+30+n1i67fV6CQ0NFbuPwukk0E984hP85Cc/8Vsi6qWg1WqJjIzk6aefxmKxYLVaxZLD83kDenp62LFjB3v37qWlpYXe3t5Ff1Y2bdrE+vXrFwiBlpYW9u7dS2VlJWVlZUxNTTE3N0dBQYEoZM60v76+nsbGxvNu1D4IV0UMhISEkJGRwebNm8nNzRWFgFDqdfDgQU6ePMmOHTvo6Oi4qKLx+XxMT0/T1tbG0aNHAc5xdSkUCkJCQti6dSuVlZV+KZnq6OigqqrqnMNTGhoaePvttxkdHQ0Il5rL5WJkZITDhw8zMTFBZGQk6enpvPvuuzQ0NFz05p+cnKS9vR273b4gZBPICKVRmzZt4pZbbmFqakqM9fo7pCEk165cuZKYmBhSU1PJzc0lMjKS6OhoLBaL+BkrFAqCg4P5u7/7O4aGhhgfH6exsZHOzk7a29sZGBhALpej1+u5+eabxfbSs7OzdHZ28vrrr9PV1eW30rfQ0FC++c1vsmHDBnE+aGpqYufOnQGbfCccjKRWqxfE2oXzB4S/n72wCP+vUqnE/h4Gg4GgoCDcbjfBwcE0NTVRV1eHw+FYdO+UUqnEYrFgs9kWbKSEZO2pqSkmJyeprq7G6/Xi8Xg4efIks7OzuFwuvvzlLxMbGyuGP89Mig4EpqenGR4epqWlhaioKEwmE3A69KnX6wkODkaj0RAUFCTmOgk4HA5GR0d59dVXOXXqFHV1dfT09Cx6DwuVSoXJZBL77MDpHf7g4CC///3vaW9vFwX/smXLSE5O5qabbiItLQ29Xr/gMLby8nIqKyuZn58PvNJCo9FITk4O+fn5JCUlidfdbjdDQ0Ps27ePffv2UVtbe0kL5NzcnOguMZvNlJaWLvA0CAfubNq0if7+fr+IgYGBAZqamhY8IEJscceOHUxOTgZEpr0Qh2ppaaGzsxODwUBmZiZNTU3vu1uZmZmhu7tbnCQCXQwITYcKCgooKioiNzeXkydPUltbS3l5ud9dnCqVCrPZzKpVq8jPz2fVqlXYbDYxzCQcFiXs0ORyOXfddRdOp5Pp6WnKysqorq5GqVSKr5tMJm699Vby8/Ox2WzU1dXR0NDAgQMHGBoa8ssErlQqsVqtPPHEEwsW1c7OTsrLy3G5XKhUqgVhRDidvOrvBUcQBGff68L/C8+TEAa02+3I5XKUSiUqlQqVSoVOp0On04ldFefn5wkJCWFgYEAMgy4mQiVRaGgoBoNBvO52u+nr66O/v5/e3l62b98uNuEqLy9namoKt9vNfffdR0hIiCgGXC5XwGxuALHVeH19vdh1FE5X0kRERIjvO3Oh9Pl8OJ1OxsbGaG5uZvv27Zw8eXLJPDYajYaoqChiYmLEpHqXy8X09DTHjx/H6XTi8/mIiIigoKCA0tJSbr/99nOaxHm9Xmpra6mvr7/q99FVEQNBQUGEhoaeU8Y2Pj7Oyy+/zO7du6mtrb2sxdHn8/HOO+8wPz/P7bffTkhIyILMUYvFwmOPPSaWxi01Qm6AcMN5vV66uro4efIkR48eDQghcDYul4uJiQkqKiouadIdGhpiamqK1tZWdDodsbGxS2DllRMdHU16ejr/8i//glwup76+nr/7u7+js7OTsbExv+9GY2JiuOOOO3jkkUdISEhAqVQyNzfH7Ows8/PzaLVasdJmZGSE+fl5brvtNrRaLTabjXvvvVdM3Ozr62NmZoaZmRm2bNmCyWTC6XTy85//nIMHD76vB24xSU5OJj8//5xQYW9vL5WVlXg8HoqLi7npppvE13w+H88991xANBa7WIzdbrfzhz/8gampKSYmJvjDH/4ghgZLSkrIz89n8+bNBAUFiZ0XH3roIbHz3dtvv01bW9uieWy0Wi15eXn85Cc/EXeg8LecrX/+53+mtraW3t5eMbcB/nY89PlKkfv6+njxxRcDpi28EOf/93//d772ta8tGOf58Hg8OJ1O/vznP1NVVcX27dvp6+u76ieaXoyIiAgeeeQRCgoKiIyMBE7n0yQnJ/Pss8+K3UIBsQz67J4oQg5Xc3Mz3d3dV93GqyIGzGYzhYWFC/qKO51OhoeHOXz48BUfgTs1NUVTUxMvv/wy9957L9HR0eJrQpe1xc6wvBA+n2/B4iLYI+wKZmZm/L74nA+fz3fJ34Vw0mFoaOh5e8b7G5lMhs1mw2QyERUVRWFhIbm5udhsNsbHx5mdncVms+FyudDr9QwMDIi7bn9gsVjEOu/6+nqmpqY4deqUKLrCwsLEXhozMzO43W5OnDgh7tJSUlIICwsjLCyMlJQU3G43c3NzYvvYgYEB+vr6GB4e9usOW2iicvaiKpR1rVixgqSkJFJSUsTXvF6v2ENBaIiz1Gi1WpKTky+YHzM/P8/U1BSHDh1ieHiYiYkJhoeHmZqaYnZ2lomJCU6dOkVVVRXLli0jIiKChIQEbDab2CRHqVRSU1Nz1bvHCQjesejo6AW7yoaGBk6cOEFtbe0Fj/Y2GAyEhYVhsVgWfAZerxeXy+V3r41AQkICcXFxbNmy5X2FwPDwMI2Njezdu5fjx4+LR5vPzc0t6fwshJ/OzjdRq9XExsaKYaULMTc3R2trK2VlZaK39mpz1cRAQUHBggVjZmaGgYEBKisrmZqauqJ/126309nZybZt29iwYcMCMRBICO7doKAg0TVot9sD0jtwOYSFhVFUVER4ePgCd6O/ERo+6fV6kpKSiI2NJTc3l40bN5KXl4fBYGB8fByXy0VqaioWi4WJiQkxZupwOPwSA9Xr9SQkJIi9xQcGBti+fTvt7e0MDg6SkJCAwWCgoaFhQS5KaGgo4eHh4olsUVFRhIaGLnBlT05Oitne/qqYEARxbm7uOaE9gJSUFO644w4++9nPnrPg+nw+mpqakMvlfhMDQpWMUMkBiOWoQi7TwMAAR48epa+vT5zXnE4nk5OTdHR0iGGCW265haysLDZs2IBer8dkMrF582Yx32nPnj2LMj/I5XI0Gs2CPi0+n4/a2lrKyspob2+/4O81mUwkJSUtEAPCpidQNjZKpVLsR/PRj36U8PDw8+ZweL1e3G43HR0d7N27lx//+McX7buyFJxvvhH6Drwfs7OzNDY28vLLL9Pb27soIc+rIga0Wi0xMTELHv6qqioOHTrE2NjYFU+6KpWKiIgItmzZsuDmDhTOTiaamppidHTUb7Haq016ejoPPPCAeHhGoBAeHk5ubi4//vGPMZlMBAUFiW41YYEMCwsjODiYgoIC4G9dLzs7Ozl27Bj//d//fdFSvcWgvLyc+++/n7m5ObH7pvB3gO7ubrEE70xGR0eZmJhgcHAQo9HI/ffff05M22g0kpeXx1NPPcWhQ4f40pe+tGTjEggLC+Ohhx7i9ttvJzc395xJesWKFRQWFgZsSaperycrK2uB8N23bx/Nzc04nU6qq6upr6+ntbX1goLL5XIxNTXFtm3bKCsrY+/evTz77LPk5eWhUqlISUlhdnaW4OBgMRdnMXG73YyOjrJv3z62b99+0cVw2bJlfOITnyA8PFzM55icnBRzCfwtCAwGA/n5+TzxxBNs2LBhQVdbAWFOHhkZobW1la985Su0tbUxMTHhV/vn5+dFj8Tl4vV6xUqDQ4cOLdo9c1XEgJBAc6aCFLJZNRrNZe/ChCYXmZmZ5ObmsnLlygV1lk6nk6mpKY4ePboosZMrRRj/tS4E5HI5SUlJpKamntPS2G63MzQ0xIkTJ/yWne9yuXC5XGIP7+npaZqampiYmMBut6PVapmcnGR6epqIiAixt0JSUhJms5mVK1fS1tZGdXU1ZWVlS2b3/Pw8w8PDF5yQL3Td6/WiUChIT08nKioKhUKBz+djamqKvr4+UUSEhobS1dXlt26DcrlcdHee7zAyIcHuQpw8eXLJDyQ6E6fTSVdX1wIXel9fH7W1tXR0dNDd3c3g4OD7LoxnJqu1tLTQ19dHbGws4eHhGI1GrFYrarV6UWLWbreb8fFxampqCAsLw+Vycfz4cbGJzfkQ7p2EhAQyMzMXJHY2NjbS3NyMw+Hw67wWExNDTEwMt9xyi3gK4/kQvpfZ2Vn6+/sZHBxc8tMuz8fU1BTHjh0jLy8PmUxGcnIy8LdmfPPz83g8ngWhZgGfz0dDQwOdnZ2LWh10VcSA1+s950aJi4tjbGyM4ODgyzrnW3D/hoaGsnnzZkpKShbU/MJptdra2sqvf/1rGhsbr8YQrogzXWjCzSYoU3/ffB8ElUrF8uXLyc7OJiIiYsEudGJigvb2dvbu3eu30//sdrt4nrxMJmN6eppXXnmF9vZ2RkZGMJlMYuw8MzMTnU6HXq/n/vvvJysrixUrVqBSqYiOjl5SMXA5+RpnIpyBcdNNN5GdnY1cLhcPVzl06BDvvvsuCoWCvLw8enp66OjouPrGXwKCED47i/vsP3K5XMzaF/B4PGK1hL+YmZmhpqZmQS39wMAAdXV1HDhw4LKfaafTSW9vLz09PSQlJYmNv8xmMyqValHynYRytffee4+CggI8Hg/bt2+ntbX1guJdLpcTGxsrNikSxL/H4+HYsWNUVVUtyeE9F0Iul5OZmUlhYSEf/ehHiYiIuOB3Icy9MzMz9Pf3B0yjsfHxcfbs2UNycjJut5vY2FhkMhnz8/N0d3czPT3N3NwcRqNRPNRPwOv1cvLkSdrb2xfVxqsiBgYHB9m+fTulpaViOcqZbRcPHjxIa2vrRRuN6HQ6LBYLt912G9nZ2axcuZK4uLgFCtDlcjE8PMyPf/xjDhw4QG1tbcC0WZXL5cTFxZGRkUFeXh6nTp0K+ONNz4fQIesf//EfiY2NXdBtTciGLisro7m52W+lRk6nk/r6eh544AHgb/XTbrcbj8eDXC4X/37y5Elx4amsrOTee+8lJycHvV4fkEmR5yM7O5sVK1bwyCOPYLPZ8Pl8NDY28u677/Kzn/1MTNDdsWOHWCrmD+x2O0ePHmXz5s3itc7OTnp6eqiurqa7u5v+/n7y8/MpLi5m3bp1wOkwSFNTk18XHDhdg97W1rZgx242mwkNDb0igR8SEkJOTg7Lli0T850aGxs5fvy4uBu82ng8Htrb2/nhD38ohla7u7sv+tnKZDKMRiPBwcHodDqxE2x9fT0vvPCCXzdcVquVkpISHn30UXJycoiPj7+kk0dDQkLIysoiODiYiYkJv68TQsmwUF33l7/8BTjtLWxra2N6ehqPx0NBQQEPPPAAH/nIRxb87ODg4KIfNnZVxIBQ6lFUVCReUygUmM1m1q5dKybmXGzHEhISQlRUFGvWrBEzjY1Go+gSFdzT+/fvp7KyktbW1kXJqPwgqNVq8fx5f1U5XAyLxSI+JBfCarWK9bBGo1EUAm63G4fDQV1dHc3NzX4VOj6fj7m5uXMOuDkfZ04CQuMkQRwEygEhF0KhUJCcnCx6x0JDQ1EqlczMzLB3714OHz4sHorlDxduSEgIer0ei8VCe3s78/PzdHR0sHPnTvr6+sT2vJ2dnbS1tTEwMMD09PQ5ZYdCLoe/xbPP5zsna16oCLjUe0VIbo2MjCQpKYktW7YQFRUl5kk0Nzdz8uTJRa1qmZ+fFytUgPcN58nlcpKTkxck483PzzM+Ps7IyMgVJ4B/UCIjI0lOTuaWW24hPT2diIgIMczk8/mYnZ2lra2NkZERioqK0Gq1C0IcgeidHR8fx+Fw4PP5xPygoaEhMSEwJiZmgXATyiKF8uPF5KqIgZmZGRobG89RnyaTibvuuovVq1czMjIidrw6H7GxsaSmpp6TJS24VgcHB6mqquLf/u3f6Onp8Xs3ubMRHiKhRjQQiY+Pp6CggH/6p3+64OQmNE8xm80LJmyhEdTRo0epq6tbKpOvGgqFgtzcXFJSUhY0kAlktFotN998M1u3bhVr8qenpxkcHOSXv/zlRV2/S0FiYiJxcXHk5+fz+9//npaWFhoaGnj22WfRarUsX75cjJnD344GTkpKWtAcZnJykvr6er83hTofQntnhUIhzl0Xu2+USiVBQUEUFxdTWlrKo48+isFgEHOqjh49yp49exZ1Yvf5fLjd7ku+N1QqFaWlpQtKPYVESJfL5bcM/Ly8PNauXcvnPve5c0ryXC4XQ0NDvPrqqxw9epT//M//JCoqShQD8/PzTE5OBtzhZB6Ph9nZWZqams55Ta1Wn5OUPjc3x8TEBA6HY9E9sVdl1eru7ubll18mPj6eFStWsHr16gWvWywWgoODF0wAZyN0JDtTCMzOztLX18fBgwd56aWXxB7tgdIJ63zEx8ezZcsWamtrA2ZyE9qp3nbbbaxbt06MV13ovWfHc+FvOwWn0xnQn//5SElJYfny5Xzxi18kMjKSsbExnnvuOSoqKvxt2gVZs2YNy5cv55577iEhIQG3283evXuprq6mvLycrq4uv91fFouF5ORknnrqKTIzM9FqtWJ/dwGn0ym2TBX43Oc+xxNPPEFcXBxarVYseXv77bf5xS9+EZDnFURGRqLVavn973/P0NAQo6OjVFRUMDo6ytjYGO3t7RgMBvFQrIyMDNavX096ero47ykUCkZGRnjnnXcoKys770LgL9LT08nPzxfPlAkEhPvrwQcfJC8v75zNVVlZGSdPnmT37t10dnbi9XrRaDQL3id4Ms9uFx/IaDQaPvShD5Geni5ea2trY//+/XR2di56jtZVEQNClvSRI0dwu90YjUaio6MxGAxiowWFQnFO+9GzERStkCDW2tpKe3s7hw4d4uTJkwHRnexMhAX1zP9qtdpzvBv+Rjh1LCUlheTk5Pf9Hs6H0G99+fLlWK1WRkdHaW5uZnp62i/KWxA4F1P+Qh5Hfn4+a9euJSEhgdnZWQ4dOkRVVZXfEu0uhlwuFxsM5ebmEh8fj1wup6uri8OHD1NTU8OJEyf82sciLCyMLVu2kJWVRVxcHMA5paeCGxdOe2USEhJYtmyZeNgPnN4lHTp0iGPHjgXEsy0kOnd2dtLa2kpkZCQqlYqQkBCKi4sZGxtjfHwcnU7H6OioOEcFBwcTFhZGcnIyycnJFBQUEB4ejlKpxOVy0dvbS3t7O2VlZWJYJ1CIiIggOzsbq9UqhjLm5uYYGxujra3Nr7H2yMhIsXUvnP5+7HY73d3dtLS0UFdXh16vJzY2Fp1Ot6BSRRhDIDVLej8UCgUREREL8uTGxsY4derUkjzvV9Wf/eqrr1JWVkZLSwsf//jHyczMJDQ09JLi50I4QDik6PDhw7z88st0dHSIbsZA5EwhIJPJxONoAylnwGAwiKeuCSUtl0twcDDp6el873vfE4XAt7/9bU6ePOmXCUOhUGAymcQTvs6HSqXi7rvvZsOGDdx8883Mzs6yd+9ennnmGVpaWgLGc3MmGo2G7OxsioqKWLFiBdHR0Zw4cYLy8nJ+9atfMTIysqRtVM9HdnY23//+9y/5/Vqtlvvuu4/c3NwF191uNz/84Q9pbW292iZeER6Ph6mpKd544w36+/u5//77CQsLE5NNhW53mzdvZm5uDofDwfj4uPjMn/3cC9607du3c/ToUV566aWAW5ySkpLYtGkTwcHB4s56ZGSEuro6/vznP/ulYsjhcNDX14darV6wMM7NzdHV1UV7ezutra309/dz5513snnzZmw22wIxMDk5SVtbG06nM6A+74shk8kwm80L+nD09fVx6NChJXnmr3pwe3R0lLfeeotjx44RGRnJxo0bxcQ6oXe8kFk7MzPD+Pg4+/fvZ2pqipmZGQ4ePMj4+DhTU1MLEisCkTNLCs/+byBht9tpbGykpaWFiIiID9TJUagjDwkJ4T//8z9pa2tj165ddHR0MDg4uMBVvBjI5XK+9KUvERUVxV//+lcaGhpEMaBQKFCr1cTHx7NmzRpWr17NypUrmZ2dZdeuXTz//PO0tLSIyW6BRnBwMImJiXznO98hMTERq9UqPh9/+MMfGB4eDgi7JyYmqK6uJi0tTSyB+uEPf8iXvvQlmpqa6OzsFGvaV65cSVZWFtHR0YSEhIj/xv79+3n11Vf91hPhfAieyQMHDlBXV0dVVRU333wzubm5FBcXn9NGVqFQEBQUJPZZEapYnE4n5eXltLS0cPToUY4fP87g4OBVP2VuMfB4PLz33nvs27fPb89JeHg4mzZtIiwsbIHHaWxsjN/97nfU1dUxPT3No48+ypYtWygsLBSFjMvlYs+ePezatYs///nPAZdbFshcdTEwPz/PwMAAAwMDdHR0iAlpwklaIyMj4oE3U1NTjI+PU1ZWxuTkJDMzM5SXl/t953O5CJmhgfqgu1wuxsbGOHnypFhOd6GcAaEkD/6WDCkcB6rX68VOf0FBQRQUFBAdHY3D4SA6Opquri6Gh4ex2+2LklcgeF8yMzPF6hS5XM7AwABer1fcnWVkZLBq1SqKi4vFA6SOHDnCoUOHGB0dDYgF9WzkcjmJiYnk5+eTn5+PVqsV67xPnDhBc3PzkvdTvxCjo6OUlZURGRkpioGcnBxSUlKIiIigo6NDFAOrVq0iMzNT/Fmv10tzczPHjh2jrKwsIJ/1kZERJicncTqdGAwGsexLqBSw2WyYzWbxTIi5uTmxJbHD4WBiYoKDBw/S3NxMVVUVXV1dARUagL+1wbVareIRuULm+qlTp2hvb/dbtZZGoxGFwJnzlNBqWdjMlJaWkpGRIR78A6fnuiNHjlBdXU1PT8810xJe8IIYjcYrCuNeDRY17X1ycpI333xzMX+FxCUguD9/9rOf8de//pWHHnrogmJAOI0NTre4tVgsJCQkkJSUtKB0FE73hkhISOCzn/2sWN88ODhIfX09AwMDizIWQVzGxMTw93//92L/Cp/PR3x8PJGRkcTFxTEzM8PQ0BDf/e53qaqqora2dlHsuRrI5XK0Wi0PP/wwH/rQhzCZTDgcDnp6evjsZz/L8PBwQC2a1dXVPPnkkxQXFy+I6Wq1WgoKCsQW0OfDbrfzjW98g5MnTy66F+mD4HK56Orq4ne/+524CMHpe/7jH/84W7ZsYe3atTQ0NNDR0UFTUxOHDx+mu7v7mnBPazQa7rzzTtauXUtGRgZKpVKsVNm9e7dfvxsh4/7szy8yMpLvfOc7F/1Zl8vF//7v/wZEDsrlEB4eTnp6Ojk5OQu67S4lgVkDdw0wPz/P9PQ0zc3NxMXFiYdNCG1IA1GRCsk3f/jDHy74nvn5ebFpjVKpFBWrXq8nJCSEyMhIwsLCSEtLIzo6GpvNRlpa2oIz3Rerfl+oA//rX/9KV1cXd9xxB4mJieLOc3R0lI6ODt577z0aGhqor6/nxIkTTE5OLoo9VwPhaOjHHnuMDRs2EBYWJpZM7dq1i+HhYb83TDkfPp+Pr3/962RmZrJx40bWr1//vtnoe/bs4e233+bYsWOL3kDlaiF0VBTClS6XizfeeIOKigqsVivT09PY7XZmZmYYGxvz2yFYl0NGRgbZ2dk8/PDDJCQkiLH2rq4uDhw4wMDAgF97uNjtdtGb4vF4LikZ2+FwUFNTw5EjRwLOC3MphIeHk5qaKlbUeb1eGhoaaGxspLu7e0kaiUli4AoRXGqtra0YDAasVqvYF3ypvrzLxe12Mz09zalTpy7r584sNxR234ODgyQmJhIeHo7L5UImk9HX18fs7OyiCiGv1yt2nkxKSiIhIUHsetnZ2UlnZyeVlZWcPHmS+vr6gNpRnw/B87J582aioqLwer2cOnWKsrIy9uzZE9D279+/n9bWVuRyOSaTiZiYmIu+/9ChQ+zevZv+/v6AfD4uxJltpD0eD21tbbS1tfnZqisnLCyM1NRU8vLyxAZpQnj3xIkTYn8Bf+F0OsVQc2hoKFar9YIJ2Q6HA6fTSU9Pj3iYz7VW+gyn54GYmBiUSqUYsunp6aG/v5+pqaklEZeSGLhCPB4Pk5OTvPjii8hkMlJSUujr62P//v38/Oc/D7juiB+EMw9gam1tpa2tjYMHD55TWgmc05t+MWhpaaG1tZW33377HC9EoB25+n6UlJSwevVqsrOzaW9v59SpU3zlK19hZGTkmkh+6u3t5ec//zm//OUv3/e918MhXtcDgpdPrVYjl8vxer0MDAxQVVXFW2+95fed9fj4OEePHuW5556jtLSUhx56CJ1Od14PQWNjIydOnOA3v/kN7e3t9Pf3XzPP/pkkJyezfPlyMRFSaKXe1dW1ZMJZEgMfAJfLRVVVFVNTU+zYsYPZ2VnxuNNr8Ya8VAKhcuJaWvDPh9Dlcfny5eTm5tLV1cWf/vQnDh06xMjISEBX0ZzNlR7AJOEf+vv7aWxsFL8zQQwI/e8D4bv0+XxUVFTQ3t5OeXm5WK1xNkLzp6amJmZmZq7pOUHY2IyMjNDd3c2OHTtobm5est8viYEPgNfrpbu7O6COUZa4NhBOIhRq0+vq6ti/fz8HDx68JjwCEtcu4+Pj9PT04HK5UKlUuFwuOjo6GBgY8LtX4EyEcEx5ebm/TVl03G63WHo6PT1Nb28vNTU1S5pbI4kBCQk/4HQ66e7u5mtf+xpyuVyscQ+EXZnE9c3U1BQDAwN0d3djMBiYmZnhhz/8YUB25LxR6O7upqamho0bN4qetqUIuZ6JJAYkJPyEcKyphMRSYrfb6e3t5T/+4z9Ez0BXV5fkkfIjDQ0NzM7OMjg4yMzMjNivZSmR+S5RegT6ca9ncrEhXS/jgOtnLNfLOOD6Gcv1Mg64fsZyvYwDrp+xXC/jgMsQAxISEhISEhLXJ4Fzmo6EhISEhISEX5DEgISEhISExA2OJAYkJCQkJCRucCQxICEhISEhcYMjiQEJCQkJCYkbHEkMSEhISEhI3OBIYkBCQkJCQuIGRxIDEhISEhISNziSGJCQkJCQkLjBkcSAhISEhITEDY4kBiQkJCQkJG5wLvnUwuvlQIbrZRxw/YzlehkHXD9juV7GAdfPWK6XccD1M5brZRwgeQYkJCQkJCRueCQxICEhISEhcYNzyWECCQkJCYmLo9PpsFqtFBcXo9FomJycpKKigrGxMX+bJiFxUSQxsIjIZDLkcjkymQyfz4fH4/G3SZeETCZDoVDg8/nEONOZf5eQkDgXmUyGxWIhLy+Pf/mXf8FsNtPY2Eh3d7ckBiQCHkkMLBJarZb169fzxS9+kaioKCorK/nHf/xHpqamcLvd/jbvgsTExJCamsozzzzDyMgINTU11NfX09zcTEVFhb/Nk5AISGQyGUVFRaxdu5aHH36Y0NBQampqePrpp+nq6vK3eRIS74tfxIBMJsNsNmMymQgJCSE2Nha5/HT6wtTUFKOjo/T29jI+Ph7QC+fFUKlU2Gw2cnNzCQ0NZWhoCIVCEZDZpyEhIVgsFpKTk4mNjSUpKYmsrCwmJyfR6XRYLBaUSiV1dXXY7Xa8Xq+/TX5fVCoVKpUKjUZz3s/cbrfjdruv2fvrWkahUIges6CgIAwGAyEhIQveY7Va0Wg0yOVyurq6GBsbY2BgwE8WXxy1Wo3BYGDVqlUsX76chIQE2tvbaW1tpbW1FafT6W8TbwhkMhlKpZLQ0FC0Wi1arZaIiAiCgoJQqVTi++RyOfPz80xOTnLixAlmZ2eleQA/iQGlUklycjJFRUUUFxfz8Y9/HK1Wi9frpba2lvLycl599VWOHDnC9PS0P0z8wKjVaoKDg4mMjPS3Ke9LWloaJSUlfP7zn8dms2E0GlEoFOj1eqKiosjOzkav13P48GE6OjqYm5vzt8nvi8FgwGKxEBoael4x0N3dzfT0NFNTU36w7sZFJpOh1WpRKpUolUoiIiJITU2ltLR0wXtWrFhBaGgoGo2GP/zhDxw6dIidO3cGZKjKZDKRmJjIo48+SmJiIgaDgcOHD1NWVhawAuZ6RKVSodPpWLFiBbGxscTHx3PzzTcTHh6O1WoFTt9bMpmM8fFxTpw4wVe+8hXa29uZnJz0s/X+Z8nFwOrVqykuLmbr1q2EhYVhs9nQaDTiQ56cnCwuQj/60Y9oamqit7d3qc38QMhkMmJiYggLC/O3KRclLCyM73//+6SmphIdHU1ERAQqlQqFQrHgfWazmYyMDLZu3crzzz/P0NCQnyw+F5VKhdFoZOPGjSxbtoyYmBgALBYLFosFm80mep3O5MSJE5w6dYo33niD9vZ2Zmdnl9r08yKXy7FYLNx5551kZ2fzk5/8hNHRUWZmZvxt2iUjl8tRq9XExMRgMpmwWCysWLECpVKJXC4nNTUVg8GAwWAAwGg0niOaDQaD+P7c3Fzsdjtvv/12QIkBmUxGZGQka9as4a677iI6OpqOjg527drFSy+9JIUHlgi1Wk1JSQnLly+nuLiY3Nxc9Ho9KpUKs9m8wCsg3D8Gg4Hs7Gz+4z/+g3//938PqCRPrVZLcHAwKSkprFmzhttuu41Dhw5RXV3Nnj17mJiYWJT8syUTAxqNhtTUVEpKSli5ciU5OTno9XqCgoIAmJmZYWpqipCQEKxWK8uWLaO0tBS1Wn1NioHIyEhRjTocDhwOBx6PJ2AmM7VajdlsprCwkJiYGCwWi7iD9vl89Pf343K5cLvdhIeHYzKZyMnJwWKxMDExwfz8vJ9HcBrB+7JmzRoyMjKIjo4WrwcHB2M0GnE6nUxNTeFyucSkzry8PIxGIxMTE7jdbvr7+wNid6BWq0lPT6eoqIj8/HzeeustPB7PRcVAcHAwXq/Xr4JGp9Oh1+sJDw9HrVaj0+lIT0/HaDRisVgoLi4WF/fExET0ej1arRaXy4VarUav1wMLm7h4PB7sdjtOpzMgXe3CWJYtW0ZOTg79/f3U1NRQVlZGW1tbQNxPF0Mmk6FWq8Uwh06nIzg4GIPBgNPpZHh4mIGBAebn5wNm3jobg8GA1WoVQzT5+fkkJCSICdCzs7Picy+EaX0+HwqFguDgYHJycggPD0er1fp7KAAEBQWRnJxMSkoKGRkZFBQUkJycjMPhwOv10t3dTU1NDXa7/ar/7iURA3K5nLCwML73ve+Rk5NDfHy8+JqQpd7e3s6RI0fYsmULISEhJCQk8M1vfpMdO3bw9ttvL4WZVw25XE5+fj4pKSkA9PT00Nvbi9PpDJh4e0hICNHR0dhsNoKCghZMwi6Xi507dzIwMMDk5CQf//jHsVqtbN68mZdffpmZmZmAEWiJiYkUFxfzuc99DqXyb7fzmePp7u6msrKSkZERZDIZOp2Ou+66i4yMDDZt2sRTTz3FwYMHOXTokD+GsACj0cjDDz/MmjVriI2N5fbbb2f79u309PRc8GfS09OZn5+ntrbWb/dXXFwcmZmZfOITn8BgMGAymSgqKjonRHPm/7/fAuNwOGhqauLAgQMcOXIkYJ4dAZVKxR133CEK0a9//etUVFQExH10KajVakJDQwkPDyc3N5fMzEzy8vIoKSmhpaWFv/zlL/zud7+jv78/YGPqKSkpFBQU8NWvfhWTyYRarRZf8/l8dHR0oNFoiIyMRKvVLvB6KpVKQkJCMBqNASEGFAoFUVFRPPDAAzzyyCOEhobS2dlJVVUVmZmZmEwmTCYTPT09164YKC4uprCwkKKiIsxm84LXXC4Xr776KocPH+bAgQN0d3dTUlLCbbfdJsaArFYrk5OTAXtDnonNZiMhIYHbb7+dlJQUfD4fe/bsoaysLKDEwN133y0KL7Vajc/nY2xsjH379rF3717Ky8uZmZnB4/FQVFREVlYWKSkprFu3DqVSGTBiAP4WB/R4PMzNzXHq1Cmqq6s5ceIEHR0dYm7A/Pw80dHRFBcXMz8/j1wuJygoiA0bNqBUKv0+iVutVpKSkli7di1RUVEoFApCQ0PFXfPZmEwmYmJi+NrXvoZSqeS9997j9ddfp6+vb8ls1ul0xMXF8eSTT1JYWEh8fLyYD3C+XA2Px0N3dzfj4+MXdcs2NDTQ09PDkSNHaG9vZ3x8fDGHcdnEx8eTkZHBHXfcgVwup6ysjAMHDtDW1uYXW7RaLWq1mpaWFnGhyMrKwmKxiN5XgaSkJGJiYrDZbERERBAeHo7RaESv1xMcHIxeryc1NZVPfOITHDx4ELvdzujo6JKP61LIzMxky5Yt6PV6lEqleH81NDRw/PhxysvLkclkhISEoNFoiIqKYvXq1RQWFp6zFvkTi8VCVFQU//RP/ySGOd577z0OHjzI7t27ufXWW0lKSmLFihUXnA8+KEsiBiIiIkhOTiYsLOyceLTb7aaiooKjR49y6tQp0WW9efNmVCoVBoOBzMxMampqrolkL6PRSGJiIgkJCdhsNgA6Ojro7u4OGCEAp+20Wq14vV4mJiaYnZ2lpaWFQ4cO8d5779He3i4umJOTk8zPz6PRaEhLSwsoIeBwOBgfH6e9vV10p5eXl1NRUUFlZSWtra1ifE2pVKLX6zGbzaLLUAjpREVF+W0MQlZ9SkoKeXl5REdHo1arcTgcopvzfKjVarGu3WAw4HK5OHjwICMjI0sWxhGqZnJycsjPzxfjs263W8wt8fl8zM3N4XQ6sdvttLa2MjIywvDw8AX/3draWtElOjc3F1A9OtRqNfHx8RQXFxMVFUV7ezuVlZV0d3czMTGxpLYI+UmhoaGEhoZiNBrFkFJBQQGhoaGiGBBc5Onp6cTFxWGz2QgJCcFkMjE7Oyt6auRyOSaTCYPBgNFoXLDbDiSUSiXh4eHExcWhVquRyWS43W6qq6upqqqivLyc48eP4/P5MBgMqNVqUlJSiImJITMzMyDEgEwmw2AwkJiYSHp6Orm5uWg0Gjo7O6moqODIkSNUV1djs9mw2+0EBwdfcD74oCyJGAgJCSEiIuK8OwWXy8Vrr73G4OAgAAcOHMBkMvGhD32ImJgYMjIyePrpp/nSl75EdXX1Upj7gYiMjGTFihVotVrx4RsYGLjoxOcP3n77bQYGBjAajZw4cYKamhpee+01xsfHF8Snz06+Ky4uDqhdQktLC8PDw7jdbqamphgfH6e6uvq8XqSQkBBWrlzJP/zDPwDv76ZeKoKCgkhLS+PLX/4ymzdvJjg4mLGxMXp6eti+fTuNjY3n/TnBsyFk5d9xxx1s376dqampJduhKhQKdDodGo1GFAIul4vR0VH++Mc/4vF4cLvdtLa20tjYSEtLC7Ozs8zPz19UsATKd3M2giv3zjvv5LHHHmNoaIi3336bn/3sZ4yMjCy54JfJZJSWlrJ69Wpuv/12XC6XaINQmimIXjj9uZ45D09PTzMwMEBFRYWYl3H33XcTHBy8pOO4XBQKBRaLhbCwsAVri8Ph4B/+4R/o7e1dUPUkeJZUKhXj4+MBIy6DgoIoLi7mk5/8JOvWrRM3ZAcPHuTAgQPiGP7617+ybds2YPGejSURAzk5OaxevVq8Mb1eL8PDwxw7dozDhw8vWHycTidDQ0OcOnUKm82GUqkkODj4HI9CoCGTybDZbGRkZLB69Wq0Wi2zs7MMDg7S3t4ecCVGnZ2dTE1NMTs7K4qV8+0ovV4v+/btQ61WU1BQgMlkIjY2lpKSEurr6/1e+imIgIqKClwuF/Pz8+c86LGxsWRmZnLrrbeSn5+/YGIE2L17NwcOHFhy2+F0WCklJYUnn3yS4uJiTCYTAENDQzQ2NlJbW8vIyMj7/jsKhQKtVktISMiS7njkcvmCRQf+JgZeeuklvF4vcrkct9vNzMwMPp8PlUoVUMm0l4NSqSQ9PZ2IiAiUSiXbt2/n2LFjTExM+M3zNzAwwODgIHa7Ha1WKwr4iYkJZmZmxI2WsDnp7OxkYGCAmZkZhoaGGBwcpLu7m5iYGLKzs3G5XOLPjYyMBGQli+C9CA0NJSwsDLlcTnNzM9XV1UxOTp5397x582ZKSkq48847xeRuj8eD1+v1y72Yn59PVlYWn/jEJ/D5fBw/fpxXXnmF9vZ2uru7zxnDYtu4ZGGChIQEcTAej4e+vj6OHTvGjh07Fig4j8fD5OQkLS0tYnxE2P3I5fKAcrWfiUKhIDExkZSUFJKTk1EqlUxMTNDV1RWQD9T4+DiTk5OMjY3hcDgu2DvA5/PR1dUlTihBQUGYzWbi4+Npb2/3uxjwer3Mzc2dk2AnNByyWq1kZmaycuVKbrnlFsLDw4HT95nD4WBsbIyqqirq6uqW1G6VSkVwcDBpaWnk5eWxZcsW0SUrPB/19fUMDAxc8Ls5c8d3sWuLhZCNbrPZFriSvV4v8/Pz4j0jJKoFBQVhs9nw+XxMTk4yMjLC9PQ0brc7YHZqF0MQXMuWLcNms+F0Ojl27BgtLS1+q3YQKn/a29tpbGzEZDKJibT9/f2Mj4/T0dGx4Gfq6+vp6OhgcnKSwcFBhoaGcDgc+Hw+srOzgdNNuXp6epiamgrIviJCaE2v14slqsPDwzQ1NTE3N7dgnVAqlWi1WoqLi1m5ciUZGRnivCHcg0tZHSWTydBoNGRnZ7N69WqKioooLy+ntraWQ4cOMT4+fk6CoEqlElvaX9OeAVioahwOB6+99hp79+7lxIkT5wyut7eXnTt3cuedd4qJLWazmeDg4IAs15HL5RgMBr761a+Sk5NDSEgIHo+Hnp4edu7cydjYWEBOdkK+wPthNBrFB06hUKDRaNDr9QHtrYmPjycnJ4dvfetbREREEBwcvKBqYnx8nIqKCp555hkaGxuXNB9FJpMRGxvLgw8+yN13301ycjJGoxE4LVJGR0d57bXX+P3vf3/RiVjouCaTycSJraqqitra2iUZh0qlIi4ujkceeUQs6YTTgjEuLo7vfve7YvOnkpIScUKbn5+npqaGAwcO8PLLL9PX1xdwYbTzYbPZSE1N5etf/zqTk5McOXJEfL79xZkJyr/+9a/FTROc9rK6XC4cDsc5P3P2WSPh4eEUFhZy//33YzAYaGpq4tChQ4yNjQVMGfGVEhERQXFxMQ8++CDJycniPdja2spPfvIT9u3bR3d395LZo9PpyM/P56GHHmLFihXs3LmTt956i8OHD9Pf379AyAjPeHx8PHNzcwwODuJyuRZFECx506G5uTmmpqZoaGhgeHj4goMSFJBSqcRisRAeHo7NZgtIMSC4Z9PS0sSdp8PhoKOjg927d/t993ylCDuh0tJSMjMzgdP9IAYGBqitrQ2IRj1CTXtWVhZRUVGEhYWRmpqK1WrFZrMRFxeHTqdDpVIhl8txOp1MTk7yk5/8hOrqalpbW5mdnV0ysSbEeAsLC7nzzjuJj49Ho9EwPj7O8PAwfX19vPLKKxw4cOCcSRwQa8FVKpWYSR0cHCzuGlwu16IlGJ05BoVCwebNm1m5ciUpKSnodDrxWVYoFBgMBlauXIlKpUKtVos5NHB6p5aamopOpyMiIoK6ujr27dtHY2Mjs7OzAev9i4+PJz8/H71ez/Hjx9mxY4e4o/YngidmampqgWdIcIG/372tUqlYtWoVubm5hIWF4Xa76enpYe/evdfE3CV8/pGRkeTm5oqeEZlMRnp6OsuXL+fuu+8mMjISr9fL4OAgR44coba2lv379y95DpTNZuPRRx8lKiqKgYEBXn75ZRoaGhgaGsLr9aJUKsVcgsjISDHhsa6ujj/+8Y8MDQ0tyjO+qGJAJpOJk7DA7OwsIyMjl1wuJJQpCZ6BQCQ4OJioqCiio6PFmO/c3BxDQ0PXRNLj+ZDJZOj1ekJDQ8nPzycxMRGfzyeeG9HW1nbexWqp0Wq12Gw2Vq1aRWZmJsnJyZSWlooTwtkTtdPpZHBwkNdff52GhoYls1PoyicskkKTFMGmgYEBWltbaW5u5s0332Rubu68sX+LxUJERARarZa8vDxWrlyJTqcDEAXBYi+mwnNdWlrKqlWrRAF85liFpEiv1yu6ZIX8AaECITQ0lKSkJBISErDb7UxNTTE4OBiQgl/w5uTk5ACnK4QOHz6M2+0WK1OEXAh/7KQFQXAlKBQKli1bRmJioliNMDw8zIkTJwLiGb8Ywv0ul8uxWq2kpKSIIUK9Xk9eXh6rVq1iy5YtBAUFMTMzQ1dXFwcOHKC6unpJ5wCB4OBgbr31VjweDx0dHZSVlYlNhcxmM3q9HpPJxNq1a0lLSyMjI4OsrCx27drFW2+9xejo6LUnBgwGA8XFxYSGhorXjh07xt69e2lqagrIrmJXwrp16/jYxz62aPWf/sBgMLBx40buu+8+Vq9ejU6nw+Fw8MILL4hxLX/viOB0nfHy5cv51re+hVqtRi6XI5fLL2jbxMQEtbW1S37vCWfcf+Yzn6G0tFRMYPJ6vQwNDfHb3/6W8fFxlEolP/nJT9BoNOcNw4SGhhIdHS329xfaRy/lpK1SqTCZTGzevJni4uKLvndmZoaJiQkqKirweDwoFAoyMzPFxC+j0ciaNWtYvnw527dvZ//+/fzsZz9bopFcGnK5HL1ez+bNm3nooYdobGwU+1iYTCaCg4Mxm81kZmbS398vZuYHwvNxqajValFACwmEQ0NDATsGr9fL1NQUY2NjjI6OimeqeL1eMT/gvvvuY/369VgsFlEwt7a28uyzz3L48OFLSsxdDNRqNWFhYfT39+N0OjEYDGRlZZGQkMD69etJTU0lISGBkJAQFAqFeLDXYrOoYkCoA9VoNOK18fFxsaNVoN5ol4qQNJiVlUVOTg4qlUpsfrN9+/aAO/L3fN0Gz2Rubk7si7127VoKCwspKChApVLR09NDZWUlZWVlNDc3B8x3Nz4+TldXF0eOHCEpKYmwsDC0Wq3Y3lponexyucjJyRHbMC91vkN4eDhJSUnk5uZiNpsXuDJNJhObNm1ibm4OuVzOsmXLFsR+z+TMMMGZCAt0fHy82PFysRDaBHd2dhIRESF2FLXb7dTV1VFfXy/2GLDb7djtdlpaWsQdXHR0NMnJyWRnZ4ueDZ1OR15eHjKZjN7eXg4cOBAwJawGg4F7772XjIwMNBoNFouF1atXI5PJiI+PFyuk0tPTGR8fJz8/n23btjEwMLAoneKuNgqFgpycHPFcj9nZ2YAIf1wMId9J6FdhtVrFQ7A+97nPERUVRVFREVarVeyzUFdXR2VlJSdPnvRrEzu73c6JEyfEJmNf+cpXMJvNGI1GdDods7Oz1NbWYjAYiIqKIj4+nq6uLnp7e5menl60kOaiigGVSnVO32fBFRjIN9qlIJfLRVdtdna22G1QcIlu27aNmpoaf5sp9uLXaDTExcVhsVjOuxD6fD6mpqZEN/THP/5xEhISiIqKEqs7tm3bxpEjRwKqG9zIyAjNzc28++67OJ1OFAoFRqNR7Kve1dWFw+HA7XaTlpaGWq0WFfdSIZSdxsTEkJycfM5rJpOJW2655QP9DqVSidFoJDo6msjIyEUVA263m9nZWU6dOoXRaMRms+HxeBgZGeHAgQO88cYb1NfXi+91u90LYs96vZ7s7Gyxja9w3HRaWhp6vR6n00lDQ0NAiAGZTIbRaOSjH/0oKSkpyGQyrFYrpaWlpKenk5KSwvT0NMPDw6SmpuJyuSgtLeXUqVM4HI6AFwNCeEMQA0KlRyDkA10Mr9fL9PS06BkQ+ieo1Wo++9nPirlEPp8Pl8vF7OwslZWVVFRU0NLS4lfbZ2dnOXz4MOvXrycxMZFHHnlEtLO2tpbm5mY6OjqwWq0UFBQQFxdHS0sL7e3tTE1NXZtiICQkRFxUzqxxPXHixCUNSEiGWcpyqUslMzOT3Nxcvvvd7xIaGipm5/b29lJfX09VVVVAdOoT3JePP/44hYWFhIaGLujhL+D1ehkfH0ehUKBSqQgLCxPbez7//POUlZXx1ltvBVyZ0djYmJgQ+MILLxAcHCx273M6nWg0GoqKirj11luRyWTiASzXQmvry8HlcjE9PU1HR8dFzzG4Wng8Hn70ox8REhJCZmYmra2tTE5O4nQ6mZubEz/f84l+u93O8ePHqa+vx+v1smbNGrZu3YpCocBqtbJ+/Xr+53/+Z9HHcCnYbDaxDazBYMDr9fL/sfff8ZGd5d0//p5eNBqNRtKo9y6turS9eddtbWPjbmMMIUAMJISaBAghIXngy0MSQjE8MZDEYGLAxtheg2Hxmq3eIml31XvvbUYjaZqm/v7Y3zmsvMW7tqSZXZ/367UvzBTpvnXOue/rvsrnmpubY3x8nOHhYX784x8zMjLCyMiIGO646667uO2224iJieH5558P9xSuiMlkIj09Ha1Wi0KhIBgMcuLEiXUvtb0WhAx7k8kkKgsK+4PQ9RMQ1+PXXnuNf//3fxdLKMPN5OQkX/3qV6msrCQhIYG5uTl8Ph8ej0fsdGkwGPj3f/93UlJScLlc/PjHP6apqUnU6lgL1swYEE4MQpjA7/czNTWFzWa7pgn5/X7cbjdWq3XdpT4vhUKhwGKxUFVVxdatW7FYLGi1WnE+k5OTnDx5UqyfDhdCj/WysjKx+1VaWhoGg+GS7udQKCR6cIRkN0AUi3G5XBGZ5R0KhcTTp9/vFw0aoXbdbDaLpW6CESQkta0ngrv8woSztyIUCuFwOFhYWLikToVer8dsNqPX60WP1NLS0rplgDscDjGRaWZm5qrzMIRTkN/v5+TJk0RHR7Nt2zbMZrMoMmaxWIiLiwu7d2DDhg1s3boVnU5HX18fAwMDnD17VhTp6urqwmazMT8/T2NjIzqdjrq6OiwWy0WJlZHI8vIyDocDv98vhnFGRkYiqk25gKAtkJqaKvYY2LJly0XqtjKZDLfbjd1u5+jRo9TX1zM6Oiom6YUbYZ3q6elhYmJCPO0HAgHm5+eJiYlBp9OJnprOzk76+/vXPIdjzYwBIdEpNjYWjUbD8vIyfX19V71oCElgy8vLzM7OMj4+HraEjwtRq9UUFBSwfft29uzZI1rUcP50NjAwwGuvvbZC6zscJCQkcPPNN3PXXXeRlZVFenr6FT8vdPO7FEKYISYmRlT3isQwz/Ly8grPhWDUWCwWMd4bDoQQjN1uZ2lpCa1We1UJQYFAgKmpKYaHhy9ZB52UlERpaSkajWaFMbCeLt7l5WXxNHOthEIhTp06RVxcHNPT00RHR6PRaNDpdKSmppKamhp2Y2Dr1q1iM6L6+npeffVVXnnlFZaXly96BpqbmzGZTIyMjBAXF7cicTpSEZoQCTlcQqe/ycnJcA9tBUI4w2w2U1dXR01NDZ/85CdXhPuEUIEQ6hgYGODll1+mvb094sIegUDgss+NwWAgPT2djIwMxsbGOH36NENDQ2senl0zY0Cn02EwGMS2kaFQiPn5eTF+eyVMJhMbNmxAp9Nht9tpaGhgZmYm7BdUp9ORnp7O3/3d31FYWEhqaqpotLhcLr761a/S0NBAU1NT2N3pRUVFfOELXxCzzt8uSqWSJ554grvvvpuuri72799Pb28vbW1tuN3uiBRTgj9p5j/66KPs2rULs9ks6gzMzMys+7j7+/uZnZ3l0KFD13Q93G63GPJ4M1u3buWJJ57AZDJdlFB4vSLEfZOSksK6mQpaCRkZGSQmJnL8+HF+97vfiYqpbzYEhGTCiooKdu3aJbp1Ix2h86UgKR0KhRgdHY2Ig9eF5OTkUFRUxMc+9jHy8/NJSEi4Yt5PV1eXqNcRSTlOV0NtbS2PPPIIOp2OpqYmvv/9769Lue2aGQNCideF7huhDEqw3i6FUDeenZ2NRqNhYWGB3t7esJ+04XxL0MrKSlHURljUp6enGRgYoLGxUay/D/dYA4EATqdTbO15td9xuVwsLS1htVqJjo4mISEBjUZDYmIiarUap9NJTk4OSUlJ9PT0YLVaRdnZSEJoJV1XV0dmZqa4cNhsNpqamtY9dujz+USZ0avNfxF0A4R/b2Z+fl7cmORyOUqlEr1ej06ni4jY6NtFqJlfa/GkK6HT6aisrCQlJQWlUsnp06cZHh6+rKy4TCajtLSU3Nxc9Ho9U1NTEelqfzMGgwGLxYJarRbDa16vNyJyapRKJQaDgbS0NLZu3UpJSQmlpaUkJCSIXszZ2VmsVisDAwNkZWWRm5uLRqPB6/WysLCAy+UK6310LchkMmJjY8nKyqKwsJDJyUlGRkbE6ru1Zt0UCGUymSgJq1QqL3mBhKzrjIwMKioq0Ol0jIyMcObMmbArYclkMu644w7R7X7hgt7R0cGBAwdobGwMu/dCwGazcfr0aW666SbMZvNbfl4IyUxMTDA0NMSpU6fIz88XVeT0ej25ubnk5eVht9vp7u7m+eefp6mpaU2MgTdvmNdiXMlkMvLz89mzZw979uwRpZSFPgsvvfRSWPJPgsHgmm3ScrkcvV5PXFwcJpPpujUGgsEgPp8Pm80WVpnf2NhY7rvvPgoKCgDYv38//f39l/28QqHg5ptvpqqqimAwKJaCRTqxsbHk5OSInoFIQoib33vvvTz00EPk5uaKyYJC5VZ3dzdnzpzhZz/7GY899hgf/OAHI7bl8luhVCpFD0hhYSGvvPIKvb29a5o0uOL3r/lvuADB4rxUEofBYCA+Pp6vf/3rFBcXk5OTg06nw2q1cvjw4bA2+omNjeXWW29l+/btFBQUiBtVMBhkfHycP/7xj/z0pz+NqAXY4XDQ19fHli1bLvsZQaN7fHyc0dFRfv3rX9PV1cXAwABOpxONRoPBYCA6Oprs7Gw2b97MfffdR1xcHGVlZSQnJ9PZ2YlCoaCzsxOr1fqOxXx0Oh3Z2dlUV1evGGd3dzczMzNXjE+XlJRQWFjIww8/LJbYCUmRfr+fL3zhCzQ0NDA3NxcRJ5/VZr0UCFcTi8WCxWIRS14DgQAOh4Ourq6wloBpNBoKCgqIjo7G7XYzNjZ2SUNf0IXYunUrd9xxB263m2effZZz584xMTERhpFfG9nZ2Wzfvl30+s3OzuJyuSKiH4GwzvzFX/wFZrNZDIV1d3fT09PDk08+yezsLEtLS6Lc9TsJiYYbtVrNtm3biIuLY3R0lCeffJKenp518zKv2V9O6C3vcDjEbOf5+flLKnOp1WrS0tKorKykrKyM9PR0DAYDfr9f1JIPFxaLhaysLLZv3056erronnI4HMzPz3P48GFaW1sjziXodDrF04larRZlkgVmZmZYWFhgfn5erGGtr69nZGTkonbLUVFRzM/P4/f7SU1NJScnh/T0dCwWC6FQSPQ+DA0NUV9f/7bHLJPJSExMpLi4mJ07d654Lz09HavVesWyufz8fHJzc8VWwIJq4vz8PGNjYzQ0NNDX13dDGgJCglVUVNQKXY+1+l1yuZzs7GzMZrO4eM3PzzMxMfGWi5dCoRCbj1VVVbFhwwax8ZXL5WJqaoqlpaWwKpQKOiJCvtOFrbGFTUetVpOXl0d1dTXbt28HYHR0lOPHj183DX6EsACcn7MQxo2EUu64uDiSkpJISUkB/pSseurUKVpaWjh79qyoLbJ9+3bi4+NF4bfrDZ1OR1xcHBUVFcTFxeF0OhkcHFzXBNo1MwaGhobQarWMjY2Rnp6O3+8XhUTe3JXJZDKxY8cO/uIv/kKM+QCXTZxaL2QyGZs3b2br1q185CMfETvEAQwPD9PU1MTf/M3fRKSWupB4mZOTg9VqFXXwBf74xz/S3NwsKsZdqWuX0+mkp6eHnp4eRkZGqKys5IEHHqCmpobMzEy+8IUv0NHRwdmzZ2lsbHzbJ1O5XE5VVRX79u3jQx/60EXvARf97Asf/As3IUEVbmhoiKNHj7J//37OnTsX8SIwbxdBdCg9PZ3U1NSL2tauJkIDq8cee4ytW7dyyy238N///d8cO3aMn/3sZ2/ZH16r1ZKXl0dtbS0f+9jHSE9PF2vDFxYWaGxsDHtY8EoI7afj4+P5y7/8S6qrq0XVwQMHDvD000+HPWfoapmcnOTcuXM8/PDDGI1GUSQuEhJSc3JyyMnJEf///Pw8v/zlL3n++efFzpxCI7t77rmHsrIy0UNwvRkEFouF4uJi7rnnHtHoWW+DeM19KkK5SlRUFHfffTf9/f10dHSIi7JOp+Nf//VfKS0tFZtMeL1enE4n3/3udzl16tRaD/GSaLVaEhMTefjhh8XGNzKZDJfLxRtvvMEf/vAHTp48yeLiYkSeNB0OB93d3fznf/4ner1ebJErYLVacTqdOJ3Oa9ogOzs7GR8fp7m5mTvuuIPKykruuusuMjMzRfW1np6et+UpUSgUVFdXk52dfdF7l1tcLywngj/JlPb29tLd3c3+/fsZHBxkZGTkhumFIRAuASXh1LxlyxZqamoA2LdvHwUFBXi9Xnp7e5mcnBRj5kLTK4PBQFxcHJ/85CfJyckhIyODlJQUNBoNoVBI7Of+7W9/+22XK64Wbreb9vZ2UlJSMJlMvP/97yc+Pp7Y2FhRlCsxMZGYmBjm5+d58cUX+d73vsfAwMB1YwjAnxQiI5GMjAxRIhnOe5sPHz7M3NwcWq2WlJQUqqqqKC8v5/bbbyc2NpZAIMDs7Cz9/f20t7dfF94ZgOrqam677Tb0ej0HDx7kF7/4xbqHxtfUGBCEhuLj4zEYDGRmZpKfn09xcTGzs7OiitSmTZtISUkR5SPtdjsDAwPU19eLsqbrjVarJTMzU3SJA2KGamNjI01NTfT09ERszb0gFrTaN5RQx26z2UQ1wzvvvBOdTkdiYiLbtm3Dbre/LWNAuPZjY2O0tra+rfEJi0FnZydtbW00NjaK4aobDbfbzeTk5LpnSwthArPZTGxsLKFQiKSkJJRKJTt27CAhIYHx8XG6urrESgeTySRKXW/bto3k5GTRGyDIFXd0dNDS0kJ3d/e6zudSeDweOjs7KS4uRqVSiY1kEhMTcbvdGAwG9Ho9Q0ND9Pf309LSQnt7+3VXxiYYaEJPFaH0OxLyTgRhKmF9VSqVxMfHk5eXh9frpaCggOrqakpKSsT7z+/309zcLOYYRWrp84UoFApSU1PJz89ncXGR/v5+zp07t+5G2poaAwsLC7z44ouYTCbRir733nspLy+npaWFuLg4UlNTycjIEE8HHo+H1tZWfvSjH3Hq1KmwqQ6azWZuueUW4uPjxdeETebHP/4xc3NzEVM5sN4IWfHHjh3D7/fz2c9+FpVKRVJSEl//+teZmZkR3XjXgs/n43vf+55YUfJ2xzYzM8P8/HxEhm9Wk5mZGY4ePcqjjz4a7qEA58s5n3jiCbGstaGhQTQGhJN0QkLCRSEfu91OT08Pzz77bMTI4NpsNn72s5+JrZrLysrIzMzEZDJRX19Pe3s7/f39YkOiSMsZulry8vK4+eab0Wg0LC0tMTY2hsPhiIgT9dmzZ4mOjubee+8FIDU1lW984xvMzc0RCoWorq6+qALC7XbzD//wDwwMDIS1GuVqkcvlREdHk5OTQ0FBAadOneLcuXNrGua7HGtuDPzud7+jsrJSXODT09MxmUxi0xiNRiPGpwKBAC+88AInTpzgjTfeCOtm63a7GR4eXlEhsH//fl577TVmZ2fDLioUCTidTs6dO8f73vc+tmzZQnJyMgADAwNv+2cKZWVvtzJDSPaKhMVsrQmXR0o4yf/whz9k48aN3HfffURHR4uZ3EKCYEVFhRjG0Wg0aDQaMZZrs9mYmJjg4MGDDAwM0NHRQUdHR8QYcIJBs3//fo4dO0ZUVBR6vR6VSoXNZsPlcuF0OsU2tNcrSqVSvC5er1eUmI6EE/Xk5KSYmCp06rRYLJhMJmBlHtHc3Bzd3d20tLQwOjoa0Tknb0YQSDMYDDidThITE6mtrWV4ePiaw7jvhDU1BrxeL0NDQ7S1tYk9CqKjo0lKShI3DmFx8Hg82O12Tp06xdmzZ8NeliMkcVzosjx9+jQNDQ03bBLateL3+5mZmeE3v/kNbrdbPM2/uRrhWhC8Q9fzAnujI0gfnzp1CrfbLapxChUB8KcmY0qlUhSPcblcYp+L8fFxenp6+OMf/8jAwAB9fX14vd6ICrn5fL4ragvcCMhkMvGaCdUEV9s7Y62x2+1MTEzQ3t5OamoqMTExxMbGihVdQt8ap9NJd3c3jY2N1NfXi5Lp1wNCyE0wyqKiokhPT8fpdDI9Pb2u5errUpT51FNP8cILL/CBD3yAffv2UVtbe5FOfGdnJ6+99hovvvhiREhh2mw2XnvtNV5//XXxtbfKkn43IjSdOXDgwIrXJG5chOZQbW1tdHd3c+DAAW6//XaysrLEElYhqdNsNpOQkMBtt91Ge3s7p0+f5vjx4/T29tLT04PH44mI+LTE+TCP0CTKarWGvS+E1WrlyJEjNDU1cdttt1FbW8uHP/xhtFotcL66oL6+nnPnzvHcc8+JjfCu1/VHo9Fw5513snHjRgYHB9m/f/+65jqtizEguH5/85vf0NzcfEldaavVyvj4OAsLCxHhooI/ibhIvDXX6wN4PeP1esXkyNnZWSYnJ+no6GB4eHjdxuD3+1lcXOTEiRO0tLRcpP6m1WrRarW88MILWK1WZmdnmZqaYnFxUTIEIgDBvV5ZWYlKpUIulxMXF0d0dHTYjQH40/118uRJent7OXv2rLh3CE3s5ubmGBsbiwgZ+HdCMBhkamqKc+fOcfr06XX3jq6LMSC4ftva2t5WYpmEhMTF+Hw+7HY7Q0NDLC0t0d/fz+DgILOzs+s2BiFH453kiUiEj9nZWXp7e0V3tNvtFt3WkcCF95dQYXYjIRw4rVYrQ0NDDA4O0tjYyIkTJ9a/Sih0laZUJMSQrpYrTelGmQfcOHO5UeYB6z8XocufILJ0LWVh0jWJPNb7muj1ehISEvjRj37E8vIyQ0NDfOMb32B6evodlbZJ1+TaUKlUKJXKFc3JVttr9lbXJDLMPwkJibeF0GBKQuLtsLy8jNVq5Yc//CGBQAC73Y7dbpfCo+uMz+cLe9Kj5BmIYCTrOvKQrknkIV2TyEO6JpHHW16TqzUGJCQkJCQkJG5MIquBtYSEhISEhMS6IxkDEhISEhIS73IkY0BCQkJCQuJdjmQMSEhISEhIvMuRjAEJCQkJCYl3OZIxICEhISEh8S5HMgYkJCQkJCTe5UjGgISEhISExLscyRiQkJCQkJB4lyMZAxISEhISEu9yJGNAQkJCQkLiXc5Vdy28URoy3CjzgBtnLjfKPODGmcuNMg+4ceZyo8wDbpy53CjzAMkzICEhISEh8a5HMgYkJCQkJCTe5Vx1mEDi3YNMJsNkMmEwGIiJiSEnJ4eoqCiioqJoaWlhcXERt9vN1NQUy8vLYRujRqMhLy+PpKQk0tPTkcvlBINBxsfHGRkZYXx8HIfD8ZbuMQmJa0WhUKDRaKiuriYmJga9Xk9HRwdzc3NMT0+He3gSEteMZAysAjKZDLn8vJMlFAoRDAbDPKJ3hkKhID09nczMTPLy8njooYdIS0sjOTmZb3/72/T29jIzM8Px48eZm5sLy2arUCgwmUzccsst7Ny5k5tvvhmtVovf7+fgwYO8+uqrvPbaa3g8Hnw+37qPT+LGRqvVEhcXxwc+8AHy8vJITk7mqaeeorGxUTIGJK5LZKGrXMlvlESJ1ZyHTCbDbDazb98+brvtNtRqNUePHuVXv/oVc3NzBAKBd/Tz1zsJR6vVkpqaSk5ODl/60pdISkoiJiaG6OhoVCoVSqWS+fl53G43LpeL//mf/6GxsZHXX3/9LX/2al4TmUxGdnY2X/3qV6muriYtLY2oqCiWl5fFjX9paQmr1co3vvENWltbaW9vv6bfcTmkxKjIYz2vieA1u/vuu7nnnnvYtm0ber0ehULB0NAQL730El/60pfe9s+Xrknk8W65JuvuGVAqlahUKuLi4sTTpnCqvpBgMMjg4CB2ux2bzYbT6XzHm+tqo1arqauro66ujpqaGlQqFR6Ph4mJCf7whz/gdDrDPcSrQq1Wo9VqKSoqoqioiA0bNlBYWEhMTAwajWbFZ81mM8FgEJ/PR11dHTKZjI6ODubn5/F4POs63ujoaNRqNX6/n9bWVsbGxlhcXCQrK4v09HQKCgrYuXMnPp+P/v5+lpeXr8uQQXp6OhkZGZjNZiYnJ+nt7WVpaemyHqjo6GgqKirw+Xw4HI5VM4Te7SgUCvR6Pdu2bWPjxo2UlZURGxuLQqEgGAyiUCiuq83hekYmk6HVaomJicFoNJKVlYVWq0Uul9PT08Ps7Cyzs7PhHuZ1xbobA3q9ntjYWLZs2cIDDzzAPffcg1J58TCCwSA/+MEPaG5u5tSpUwwODkbc5qrX63niiScoKysjJycHAIPBQHZ2NvX19RE33ssRHR1NcnIy73vf+9i6dSs1NTXie5faPOVyOWq1mttuu42srCw6Ojqor69nampqXcar1+tRq9UMDw9jMpmYn5/nmWee4ejRo/T397Nv3z4eeeQR7r33Xh5//HEATp06xdTUVMQZlFfDzp07ef/738/mzZt5+eWX+fa3v01HRwder/eSn09PT+cf/uEfsNvt9Pf38+Uvf/m6D11FAlqtlsTERP7mb/6GnJwcUlJSxPdCoRA9PT2Mj4+HcYTvHhQKBQkJCZSWlrJhwwY+/OEPk5iYiFar5Zvf/CaHDx/m0KFD4R7mdcWaGQMymQyFQoFOp8NkMpGYmMhDDz0kWnKVlZUkJCQgl8sve1q7//77KSsrIyoqit/85jeMjY2FLWHtzaSmppKfn8+GDRuwWCzi6yaTidzcXFQqVRhHd20IRllZWRkxMTEr3gsGgxw8eJDp6WmsVivvf//7SUhIAM4vjgaDgaSkJLRa7bqNd3FxkZ6eHr71rW8RFRWFXC5ndnaWpaUlPB4Pr7/+OomJiaSkpFBRUUFJSQkPPPAATz/9NAsLC+s2zneKTCYjKiqKtLQ0iouL0ev1mM1msrKy6O3tvaQxoFKpUKvV6HQ6FhcXr0tPiIBCoSAqKooNGzag0+k4deoUHo8nbAZdeno6ZWVlotdMYGxsjI6ODv71X/+V/v7+sIxttZDL5dxxxx3U1dVx66238tOf/pSWlhbeeOONcA9NJCsri6KiIr70pS/hdDpZXFzk+eefx2KxkJyczAMPPEBeXh6ZmZn87ne/w263s7y8zIYNG6iurubxxx+nubmZtrY2nn766XBPJ2JYM2MgLi4Os9lMUVERMTExJCYmivE1vV5PTk7OiqQ7v9/P8vIyCwsLohGRkJBAIBCgpqaGmZkZ4uLiaG9vD+uCcOH8srKyiI2NXbERulwuZmZmwj6+q0GpVJKUlERRUREVFRVYLBZkMhmhUAiXy8XS0hI2m40TJ04wOTmJzWajsLCQgoICsrKyUCgUKJVK1Gr1JUM9a0UgEMDlcjE8PHzJ9202Gz09PTQ0NIjGWnl5+UUhj0hHoVCQkZFBUlISJpMJuVwuGtmXIyYmhri4OAwGA319fdeVq1QmkyGTyVAqlaSnpxMbG0tSUhIbNmxArVbj8XjE5NVwkJaWRllZmZhDI1SutLe3c/LkSbq6urBarWEZ2zvFYDCg1+sxGo1s2bKFjRs3smnTJtHojARjQLg3ioqKqK2txWKx0NHRwcDAAGfOnBH3GaPRiF6vp7S0lJaWFnQ6HT6fj02bNlFeXk56ejqDg4MRsR7IZDLUarWYhB4XF0dUVJR4LTweDw6HA6/Xy/LyMm63m6WlJXw+H36/f1XHsmbGQF1dHdu3b+fv/u7vriqOtri4yMTEBPX19Wi1WrKysqioqCAlJYXHHnuMvXv3cvbsWb74xS8yMjLC4uLiWg39qsjNzWXTpk0YDIYVYY6Ojg5eeukllpaWwji6qyMqKor3vOc9VFVVkZiYKL4eDAYZHh7m3LlzHD16lOeee078ew8PD7Nr1y6+/OUvYzAYwjX0t+TEiRMMDAzw8MMPk56ejlarRafThXtY14RGo+HOO++kvLwcg8GA3+/H5XJhs9ku6/YvKCigvLyc1NRUfv7zn3P8+PHrJkSgUChQq9VER0fzxBNPsHHjRmpqatBoNLjdbnbs2MG//du/ceDAgbCMb8uWLTz66KOo1WoAvF4vv/rVrzh69CgHDx7E7XZfl54YhUJBXl4eBQUFVFRU8NGPfhSz2UwoFOLOO+9EoVDwX//1X+EeJnK5HKPRyIMPPsjOnTv5wx/+wC9/+UuOHj0qfkapVFJfX8+WLVvYs2cPIyMjOBwO1Go1n/vc5wB4/fXX+cMf/hARXhyFQkFiYiJyuRytVsvtt99OSUkJxcXFbNq0idHRUVpaWhgbG2NiYoK+vj7OnTuHzWbDZrOt6lhW3RgQJrV582a2bt16SUMgFArhcDiYnJxkbGyMgwcPYrVamZ+fp6+vj+TkZDZv3ozZbCYlJQWj0YjZbCYjI4OysjLsdnvYjYHL4XQ6mZiYWHWrbS1wuVwcOnSI8vJy8vPzWVpaoru7m66uLt544w0mJiaYmprC5XKJ37HZbMzPz7O8vIxerw/j6K+MXq8nPj7+uk3oSkxMJDs7mwcffJCMjAyCwSDd3d20trbS3Nx82XBZWVkZJSUl2Gw2RkdHIyqGrdPp0Ov1xMXFXdKTtHHjRvLy8ti6dStZWVkYjUYAUTfil7/8ZVgWcL1ez86dO6moqCApKQm5XI7X68Vut/P8888zMDAQUcmparWauLg4nnjiCTIzM+nv72dpaYlAIIDZbCYhIQGz2Yxerxe9MRfqihiNRrxeLw6Hg5/+9KecPHky3FMCzm+cggfD7/fz8ssvX3Q/BAIBWlpaGB0d5ejRo9xyyy3U1dVRXFxMZ2cnbW1tPPvss8zNza1Y19YTtVpNcnIy1dXVFBYWsnv3brFaKz4+HoPBIIY/LRYLmzdvxuPxsLy8jNPpZGZmhra2Nv73f/+Xvr4+HA7Hqoxr1Y0BtVqNxWIhJyeHzMzMi94PBAJ4PB66urro7++nr6+P119/HbvdLgrZ2Gw2dDodRUVF+Hw+ysrKUKvVREVFYTKZLplwGCn4fD5cLlfELAxXwu/3Mzo6Sl9fH52dnczMzNDa2kpTUxONjY04HA7cbveK71gslssu5pGE0WgkOTkZhUKB1+tlcXEx4k/IgsswPT2d7OxsCgoKyMvLIyoqimAwyNjYGOPj45c8EQjhg8zMTLKyspDL5fh8vojJsREqiFJSUsjPz7/kM7x161YKCwvZvn27eO+NjIzQ09NDf38/TU1NzM/Pr+u4ZTIZer2eqqoqUlNTRQN4bm6Ovr4+ent7V/2E9k4R7gUhpyk6OprFxUUCgQCJiYlkZWWJeT7BYJBAIIDBYBCrIQKBADMzM3R2dvLGG2/Q2dkZ7ikBfwoTKJVKgsEgQ0NDF3lgQ6EQNptNLDNOTU0lMzOTuLg4/vjHP3L27Fk6OjrCuj4LYmmbNm2ioqKCHTt24PV68Xg8LC0tiXkQk5OTK75nMBhISUkhNzcXo9FIS0sLU1NTOJ3OVZnPqu+qcXFx7Nu3j8rKyksaAwsLC4yMjPD5z3+egYEBJicnL5rI6OgoY2NjtLS0cMstt/D9739/tYcpwfkHx+l08vLLL3Pq1Cn6+vpYWlq6rMUsl8v5/Oc/T11dHfHx8es82mujuLiY97znPajVaoaGhjh9+vS6lT6+XQRD4Hvf+x5ZWVlYLBbxdOx2u2lsbGRoaOiS31WpVJhMJjZt2sSWLVtQq9WkpqZiNpvDvlnJ5XLi4+PZs2cPt912G3fffTc6ne6i5/5CL05TUxPd3d0cPnyY48ePMzY2FpYFXKvVYrFYePDBB0lPTxfH8Prrr/OTn/xk1U5lq8ny8jJjY2M0Njbi8/nQ6/XiZh8dHU1sbCxms5mFhQXm5+dZWlqiuLhY/Pvb7XYOHDjAF7/4Rex2e8R5OQVht0AgcFkDPy8vjz179nDPPfcwOzvLr3/9a37yk58wOjoa9oNaXFwcf/Znf8bWrVtFr9+ZM2doamritddew2azXTLReevWrXzkIx+huLiYoqIiPv7xj4vG6OUqi66FNTliv/nU6Pf7WVxc5A9/+AOdnZ309/fT3d3N0tLSZS9MKBQSre/XX3+dmpoazGYz9913H52dnUxOTkbMqed6Z2pqCrvdztLS0ls++ImJiRFtCKhUKmpqati1axc7d+7E6XTS2trK/v37I7bUU/AI3HfffWzfvl3MEdBoNMhkMqamphgYGODVV1+9rDFgMBgoKSkhJiaG5eVlWltb6e3tDbsanl6vx2Qycf/994v1+cK83ozNZmN2dpauri5eeukl+vv7GRsbC5vKJZyvDkpOTiY1NZWoqCjx5CmELiI5UfjVV1/lxIkTohdGJpOh0+nEBNPl5WXRQP6Hf/gHUlJSiImJ4fDhwzQ0NIjehEghGAzidrvxeDxoNBoeeughDhw4wNmzZ1d8zmAwUFxczB133EFfXx9NTU289NJLTExMXOTpXG+MRiOpqals3rwZmUxGS0sLTz31FCMjI8zMzDA1NYXX672kampvby+tra1kZWVhMBjIzMwUtVYi1hh4M16vl/n5eQ4fPkxLSwtDQ0NX9YA7nU5mZ2fp7u6muLgYi8VCRUUFsbGxKJVKyRhYJRwOxxVPOHK5XFxEYmNjRVep0+lkYWEBu90eEZK/gghJXV0dZWVlZGRk0NLSQmdnJy0tLavywKw2giFgsVjYunUre/fuFZM5g8EgVquVvr4+mpub6ezsvGSujJBYVVxcTHR0NMvLy7S3tzM5ORm2RFa5XI7ZbCY+Pp7k5GS2bdtGcXEx8fHxFyVACie9wcFBhoeHOXPmDG+88Qbj4+Nhf8bj4uJIT08nJiYGpVKJz+djfHycqakprFZrRIeeuru7L3pNqVSi0WhQqVQEAgFCoRBRUVEsLCwQFxeH1+vl3Llzly1dDSfBYBCPx8P09DTz8/Ns3bqVrq4uuru7cTqdYhghKyuLvLw8cnNzOXLkCOfOnaOtrU3MmwgnJpNJ7KUyMjLC8PAwv/71r1lcXLzi31ulUomVBH6/H7/fj8fjIRgMrlpe1LoYAzMzM3R0dPDTn/4Ur9d71Va+3+/H7XaLriqlUklcXBxarfa6TQy7HomKimL37t389V//tRiPDgaDHDt2jOPHj/Pzn/887A8ZwIYNG6irq+OrX/0qer0ep9PJ1772NVpbWxkdHQ338C6JXq8nPT2dP/uzP2P37t3k5eUhk8lYXl5mfn6eJ598khMnTtDY2HjZ8E1MTAwbNmzgYx/7GMnJyQwPD/Pcc88xMTGxzrP5E7GxsXz2s58VBblyc3MZGRnh+PHj/P73v1+xyQcCAZaXlzlw4AA2m000DsLtzgXYu3cvt99+u3jPLy0t8T//8z+88cYb2O32cA/vmhE2EgGj0UhsbCw5OTkYDAZmZmbYv39/RGTav5lAIIDNZuOpp57i1KlTPP3000xMTOD1ejlw4AAqlYqEhAT+7d/+DbPZzNTUFP/xH//B0NBQxCScV1RUUFdXh0KhYHp6mqGhobcMxQjy6+Xl5ezYsQOlUklzczPf/e53aWlpWTWDf1WNAaGSICEh4aIazmAweM0PuEqlErOPBatckL2NZIv8RkIul7Nv3z62b99OUVERGo0Gn8+H2+3m7NmzNDU1rbshYDKZiIuLo6amRhTYycvLIz09nZSUFDETV6FQkJOTQyAQICoqCp/Ph91uD+smKaDRaLBYLOzatYuSkhJuueUWUdFueXmZkydPcubMGV577TXGx8fxeDwXPTtRUVEkJiZy1113UV1dTWpqKmq1WsxWTklJIRQKrZvWgCARu3nzZsrKytizZw8WiwW9Xk99fT3nzp0T/735xO/3+1lYWIi4+HRWVhYlJSXI5XLcbjcLCwucOHGCkZGRcA9tVbBYLGzYsAGNRsPCwoIodR1pXoELsVqtDA0N0dTURF5eHo899hhnz56loqKCbdu2kZ2dTV9fH0ePHmV6ejpsVQOXor+/XwyzCsm0WVlZTE9Pr9jU5XI5WVlZYvXHTTfdRHFxMWlpaSwsLDA4OMiZM2dW1fO36saATqcjNTV1VRTp1Go1BoMBi8UixkXGx8dxuVySMfA2EcQthI3lzR6WCw02hUKBVqtl+/bt1NXVkZycLJ5aFxYW6OjooKenZ13HL5fLSU1NJS8vjzvuuAOtVovRaGTz5s3odDpUKpUonKRUKiksLBQFrDwej+h6drlc+P3+sIQ3BGXBvLw89u7dS0VFBeXl5WImt9Vq5ezZs7z22mt0dXUhl8sxmUwXXav4+Hjx71BYWEhsbCxwPlySk5MjnlyFk8dan7SVSiUJCQls3bqVHTt2UF5eLvbrGBoaoquri7a2NrH1tdfrJRAIEAgEIs4IkMvl6PV6UlJSxMRBt9uN1Wqlq6srYvNPrhWLxUJRUREqlQqHw8HY2FjEH7YcDgdTU1M0NDSwbds20fO0detW7r77btRqNWNjYxw5ciTiDMzx8XGGhobweDyimmhJSQlarXaFmJZSqaS0tJS0tDSys7O56667sFgsxMTE0NPTw9DQEAMDA6s6tlU1BgSxoMcff/yi0qG349ZPSEgQs8IVCgXDw8P87Gc/o6+vL+IzwyMRjUaDRqPBZDKJddEGg0HcPIXTmZDJmpqaSmlpKTt27CAjI0P8OUtLS7S1tdHR0cHg4OC6jV/ImP/Hf/xHdu7cKW5+QqxQ2NxDoRAqlQqdTscHP/hB0SsFfyoJ+8lPfkJ7eztnz55dd3d0VFQU5eXlfOMb3xDLhATsdjs/+MEPqK+vZ3BwkH379lFXV0dVVZXYiEWYS0xMDMnJyRcJX6WkpPDZz36Wrq4uOjo6RFfpWlcVJCYm8pnPfIabb755RfmgVqvlPe95Dzt37mRxcRGHw0FnZycNDQ0MDAwwMjJCV1fXmo7tWklISODxxx+noKBAfD7OnDnDkSNHImpzeaeUlJRw1113icJO14N6qs/nY3Jykq985Svceeed7N69m2effZaYmBhCoRCf+cxnOHfuHK2trRE3l6WlJUZHRzl48CDV1dUUFBTwox/9CI/Hs8IbI5PJxORAjUYjllO6XC7++7//m4aGhlUf26oaA8Kpc7V0+eVyOXK5XFxUQqEQy8vLEXeBIx2tVivKuqakpJCdnS3W3aempgKIJx/B4uzv76e6upo77riDpKSkFep9S0tLtLa2XrFz3lohiKR4vV66u7vx+/14vV6sVisDAwNMT08TCASwWCzEx8cjl8uJjY0lMTFR9Fjl5+dz//33U1xcjMFgoKmpaV16FghGS01NDRs3biQjI0MMaQhotVq2bNlCRkYGCwsL5ObmiuEP4bkSjBeNRrOiPlzA4XDQ2tpKa2srw8PDGI1GUTVvrUhOTqa4uJht27aRnJy8Yg0QavWVSiXR0dH4fD6xOVZfXx9tbW14vV7GxsYixj2t0+moqakhNjZW/HuPj4/T0dEhrj8ymQyLxYJCoUAulzM5OXndrU3Cei2TybDZbHR3d0fMNbgSwWAQp9PJ8PAw3d3dPProo+j1etF7E2mVEALBYBCHw8GJEyfweDxkZ2eLB4I3y4wrlUpcLhdTU1OkpKSIYc6hoaGLNAhWg3VJIBSMBOH0di0nMSlR8J1xYab5HXfcQXFxMeXl5czNzeH1esnNzRWNLWETaW5u5tChQ2zfvp33vve9GAwGMbQgKEe2tLSEpcY6EAhgt9sZGxujq6sLt9uNy+Wir6+PN954g66uLvx+P7m5ueTm5qJQKERXXHV1NQkJCVgsFvbt2yeKWg0PD69LUx+FQoFGo2Hjxo1s3rx5RYMrAUHtTsgSjo6OFk+mwmuXEnwSxi4Id/3xj3+kubkZq9WKVqu9Yj+D1SAxMZGcnBw2bNiAQqEQjbQ3o1arMRqNotcvLy+P2NhYRkdHxXsyEtBqtZSWloqnTYDJyUl6enoIBoMolUq0Wi3Z2dliQrPH48Hlcom68ZGQAHklhHtJeLYFYyASKoOulsXFRaampkSPmVCWFwwGV3jRIgmHw8HJkydxOBxMTEwQExODyWS6SNHV4/Fgs9mYnJwkISGB5eVlZmdnmZiYWJMeGOtiDMTFxZGTk8OePXtEqcirQUgCgz+VH0XixY1kSkpK2LZtG1/72tdEd5NKpWJqaoqpqSlOnz5NZWUl+fn5REdHs2nTJqqrq3n/+98vutoFgywUCnHfffdx7tw5XC7Xui/cPp8Pm83G5z//+RWGpRDiuLB5x9DQEKOjo6IamzDvxMRESkpK+PKXv0xqaiof+tCHOHnyJIuLi2vuRler1cTHx3P33XevaBMtIGzyF/Z8EP72wWCQpqYmsUHWmxEWiq997WucOXOGnp4eMWQCrLlru7u7G4/Hw89//nPRyPnNb35zkSdPrVbz+OOPk5WVRVpaGpmZmQSDQXw+H+3t7RGT9X0pnE4nVquVUCjETTfdxL59+3jPe94j5kfNzc3R1tbG73//e7EyIlLXK7lcLuonJCUlMT8/z8TEBENDQ9eFMSAccj74wQ/yyCOPsLy8zOnTp2lra+Nv//ZvOXLkCM8++yyDg4MRNx+n08np06c5e/YsGo2GZ555hoSEhBXhQjj/7FdXV7Nnzx7kcjljY2P85je/WTMv5qoaA0Id6NTUFGazWXRNCu5MIbP4rdBoNERHR7N37142btwIIGqtt7a2RvSCESkInfo2bdpEWVkZsbGxYtcrIdO2u7ub8fFx5ubmmJ2dZc+ePahUKtFtCH/qKDk9PU1HR8e6xJ6vRCgUuqqHQUhMezPCwmC320lOThZ7XoyMjKz5vGJiYqioqCAuLu6SHdMuTOoMBAL4fD6xbffy8jJdXV0YjUasVitpaWlERUVhMBiYmJhgYGCAgwcP0tDQIDZnWWuExWtxcVE0Rl599VXx9ebmZvx+/4rroFKp0Gq1lJeXU1dXR1FREUajkaysLOLj47FarRGbnCds7EJL6erqapKSksR1LioqCqVSiVwuZ2pqit7e3oitOlCpVKIWh16vx2az4XA4whL6u1bkcjkxMTHcddddokDXL37xCzo6OpiYmGDr1q1UV1cD8MwzzzA9PR1RSpGhUAifz4fP58Pj8TA8PIzVal2xJgjGTklJCYmJiSgUCmw2G2fPnl0z4aRVNQYCgQAOh4P+/n60Wq34kKhUKqKiooiPj7+qznF6vZ60tDQeeeQRSkpKgPMuuu7ubk6cOLGaQ75hSU9P59FHH2XXrl1YLBbRxT89Pc3Jkyd57rnnOHPmDE6nk/HxcSYmJti+fbsYfxY2JiFPo6enh2effXbdteFXG6fTKWqa+/1+tFotGRkZpKen097evqa/Oy4ujh07dhAdHX1JF7Lg5RDyNxYXF6mvrxeT7qamplCpVKKhLKji9fb28vrrr/O1r31tTccvIHhbhPtK2ECsVisvvPDCW36/vb2dbdu24Xa7yczMJCoqioyMDBITE5meno5YYwDOr2WlpaVUVlZSVVUlrmfBYBCj0YjRaKSoqIi+vj6USmVEyN9eCrVazbZt28jLy0Ov1zM2NiYaA5GOoDfz4Q9/mPz8fJaXl/nWt77F1NQUMpmMT3/601RVVbFr1y4aGhrw+XwRZQxcSDAYZH5+/qJ1VS6Xk5GRgUKhID09HZ/PJ3py1+r5WFVjYHl5mYmJCX77299isVgwmUzX/DPkcjkpKSnceuutZGdnYzabgfMd9iKpXjSSESoGMjIyMJlMqFQqlpaW+PGPf8zp06dFt3gwGCQjI4NNmzaJXoFLsbCwQH9/P6+//vp1sVhciZSUFDZt2kRBQQFGo5GpqSlOnDhBfX39mv9uk8nEhg0bLusd6+npYXp6GrvdzokTJ2hpaaGlpQW/3y9qsQvGQGVlJUlJSYRCIZ5//nlOnz695uMXyM3N5Z577kGtVosaBlarFbfbfVWKgYLnSQhjaDQazGYzWq121ZKP1wKdTkdKSgpf//rXSUtLQ6fT4XA4RBlZwTiQyWR84hOfoLy8nMHBQUZHR8Mug3shCoUCo9HI448/TkJCAj6fj1deeYVz586Fe2hXhVarxWQyUVlZSW9vL83NzczMzOB2u5HL5fyf//N/uPvuu3nkkUfYtGkTgUAgYj00l0OhUFBRUUFGRgZ+v59PfOITnD17lrm5uTVLjFxVY0A40YyMjLCwsMDy8rLo+hD6NgvZz5ebkEajISUlhc2bN2M0GsU4amdn55qf3K4FoSPcm+v1BaGkcCU+ymQyysrKKCsrIyUlRRQTeeONN2hoaKC/v1/UW4+Ojqauro5NmzaRk5Nz2U6EQjVCTU2NWLt7vSGXy0lLS6O8vJw9e/aI5ZV9fX3Mzs6uy8nBZrPR0NCA0+nEbDYTGxvLzMyMWCbb3d0tujSFss2pqakVJ0tBDvpCI298fHxFjfJaYzabqaurQ6vVsri4SGxsrJjU1NPTw9zcHE6nc0XWfXR0NAkJCSQkJJCamkpJSQlFRUWi91Amk2EwGFZFn2S18Hq9YtJmKBQSpWSXlpZYWFggFAqJsskzMzNYLBYSExPFluuC7KywUUUSgnaFVqvF5XLR3d3N1NRUuId1VaSnp4v3TldXF4cOHWJ5eVkMb/T09IgGWGlp6Zpk3q8lgsFfXV1NRkYGoVBIlL9eywqJVU8gFGIgMzMzLC4ukpCQAJx3SxUWFpKQkIBWq72sq8NgMFBQUMA999yz4vUDBw5w5MiR1R7u20Zw4/r9ftRqtbj5a7VazGbzmmdvXw65XM4999zD5s2bKSwsBKCrq4vvfOc7tLe3o1AouP/++0lJSSEjI4P3ve99K0SIBDf1hcZMbGwsdXV1GAwGOjo6wmoMXBjCuFrkcjkajYbNmzdz00038cEPfhCVSsXg4CAnT55kZmZmXZIhBwYG+MEPfkBmZibJycmUl5dz/PhxsZnQ6OjoW/5tLRYLNTU15ObmotfrmZycXLPs4ssRFxfHtm3biI+PF0/yQknqs88+S319PcPDw6InT6lUkpKSwpYtW8RmRULpJyAmfppMJmJiYtZtHldCKAELBALisyCIXR05coTi4mLS09P51re+xdjYGE6nk9LSUioqKsScCYPBQFFREZ2dnRElXSyU5wr4/X6am5uvm9NzVVUVu3fvxu/3c/z4cf73f/9XfC8YDDI8PMzo6Ch2u53t27evq6G8Guj1eiwWC3fccQeZmZnimrzWrLoxsLS0JN5YOTk5ojGg1WrZsWMHfr+fvLw8vvOd71y0AMtkMuLi4lZkVfp8PpaWlvB4PBFVN3r69GkmJyf5wAc+IKqVAVRWVmKxWHjllVfWfdPMzc1ly5YtvPe97yUjI0N84KOioigoKOCjH/0oOTk5pKWloVKpUKvVKJVK8WZzOp387ne/48CBAwDs2rWLe++9l6ioKFH+t7a2FoC+vr51nVt8fDwlJSU88cQT/PSnP6W9vZ2xsbG3/J5cLmfjxo3ccccd3HvvvSQkJBAIBDhw4AD19fX87Gc/W7fFQkiyW1hYoLOzUywvEjL938og0Wq1bNiwgUcffZTo6Gj6+/t58cUXmZiYWFcRroGBAb7//e+zc+dOMjMzKSwsJCUlhfj4ePLz82loaKC7u5uGhgYqKiooKioiJyeHuLg4TCaTmGgn0NDQwFNPPcXRo0fX1ai5EnNzc/zXf/0XH//4x4mPjycUCrF9+3ays7N56qmnOHHiBLOzswQCAXbu3MnOnTvZsWPHitCo2+1mdHQ07M2W3kxNTQ2bN29GpVLR09NDc3MzY2NjER8CFOTuy8rKqKyspLOz87L3S29vL8899xwf/ehH0ev1xMfHMz8/H1F7yOXIzs5m8+bNYoigra2NoaGhNX82Vt0YEMQgJicnmZycpKioCDh/IaOjo8nOzmZpaYmCggImJyfFxiRqtZqoqCiqqqrIzc0Vf55QQy6EHSIFod6+tbWV0tJSsdzLYDCQnp5OaWkpMpmM8fHxdVMsExI1Y2JiVsSlo6OjqampoaamRsxCvxCbzSbWGAvhBDhfOz43N4dWq0WpVGIwGKirq0On0xEfH8/g4CCLi4vr4gIVciDq6uro6+tDp9Ph8/nEEsfl5WWxhDAqKorY2FhiY2MxmUzU1tayefNmMjMz8Xg8dHV1ceLECZqbm5mYmFi3BUKozBDuh2sxFuVyOXl5eRQUFIj6CXa7ne7ubtxu97omqQnhDrVazdzcnHhvaLVaUlJSxPp8vV5PSUkJOTk5JCUloVKpRCPA7/fjcrno6OgQ+zDMzMxEzDPudrtpb29nfHwcu90uNvSRy+WifK8QPisrK6O6uprY2FjUajXBYJD+/n66urrEapBIQJDBLiwspLa2FoVCwdzcnHgPXQ8bpdD/Qq1W097eftlnyOPxYLfbsdvtuFyu62Zuwh5ZVVWFWq1maGiI06dPs7CwsObeyzXTGWhra8NkMrF79+4VLqnU1FRUKhXvf//7ee211zh8+DCBQACTyUROTg5//dd/vcIYmJ6eZv/+/QwMDERcSaHb7ea///u/eeyxx0RjQLBeP/zhD3Po0CGeeeYZHA7HupTrCHKiTqcTn88nxmOTk5P56Ec/Kn7uwjyHYDBIW1sbp0+f5kc/+pEY3gHIzMykra2NhIQEMezxkY98hIWFBYaHh/m3f/s3mpqaGB4eXvO5ZWZmkp+fT25uLh/96EfFngiDg4PMzMwwOTmJVqslOjqawsJCtm7dytatW6moqCAmJkbs397V1cWzzz7Lr371K+bm5tZ83KuFWq3mvvvuY9euXeTk5ODz+bBarTQ1Na17PHp2dpbXX3+drq4usrOzGR4epqSkhJSUFEpKSsjIyCA7O5u9e/eu+J7f7xfzbJaWlpiZmeFLX/oSvb29EdE86kKERlzNzc2kp6dTU1ODSqUiPj6eT3/607jdbrxer2goX6iH4vP5+PnPf87Jkyc5e/ZsmGfyJ1QqFVlZWdx00028973vRaVSMTo6SkNDQ8SIPV2JC43ppaUlTpw4cdl8AEEUamBggMHBweuiCkporLZz507uvfdeAoEAp0+f5sknn1zTxEGBNTMGTpw4wcTEBGq1mptuuon8/HxUKhVGoxGtVssjjzxCYWEhO3bsIBQKkZqaSn5+PoWFheLJdXZ2lo6ODl5++eWIXLj9fj+dnZ20tbVRUlJCfn4+CoUChULBzp078Xq9nD59mo6OjnWphJiamuL48eN87WtfY8OGDezcuZOSkhJRxObCjo+dnZ2MjY3R09NDe3s7/f39jI+Pr1gU+vr6+PWvfy02nBFEiBYWFhgbG2N4eHjdko5aW1tRKpUcPXqUwsJCysvL+ed//mccDoeoQqhUKlGr1cTGxhITE0NMTAxRUVHMz8/T3d3Nj370I3p6eujp6bkukyABsY/5sWPHxO554VrIZ2dnWVpaYmxsjKioKNEzJSRHlpSUrDgIDAwMMDAwgNvtFkWi+vr6Ii657kJ+8Ytf0NLSwhe+8AWys7PFsKdGo0GtViOXy8U5ClnrDQ0N/Pa3v424NsAajUbsbqnVagkEAqKCX6RrC8CfGmGlpaWRmJgolkNeiEwmIzk5maqqKm6//XaOHDlCa2trmEZ8dQhlhHl5eXzqU5+ioKCAqKgo+vv7GR4eZmRkZF28y2tmDMzNzREMBjl+/DjJycno9XqysrJQKpUolUr0ej2BQIDo6GjgfGJUenq6KH0LiIpYIyMjEeNqu5BgMMjc3BzT09PMzMyQk5MjnhDi4+OJj49fMZ+1RohJNzY2srS0hEajQaVSiQ19BO+K1+ulo6OD0dFRuru7RSnYN/+NbTYbnZ2dzM3NYTQaiYmJwePxMDc3R0dHB/Pz8+t2XQRN7uPHjxMKhUhJScFisYi1uIL8qPB3EBQr+/r6GB0dpaenh2PHjjE5OXldGgIymUx0Qy8tLdHQ0LBuRubl8Hq9eL3eizx2QojGarWuMAYGBwdFY+B6YXR0FK/Xy6lTp3C5XOTk5JCenr7CCPB4PDidTtG4PnHiBMPDwxF3GlWr1eTk5Ih5DfPz81it1ohWSrwQIRFYp9Oh0WhW5JEpFAqioqIwGo2UlZWRn5+P0WgUn/9IRQjdFBUVieqvUVFReL1eWltbGRoaWrfnZc2MAWGjfO6553C73QwMDPCZz3xmRZZ9VlbWJaVV4bxL6MiRI5w4cSKiBSPm5uaYmJhgdHRUVEsMN11dXfT393PkyBFuv/12MWv74MGDl7SmL8fs7Cx2u53m5maUSiVlZWV0d3dz5MgRvvvd767rdREaE33lK1+hrq6O/Px89u7dK+YCCDkSy8vLnDhxguXlZTweDz/5yU8YGBhgaGjouljwLodSqWTbtm1ER0czNDTEU089dVUJlOFAEFFZ7Rar4WB5eZmxsTH+6Z/+iZqaGurq6vjHf/zHFWpxExMTnDt3jv/3//4f/f39EZmVr1AoMBgMbN68maSkJHw+H/X19TQ3N1+X10kwDASRNKPRSGVlJbW1tTz++OM4nU76+/s5dOhQRJdMqtVqcnNz+eAHP8iDDz4InNfsGBkZ4V/+5V8YHx9ft7GsS2+Cnp4elEolZ86cISMjg/j4+ItaHAv4/X5xI3vhhRfWtUXuapOamsq+ffvo6elZd4PG7/fjdDo5duyYuHC9nXpnv9/Pk08+SWxsLEajEbvdLkrGhmNzDYVC9PT0MDExQXt7O//7v/+LXq8XvQLBYFBswxoKhRgZGQnbWFcTodJGrVZfl56N6xmhdWxrayujo6N0dnau8PY5nU7RcxWp6ollZWVUVVVRVlaG0WjE7Xbz8ssv09HREe6hXTV+vx+bzcbU1BRut5uPfvSjHDp0iN7eXt773veSmppKfHw8NpuNkydP8tvf/jaiSjrfTFxcHJmZmXzxi1+kqqoKOL++tba2cvDgwXXXp1gXY2Bubo7+/n4xUSUYDJKcnHxRrevy8jJzc3O0t7dz6NAh0RUd6SwuLjI2NkZHR8eKE4MgHxsOASIhkemdWpahUIimpqbVGdQqIWQJR+rJeLVRKpXodDr0ej1er5f5+fnr3ri53vD7/czNzTE3N7fuZbWrQXJy8opSb7vdTmtr63VVgy8YZZOTk8zNzVFeXo7T6cRisbBjxw5UKhV+v5/GxkaamppobGyMyPCygFAhtX37doxGI8FgkOnpaTo7Ozlz5syKsuP1YF2MAavVitVq5dOf/jS33XYbN910E5/85CdX9Fifnp6mu7ubZ599lvb2dhoaGiJS0/tSHD58mCNHjvDlL3/5oveE2LWExNvFYrFQUFCAUqmko6ODF154IWJDZxKRSXx8PKmpqchkMhYXF5menqa9vf26uo+EPimHDx/G5XLxV3/1V+zbtw+lUklLSwv19fXU19fz61//GpfLFfH7R05ODpWVlaJI3dLSEk8++SSHDx+mvr5+3ce/LsaAQDAYpKWlhdnZWdra2lbkDzidTlEDf35+PuIv5IWsl0KUxLsTQU/gr//6r8VY/PWUhCcRfoLBIH6/n4WFBf7whz9w+PDh66Kc8FJ0dnYyOzvL0NAQGo0GmUyGzWZjdnZWlPe+HtbjvLw8KisrkclkOJ1OsYncyMhIWMa/rsYAwPj4OOPj4zQ2Nq73r5aQuC4RmnT9/Oc/D/dQJK5THA4Hs7Oz9Pb2cuzYMQ4ePLiuLujVZGpqiqmpKdra2sI9lHeEyWQiLi4OOF+5NTQ0RG9vb9haxMtCV2mChKvxztvhSlO6UeYBN85cbpR5wI0zlxtlHnDjzOWdzEOhUCCXy1EoFPj9fjHBdq2Qrslbc8stt7B161Y+//nP8/TTT/Pyyy9z+PDhNTPS3uqarLtnQEJCQkJifQkEAgQCAXw+X7iHIvH/p7u7m6WlJex2Oy0tLfT19YVVNlnyDEQwknUdeUjXJPKQrknkIV2TyOMtr8nVGgMSEhISEhISNybro5MrISEhISEhEbFIxoCEhISEhMS7HMkYkJCQkJCQeJcjGQMSEhISEhLvciRjQEJCQkJC4l2OZAxISEhISEi8y5GMAQkJCQkJiXc5kjEgISEhISHxLkcyBiQkJCQkJN7lSMaAhISEhITEuxzJGJCQkJCQkHiXc9VdC2+Uhgw3yjzgxpnLjTIPuHHmcqPMA26cudwo84AbZy43yjxAamEsISEh8Y6Qy+UolUqUSiWBQIDl5eVwD0lC4pqRwgQSEhIS74Da2lq+9KUvcfr0ab75zW+GezgSEm8LyRiQkJCQeJvo9Xqys7PZvn07ubm5mM3mcA9JQuJtIYUJ3gYKhYJQKCT+k4gs5PLzNq5MJrsophcKhQgGg9J1k3jHyGQyzGYzxcXF7N27N9zDkZB4R0jGwDWSmJjIv/7rv3LmzBmam5s5duwYgUAg3MNaVeRyOenp6TgcDqxWa7iHc9VERUURFxfHBz/4QXQ6HVqtlptuugmNRkMoFGJ8fJzOzk4OHz7M8ePHsdvt+Hy+cA9b4jpFo9HwiU98gu3btwMwOzuL3W4P76AkJN4m624MqNVqVCoVACaTidjYWHJzc1EqlQSDQc6ePcvS0hLLy8sEg0ECgQBer3e9h3lZNBoNVVVV6PV6zGYzMzMzTE1NYbPZwj20q0KhUBAdHY3FYsFkMpGamiq+J5fLCQaDKBQKkpKScDqd2O128XUAu92O1+sV33M4HMzNzYVrOiIymYzs7GxKSkrYsmULWq0WlUpFSUkJKpWKUChEXFwcRqNRnM/w8DADAwM4nc4bzqCLFBQKBQqFAq1WS0xMDDExMcD55ygqKgqz2UwwGMTtdnPq1CmWlpbCPOKrR6FQUFZWRnp6OsFgkPb2doaGhsI9LIkroNfrSUlJITMzE51Oh9/vp7Ozk9nZWVwuV7iHF1bW1RiQy+XExMQQHR0NQFVVFZs2beLjH/84BoMBn8/HE088QXd3N1NTU3i9Xtxud0SdTtVqNXl5eaJr0OPxcOjQIU6dOhXuoV0VGo2G3Nxc9uzZQ3V1NQ8++CByuZxQKCS61K/0301NTUxPTzMyMkJjYyN9fX0cPnw4XNMRUSgU3HTTTdx///1s27ZNDOXAn0pqEhISsFgsbNy4kQ0bNlBfX88zzzzD4OAgTqcznMO/IZHL5eh0OnQ6HYmJiVRWVrJhwwbgvIctKyuLTZs24fP5GB8f57777qOrqyvMo756lEoldXV1JCYm4vf7+fWvf83p06fDPSyJK5CUlMQ999zD448/TmpqKktLS/zzP/8zhw4dYnh4ONzDCyvrZgxoNBoqKip45JFH2LVrF3DerRsVFYVGoyEYDCKXy/nSl76E2+0WF4iOjg5+9atfAeDxeJiammJxcTGs3gK5XI5cLicqKoqPf/zjJCYmolarOXXqVER5MS5FWloa//7v/05KSgomkwmZTEZPTw9jY2MsLi6KG6dMJrvov2UyGXV1dWRnZ1NVVcXOnTvp7u4GoK2tLWweAqVSSWpqKqWlpVRWVqJQKN7yO1VVVWRlZVFbW8sXv/hFmpub17UkTDgtZ2dnk5+fz4c+9CEcDgcjIyN8+ctfxu/3r9tY3i4xMTGo1Wo0Gg0AWq2W3NxcMjIyiI2NRa/XU1paSlZWFiqVCr1ej06nA8Dn8+F0Ovnxj3/M8PAwfX19TE5OhnM618TmzZvZtWsXer0egGAwyIkTJ64rY+ZGRyaTUVpaitlsxmw2c/fdd5OVlUV2djbx8fEAK9a8dzvrYgxER0cTFxfH1q1bqa2tpaKi4qLPCBckOztbfM1isRAdHc3s7Cxw3kV9+vRpvF5vRGy6CoWCtLQ0CgsLKS0tpbGxMSLGdSUEI8bv9zM/P8/k5CRNTU309fXhcDjeUmAjFAqRnJxMSkoKqampKBQKampqGBsbC5sxIJPJ0Gq1REVFYTQaL/s5r9crGjUGgwGtVkt0dDQxMTEolcp1NwZiYmKoqqqiurqaLVu2MDs7i1arvW6ETLKzs7FYLFgsFgDRuElLSyM2NhatVkthYSFpaWm4XC5CoRCBQACXy8Xs7Cw9PT2cOHGC0dFRRkdHcbvdYZ7R1aHRaMjOzmbLli2o1WocDgdTU1PMzc1FrIfJZDIRHR1NSkqK+KwajUY0Gg1qtZro6GhkMhlyuRy/34/D4WB2dhan0ymGCCMZmUwmzgXOe3B1Oh2bN28mISGB+Ph4tmzZQlJSkrhGeL1etFotGRkZZGdnMzIyEnbDQKPREBsbi9lsJiEhQUyGdrlc2O12pqam8Hg8GI1GCgoK6OzsZGFhYVXCnOtiDBQUFFBTU8OXv/xloqKirvp7ycnJJCcns2PHDgD6+/v5xje+weLiIouLi2s13LckGAyueEBKSkqQy+X84he/iPi4k91u59e//jVw/nQ2ODjIuXPnGBgYuKrv/8d//AdFRUX8xV/8BQ8++CDp6en8+Z//uWhQRDJzc3P4/X5kMhlJSUmoVCpx07oab8JqotPpyMrK4i//8i/ZtGkTcP2dUh588EG2bdsmPp+XIxAIMDk5icvlwuVy0dPTw8GDB3n++edFA+16QS6XEx8fz8aNG7nnnnsA6Ojo4LXXXsPhcIR5dJenvLycmpoaPvKRj/Dkk0/y29/+lo0bN5KUlERiYiIbN25Eo9Egl8ux2+00Nzfz8ssv09HREfFrGoBKpSIpKYmkpCTgfEgwMzOTz372syQmJoreqwsNbZVKRWJiIg899BB5eXkcPXo0rPeiXC7HYrGwZ88ebr75Zu6//360Wi2hUIiOjg5OnDjBM888w/DwMBs3buR73/seH/rQhzh58uSq7IdragwYDAZqamp473vfS21tLQaD4W0vugMDA7S1tdHb2xt261uwoIVTZkJCAsFgEKUy8oszbDYbv/zlLwHExK1rvZE8Hg+jo6N4PB5UKhXp6emi+zccBAIBZmZmePbZZ2lqaiIpKYnY2FhiYmLweDzMzMwwMjLC4OAgJpOJoqIi/uzP/ozExMSwjflS6HQ6jEYjUVFROByOK4YKhIWvoKCA7u5uZmdnmZiYWMfRXozgbWppaRFd/6FQCJ/PJ3qeXC4XTqcTq9WKz+e7rgwBAKPRyP/3//1/1NbWEgqFsNlsnDp1iv/6r/8K6wHlrdi2bRv79u0jPT2dJ554gnvuuQeLxYJGo0Gj0RATEyOeQv1+P0lJSZhMJv7v//2/EW0M6HQ6YmJiuPnmm9m0aRM1NTUAYvgqISFBTFi/HElJSeTk5FBeXs7w8DDz8/PrMfQVREVFkZCQwN/+7d9SWlpKTk4OXq9XrHZKT09n165dWCwWxsbGsFgs6PX6FeHcd8qa7l5arZaioiI2bNhAUVHRO9osXS4XS0tLuN3usMZT/X4/s7OzmEwmMV6o1WoxmUxYLBbcbndEnxC8Xu9VewEuRyAQEDPwhbDDep+sLyQUCuFyuWhvb2dycpLU1FTi4+OJjY3F5XIxMzPD2NgYXq+X9PR08QGLNHe8SqVCq9Wi0Wgue58rFAox/yYnJ4fi4mL0ej29vb3rbgzYbDbm5+fx+/0oFAr8fj/T09M0NTXR2tpKZ2cncP6ZGRkZwel0XtdSvSaTiczMTLZt24bFYiEQCNDR0UFrays9PT3hHt5lkclkJCcnk52dTVRUFNnZ2SQmJhIMBvH5fPj9ftFrBpCXl0d6ejoul0tc4yINITSYmZlJVlYWW7duZePGjVRWVuJyufB4PGLY6XKbpWCoOhwOnE4nSqVSNIjWE6VSSXJyMvn5+WzatInY2Fjkcjmtra0Eg0FkMhkxMTGoVCpKS0tJS0tDJpMxPj6Oy+Vatf1wzT0DgjJXbGzsO/pZ0dHRmM1mjEbjW1p6a8nS0hL/+7//yy233CLmPoRCIZRKJffffz9Hjx6NiOz69UAQ9Qn36S4UCrG8vMzIyAgjIyM0NTWJ4wuFQhiNRiwWC5/73Oeoqqpi48aNYR3v5RDK7XQ6HQ6H45IbZ0xMDBkZGfznf/4nGRkZyGQyhoaGOHDgAG+88ca6jvfAgQM4HA62bNlCTEwMDoeDo0eP8txzz9HY2LiuY1kPbrrpJm699VbS0tJQq9UsLS3xmc985h0b12uJTCZDqVSi0+nQ6/UEAgFGRkYYGhqisbGRqakppqenmZycFO+5V155hYSEBFJTU9Hr9SiVyohLaFWpVOTn5/Pxj3+cu+66i8TERORyOYFAgObmZnp6eujs7OSxxx4jJSWFuLi4i36G1+tlamqKF154gdOnT3PmzJl1X8sUCgWxsbHce++93HnnnaSlpdHU1MSpU6f4n//5H1wul2gM7N69m09+8pOUlJTQ1dXFv/zLv9DV1bVquTZrZgxUVlZSVVVFRUUFJpPpkp8ZGxtjcHCQY8eOkZWVRV1dnZh5/GYSEhJISUkRXVvhYmlpiZ///OccOnSIrKwsvvWtb6HValEqlWRnZ4unoXcD4TYCBLRaLRUVFVRVVZGbm4tMJmNhYYHFxUW0Wi3x8fGkpqZSXV1NfHw8MpmMYDAoeg2WlpYibrG7HCkpKWzbto2oqCjxFCNUt6w3o6OjtLW1cezYMbZt20ZMTAw7d+7kD3/4AyqV6oYRdJLL5ZhMJmpra7n55ptRKpWMjY3R09PD1NRURHsClUolCQkJREdHo1QqmZyc5KWXXuK1117DZrPhdrvFU7SQT9Pb24tSqcRisZCdnY3VamV0dDTcUxER8gE+//nPU15ejslkwufz8cYbb3Ds2DEaGhqw2Wy4XC727t2LyWQSqwcuPMBMTU3x5JNPUl9fz/Dw8LqvZ3K5HLPZzIc//GG2bdtGbGws3/rWt+ju7qavr4+ZmRkxMdDpdDIxMcH09DRJSUnMz8/T1dW1qiHzVTcGlEoler2eiooKqqurSUlJuWw82Waz0dvby6uvvkpxcTEajQa/309cXBzx8fErFji9Xo/RaMRgMIQ1Nu/1emlubqa5uZmkpCS++c1vijeY2Wy+pgTJGwEh8zicVRQajYbq6mpuvvlmKioqkMlkzM3NYbVaMRgMxMfHk5ycLOasCFntdrudpqYm7Hb7uhsDwWBQjAkGAoEV47qcXLJGoyElJYXKysoVBvGlZJfXg4WFBbH8t6KigoSEBHJyckhOTsZsNjM9Pb3uY1oL1Go1JSUlFBcXk5eXh9/vZ3R0lMbGRgKBgBh39/v9BAKBiDKChE09KipKdC2fPXuWo0ePXvLzKpWK2dlZMjIyMBgMGAyGsOYDXQqtVktcXBx1dXUkJCSg0+lwOp309fXxxz/+kfr6enw+HyqVir6+PmJiYoiLi0On04nhzEAgwPz8PMeOHaOvry8sypF6vZ6EhAR2795NQkICbrebgwcPMjw8fFFlluChCYVCzM/PMzMzw+Tk5Kquu6u6q8rlchITE7nlllv42Mc+RklJyWVjTsFgkMXFRSYmJmhvb6e5uZn9+/ejVqu56667+PrXv47RaFwRi5bJZKjVajG2EwklLxf2KHi39SqQyWTYbDb2798f1hrx2NhYvvCFL2A2m8X7LTMzc4Vg0ps3S4fDwfHjx/nABz6A3+9f9+vmdrsZGBhgcnISm81GQkICLpeLhYUFlpaWLtpQFAoFpaWl3HzzzTz++ONiCVW4WVxc5OTJk+zbtw+5XI5er2fPnj0oFAp++MMf3hDKjqmpqfzud79Dr9cTDAaZmZnh+eef5z//8z/Zu3evmPE9NTXF1NQU/f394R6yiNFo5LbbbiMtLY3l5WX279/P4ODgZT8v5N8sLy8TCoUYHR2NOP2H2dlZuru7efXVV9m1axfFxcWXfH59Ph//8i//wrZt2/jzP/9z0XsF5yuLZmZmWFxcDJvxVlpaSl1dHTt27OA3v/kNBw8epK2t7aLwoEKh4MMf/jA7duzgpptu4umnn+bo0aOrbmyvqjGQnp5ORUUF73//+8nKyrqkOz8YDLK8vMyZM2c4cOAAr732Gh6Ph0AgICaknTx5kq9//et8+tOfXiGXGxcXx0MPPYTVaiUQCESU9KfgShSy2JeWliLCWFkLjEYjFRUV6PV6lpeXmZiYwOPxhGUsqampFBYWijXTF27+l1oglpeXcTgcPP3005w4cSJsC4GQhDk/P8/i4iIJCQkYjUYSExNJT09ndHRUzGrWaDQYDAZqa2vJzc1FpVKtMG5cLlfYavSdTift7e288cYbhEIhamtrUSgUovdOMNy9Xq8oTQyIz3uks3v3brZs2YJOp0Mul7O0tMR3v/tdtFot//AP/0BZWZkodz01NcXS0hILCwsYjUYcDgd9fX0cO3aM6enpsEgty2QyVCoVcrkcn8/H8PDwFccheDgFldhIPODExcWRlZVFTU0NCQkJeDweXnvtNerr6xkYGCAqKkrUTti+fTuVlZVkZWWJarb9/f00NDTQ3d3N9PR02JJahRyU6elpzp07x7Fjxy5aj0wmE0lJSezYsYOCggKcTidnzpyho6Nj1cezqsZAQkIC+fn57N69+7KfWV5exmazcfLkSU6ePLki0UhwefT19WG1WvngBz+4whgwGo3s2LGD119/naGhoYgwBgQXrUwmw2QyYTabiY2NvW7EOq4VpVKJyWQSs9htNpsohBEOYmNjsVgsKBSKq3KV+/1+lpaWeP3112lubl6HEV4aIelxfn5e3PT1ej1xcXHk5+ezvLyM1+sVjUyLxUJlZSXp6ekX5QcsLS2Frdx2eXmZ0dFRWlpaiImJoaamBrVajV6vFxUKVSoVS0tLojsdEKXGhTCJ4GKPFIQeHlu2bOGWW25BLpfj8XiwWq0cO3aM++67j/e9732YzWYCgYD4dxAW87S0NNFQWlxcpL29nZ6ennVfEwRJaEFMaHJy8rL3imA4COFO4dpEmjGg0+nEnjbR0dHi4bK3txe73U5mZqYo2rNnzx5ycnJITExkYmKCkZERTpw4waFDhxgZGWFhYSEsc5DJZJSXl7N582YaGhro6uq6SL1So9GQmJjIhg0bKCsrIzo6munpabq6utZk71vX4HswGOTMmTOcOnWKb3zjGxGdeHO1CJazXC6ntLSU4eFhysvLmZ2dvW6S0q6F3Nxcqqqq2L59u1iSdPz48bD1jxgeHkYul9PW1kZOTo6ohnc5VCqV2KBpYmIi7C7QM2fOoNfrqampQSaTER8fzze/+U0OHz5Ma2srRqORqqoqKisrRaGkCwmFQjQ2NtLS0hKmGZyns7OTmJgY/H4/JSUlmM1mcRGOjo6mv79fzAWC8/lCgvrl6Ogo3d3dYvlnJJCWlsZXv/pVtm/fTlZWFjKZjNdee42mpiaeeuopsQ6/tbWVM2fOcOTIEV577TVxo927dy87duzgU5/6FHv37uXMmTO8733vY25ubl0NZ71ez6ZNm8Rqj8HBwct6BmJiYkhLSyM/Px+tVktLSwtzc3MRpww5MDCA3+9nfHyc9PR0FAoFDoeDtLQ0LBYLH//4x8nMzCQ5ORmVSoXf78fpdPLVr36VlpYWxsbG8Pv9YTusKRQKjEYjarWaxcVFfv7zn19UmqpUKtm1axd79+7lnnvuISUlhTNnzvDjH/+Y1tbWNVlvV8UYkMvlqNVqcnJyyMjIuORnQqEQfr+fpqYmfv/73+NwOCLqJPB2CAQCjI+Pk5KSInbDk8vlYa25X2tycnLIzMxEoVBgtVrFro3hcrV5PB4mJyf54Q9/SGxsLAaDATh/TyqVSoqKioiJicFkMlFYWCjKlO7bt4/o6Gh6e3vFDpnhoLe3V9wg4U8JX3V1dWRmZqLRaEhOTharaBwOB/Pz86SkpIiu+Eg4VY+MjBAfH4/D4cBoNIpSzwaDQTRglEql6DUwmUxkZWWRlZXF/Pw8U1NTvPLKKxHh8YuPjycnJ0d0Q/t8PhoaGlAqlVRWVop/e6vVyk9+8hN6enoYHBzEZrOJnoHW1lYAMjIy2L17N+np6Tz88MO8/PLL66bUKZQVGgwGurq6GB4eZmFh4bIGl9lspri4GJ1Ox8LCAi0tLbhcrojzcAaDQRwOB0eOHOGmm24iPz+fPXv2MDAwwPT0NDk5OcTHx4v5QzabjY6ODkZGRsIaFhCIiopi8+bNxMXFIZfLVzwjcN4oS0xM5K677qKiogKLxYLNZmNgYICzZ8/idDpXeGu0Wi1paWlX9PpcDatiDAhNV/Lz88nJybns5/x+P+3t7W+7Dl8wKISM63Aj5C0IlQ5AWEq8roRcLkcmk6FQKMSxCVnrFzYiksvloi6+kHj35sx2mUxGUVER2dnZBINBpqenGR8fD2sLY5/Px+zsLE8//fSK1xUKBTqdjttvv5309HQyMzPFEiOj0citt96KSqXiueeeY25uLmwn0uHhYeLj41leXkalUqFQKDAYDJSVlYmfEVp5ezwepqenGRwcJCEhIaIULycmJjCbzTgcDtEDkJycjNfrFbXUnU4nCwsLKJVK4uLiSExMpKSkRBR/WVxcRKPRMD4+HpakToHU1FQKCgooLS0Fzkt4nz17lrKyMvLz84mNjcVqtTIyMsLPfvazS57ShNbYcrmc4uJisrKyePjhh8VOn+uBWq1Gq9Wi1+vFOvrFxcXLrp1ms5mioiLxGjQ3N0ecVwAQs+rPnj1LaWkppaWl7N27l7i4OLq6ukhISECtVothqLGxMRobG0UthXATFRXFxo0biYuLQ6lUkpSUhNlsxmAwIJPJSEtLo6CggNtvv52kpCT0ej3j4+MMDQ3R0dFxkcdZaBC2uLgYfmNAcL3efvvtVFdXr8aPvCTz8/McPXqUlpaWsEuvwvmM8J/97GeiRj9w2bKw9UZQqhNcZ6WlpSQnJ6PRaFhYWKCpqUn8G1osFtLT0/nKV74iZkYLYjbt7e1iIwyZTMYDDzyA2WzGbrfz5JNPcvLkyTDP9NIICXq/+c1vxIS2AwcOsGnTJu655x7y8vLYsGEDX/ziF/nOd74Ttr4KbrebsbExfvrTn7J582aysrJWNFtaXl4WBVQOHTrE1NQUdrudZ555hrS0tLCM+WoQqoWeeeYZDhw4QH9/vyhqExsbS1FREdXV1dTW1pKdnU1xcTGf+MQn2LZtG3q9nmPHjoXNyHzooYfYs2cPMpmM+fl5nE4nt956K3FxccTExCCTyXj++ef5wQ9+cMWY8+zsLL/73e/4zGc+I3bUFLLZ14OdO3eyadMmkpOTGRkZ4ezZs1dcmwRZYoVCgc1mo7GxMSKliHft2sXmzZv59Kc/jcFgEFVQN23aRGVlJSMjI7S0tHD8+HEOHDggekPCLWMvcGGYwGQy8cQTT3DHHXcwOzuLXq8XuywKcwuFQiwtLeFyuS6Z8Ozz+VblQLMqxoBwstTpdO9IEEgmk7Fx40Yx+ePNHeg8Hg99fX1hy8x9M6FQaIVsrEwmIyoqiqSkpLCGCtLT00lNTRVPJGazmdTUVLE7n8fjIScnR6ytNRqNmM1mUlJSxMxowZug1WpXuArj4+Px+Xz09vbS39+/5jF3wagR6oQNBgN9fX1XpQMfCoXE+KxMJqOzsxO5XE50dDTJycmo1WrROg8Xfr8fq9XK73//e0ZGRsjMzBQz1AHGx8dpb2+ntbWV7u5u9Ho9SUlJEeUVuBQej4eWlhZaW1vp6OgQFyufz4fH4xFdvaOjo5SXl6NSqUhOTiY3N5c777yT0dFRvF7vuur963Q60SsghDuFChWDwYBer8fv93PkyBEaGhoYHR29YngmLi6O2tpaTCaTeJ3X0wMl9Ip47bXX6OrqYnp6+orGgNFoFPMjPB4Pdrs97OGnSyGIiAmGC/wp+TEUCtHS0kJDQwP19fWMj4+HPSzwZoSyZp1Oh9VqZdOmTWJLeY1Gg06nQ6fTEQqFmJubY3R0lFdeeeWyqp4+n29VkrgjakVRKBTs27dvhXCJQDAYxOl00tXVJarGhZtLaQuYTCZycnLCIpksbOAbNmxg06ZNPPzww6SlpYmn/Te7/AFxkxdCB0L4QGixK+hkX8jY2BhtbW1MTEyseVMPjUZDfHw8xcXFxMfHk5SUhM1mu+ZNIhQKMTQ0hMvlwuFwcOedd4qx7XAabkKvixdffJHDhw+TmJjIvffeK7oMGxoa6OjooLu7G4Da2lo2bNiwQmcgEsu/lpeXOX78OK2trQwPD694z+l0MjAwwMDAAEeOHGHr1q3ExcVxxx13kJGRwcMPP8zx48ex2+3ragwYjUY2bdpEQUEBKSkpwPkEPCH2LAi+/PSnP6WxsfGyXgEhVp+Tk8NHPvIRkpKScLvd9PT0rKubenFxkb6+Pvr6+mhubhZbwV9uzHFxcWLNvtALJlKMAaFiS6FQiCEoWKmCGgwG8Xg8HD9+nPr6es6cOROu4V4Ru93Oiy++iNVqZXBwkOrqalHgSTiICevy2NgYhw4d4n/+538ue/28Xi/j4+PveFwRZQwI5RalpaWkpKSg1WrF9wRr/ODBg2GNUV+I3++ntbWVpqYmCgoKKCkpoaioiMTERH7wgx+se4Z9fn4+O3fu5K/+6q9IS0sjOjqaqakpZmZmaGlp4ezZs4yPjzM2NiaWqrz66qvijSfkCyiVSurq6qipqWHHjh1s2LABjUYj3qjJyck8+OCDnD59GplMdlFJzGqh0WjYtGkTX/jCF4iPj2d8fJyf/vSnxMTEkJKScs2hoqioKNLT09m8eXNEKkUuLCzgcDj4z//8T3Hx83g8K06TWq1WTFYVaG1tXbNr8HZxuVycPn2aqampK34uFArR09PDD3/4QzZu3EhsbCw6nY4777yTmJgYvvOd76zTiM8/P//+7/9+2T4qnZ2dNDc3c+DAgcsq1sXGxpKdnc3f/M3fUFJSQk5ODm63m5MnT/LhD394XdeEtrY20dC90ulYLpeTk5NDXl4eaWlpNDQ0cPbsWaampiLGGMjMzKSwsJA///M/p6KigpSUlBXPgM/n49SpUxw9epQXX3wxLJ0Hr5Vz585hs9nYs2ePmEQ4Pz9PbGwscXFxZGZm0t/fz/79+8VQ7VoSVmNAcO2UlJSIpz7BrS24SZxOJ5OTk7zxxhucPXuW+fn5iJH7DAaDzM/Pi93bQqEQGo0Gk8kUlkTCpKQktm7dSnp6Omq1msnJSQ4dOsTQ0BB9fX10d3djs9mYnZ3F5/Oh0+no7+9fYV1rNBqio6NFl3x0dLTY43x0dBSNRiPG4xcXF9e0fFKpVIoZzqFQiImJCQYGBrDb7dfk+tNqtaJoT3FxMZs2bRLbBEfS6ScYDIr31JUQkkLh/Ga63ifoy2G323n55ZcxGAw4HA4GBgaualwej0e8JwGxMct6xteTkpJIT0+/ZFvrYDCIzWYTSwi9Xi8xMTGiQSk0UYuNjcVsNpOVlUVVVRVGo1GULRYM8fXkap8RmUwmJrFpNBqcTqfYlTTcGAwGsZy5sLCQiooKkpOTiYqKEnsphEIhFhcX6enp4cSJE9hstogpUb0SLpeL6elpfve736HT6URxqOrqapKTk7FarUxOTjIyMrIue15YjQGlUkl0dDSPPPIIGzdupK6uDo1GI26kQp/6Q4cO8Ytf/ILe3t6IuEEFBLehzWbDbreLJ+dwacVnZGRw5513YjAYmJmZobGxkW9/+9t0d3dftDBcWJd+oWqfUIO/c+dOysvLycvLA85nve/fv5/Y2Fg8Hg9jY2O0t7df0fX4TlGpVERHR5OamsrIyAhzc3OcO3fuql3iwnWIjY0lJyeHj33sYxQXF5Ofnw8gPmzhEkx6u7z53rLb7RERNhsbG+Nzn/uc+P+v1lAURHsuvK4qlWpdQ23FxcUUFRVd8j2v10t/fz+vvPIKL730EklJSWRkZIgJnPn5+VRVVVFeXi4mf4VCIQYGBnj11Vf5wQ9+ENGdDRUKBbm5uSQmJqJUKvF6vRGhkSKTyUhMTBQTOjMzM7FYLKIb3ePxiAl209PToqrt9UIgEGB2dpbvfve7wPn9sLS0lKSkJG655Raampro6+tjZGRkXarnVsUYCAQCeL1exsbGSExMFOM5l/yFSiVRUVFkZWWJrvWHHnqIuLg4sbRNYHBwkOPHj/O1r32N2dnZiDIE3syF+QPhUu0aGhripZde4oEHHsBisbB3717cbjcTExNvuVloNBpuu+02tFotKpUKi8UiLoL/+q//SldXF319fWJDHa/Xu24NioTQRHl5Offffz8TExMsLCyI6n0Xlj8J2gIJCQkkJSXxwAMPkJSURHx8PImJieI95na7GRoaEksLrxdSU1PZtm3bihBaJLFam4jQTW+96O/vv6xGikajoaysjG9+85v8/d//vWioCHkbFyZ9CUb47373O7q7u2lubo74+0uhUFBWVkZaWhrBYJCOjo6L8jzWE5PJJHoDCgoKxN4KgidmcHBQXOs2bdpEUVERw8PD2Gy2sI15NVCpVJSVlZGSkkIwGORXv/oV9fX161ZGvyrGQDAYxO1209XVRUxMzGWNAZlMJkoW79ixg9zcXFGl7M1VCMFgkKmpKUZGRhgbG1uNYa4b4dIamJubo6mpiR07dojlnuXl5aSnp79liZBKpSIzM1OsZ+/q6mJubo7x8XHq6+sZGxsL68OmVquxWCzs2rVLbDAidCa8cG4qlUo8oVksFmpra1eIEQnGpt1uZ2pqitHR0YjLNr4SOp2O+Pj460bYSuhHcCWjMSoqirS0NNRqtZjoKuS2rBeLi4uMj49z7tw58vLyRG1+OH/P6PV6srKygPNhDeEf/Km97OzsLJOTk3R3d3Py5EnGx8cjogT6SiiVSnQ6HdnZ2SQkJIiJtuHsOClUddTW1pKfn09KSgpRUVGip2h+fp7R0VGamprEtvaDg4OEQiEyMjIYGxuLCB2aa0Emk6HRaCgpKcFoNGK32+ns7FxXhdRVMQa8Xi9Wq5Vf/epXzM7OsmPHjkt+TqFQiGVEn/3sZy9bhig0MxJOo9cDF4YHwhUmGBsb48CBA+zYsYNAIEBJSQkbNmy4qu96vV4aGxuZmppiYmKC5557jvHxcaanp/F4PGHNVhd+d0pKCp/4xCdEQaSFhQUWFxdXnCCFLG7BffjmnyEgZFmvZZhjLVCr1RclEEYyer0erVbL3NzcJe8huVxOSkoKN998M9HR0eLB4siRIxw/fnzdxmm322lpaeEb3/gGX/rSl6ioqLjk54LBoFjuJRgrfX19nDlzht///vcRU8t+teh0OiwWC1u2bMFiseDz+Th79qxYvRIOoqKiyM3N5dZbbyUzM/Oi96empujr66Ojo4OysjLS09N54403MBqN3HnnnfzkJz+JSH2EKyGEzO+44w4xKbu+vn5dD2DrljMgJAtu376d6urqK7ZgHRwc5PDhwzz99NNXbLcZSVwYJpDL5Xzyk5+kqamJU6dOMTQ0tC4uTyEk8M///M+kpaVRXFxMUlISarV6RRe/N/+31WoVRUbcbjder5eZmRm8Xi9erzfiytYAUS9Ar9evCB8JktCXw2q10tfXx3/8x3/Q3t6+HkN9VyLU5r/vfe+jrq6OJ598krGxsRUuc7lczs6dO9m9ezcf+MAHMJvNjIyM8MILL4jZ7OuJ0FhoaWkJj8fDwMAA//3f/72ivlsIkV1Y5SGUq0aiWt9bERsbS2ZmJmq1mvHxcTo6OiIqSftCrFYrv/3tb3nxxRdpaWlBo9FgsVjIyMgQ+8K0trZG5NjfCmEOqamp9Pb20t7evu7zWNcEQqERy5W40M3W29t7XcSB5ubm6Ovrw+/3iwmQdXV1REdHo1QqmZ2dXRdjQNAJ6OrqYnJykrm5OZKSkt5SCEowBrq6uiLKvRYIBLDZbLS0tJCVlYVerxfFdoRa7jeL77zZIxMMBvH5fKKBI6iTtbS0MDo6um5zWQ0E4ZvrIUQgGP+5ubls3LiR7OzsFRLDer2e2NhYamtrKSsrIzMzU7xG9fX1zMzMrHtip9frZXZ2lqamJrxeL319fRw5cuSyYi83AkajkZSUFBQKBYuLiwwNDYW1V8eFvFk/IxgM4nK5UCgUYifPjIwMzGYz6enporEZiYeXtyIpKUlMbJ6dnQ1LsnxE6QwEAgGef/55jh07xiuvvBIRGa1Xw6FDhzh79iwf+MAHMBgMKJVKtmzZwpYtW/jABz5AY2PjumsOCJLD1zMOh4Njx47x4Q9/mG9+85uUl5cTFxd3TT/D7XaLuQ//9V//RUdHBy0tLRdlr0c6CoWC0tJSMjMziYqKivgwgWAMCL3nt23bRmpqqnjaLy8vZ+fOnWRmZopKo0J71oMHD4ZFQ97n8zEzM8MnP/nJdf/d4SItLY3a2lqUSiV2u52+vr6IfTaMRiO33347W7Zswev1YjQaSUxMRK/X43K5RK9GJBgy10plZSW33347w8PDHD9+nJdffnndjeFVNQbGx8d54403+Kd/+icqKyvJzMykqqrqit/x+/0cPXqU4eFhBgYGOHToEBMTExFdOXAlLgwVCDXGlxMokbgyoVAIh8NBf38/3/72t8nMzBSlYmNjY0lOThaleRsaGla0JV1YWMBms9Ha2sr09LRYr7u4uBixoY8rISSxabXaiDcE3oxWq+Xuu+/G5XKJC1xMTIwoMR0KhbDZbDz55JM0NDTgdDqvywX9ekNIGt64cSNqtZr5+Xm6u7vDXqPvcrkYGhpiYWGB5eVl0bMpVDnFxsaKbYlnZ2eZn5/nO9/5Dm1tbdjt9uvq3lGr1RQVFVFZWUl+fj6//e1v6ezsZG5ubt3nsarGgOBm+sMf/oDb7WZxcZG8vDx0Ot0ltdSFzzQ0NNDV1UVnZye9vb24XK7rbrEW3POzs7Oi3sDAwADHjx+/7pJZIgmfz8fCwgKnTp2ir6+P8fFxcnNzSUhIICMjg/T0dFQqFadPn8br9YoPkNVqZXZ2ljNnzjA3N3ddhJuuBkGYKNJDBUKH0enpaUZGRkhLSxNFVYRcFI/Hg8vlYmFhgfHxcY4dO0Z3d/d14xG8nhGy1+Pj40lLS8Pv92O32yPiICZoCMzOzmI2m0X9A5lMhk6nQ6FQ4HQ6GRoawmazMTExwYkTJ7BarddVZRAghtKSkpKIioqira2NsbGxsGifrKoxIChXTU1N0dXVRV5eHmazmerqalHr+0KE3ID/9//+H1ar9bpMwBFwOBzcfPPNF70ulEpJvDPm5uaYm5uju7t7hUiSwJuNR+H/X29G5eUIBoOMjIwwMTGBzWbDbDZHtEEgKCl+97vfZf/+/Tz11FNic5nBwUH6+vro7OzE6/XS0dEhdpcL90b0bkEul5OYmChqcHR2dooNscKdgGcwGCgoKOD3v/897e3tvPe97yUhIQGdTgecTzBvbm7mk5/8JE6nc8Uh4HpDr9ezZ88eTCYTo6OjvPjii2E7uKxZzoDg6vne975HfHy82OzjQqxWKzMzM9eNfORbIS1ka08kNuVZD4LBIDMzMzQ1NfHKK69w//33s7S0JGbdR6KKYjAYFOPQ//iP/yh2NV1YWGBpaUl06dpsNpaWlq7bBf16RKFQkJ2djclkIhQKMTw8zMzMTER4ZWZmZjh48CBwvszw5MmTaLVa0btst9vFe8bn812364FQTlheXi6GlV0uV9iuwZoZA36/H5vNxuuvv75Wv0JC4l3F0tISfX19HD16lIqKCmZnZzl8+HBEG9OCOM9LL70U7qFIXIBCoSAhIUHUdpienmZxcTEiNtbFxcUVZb/19fVhHM3aoVAo0Ol0ZGZmMjw8zPj4eFi9HBFVTSAhIXFlenp66O/v55e//OVFbaclJK4WoQ+JVqslGAwyNDR03QlwXe+oVCp0Oh2JiYkcPXqUI0eOhNW7LAtd5SoSDkW9t8uVpnSjzANunLncKPOAG2cuN8o84MaZy2rOQ6lUsmHDBrFt8alTpxgbG1s1CWjpmrw1Qunto48+SldXF/39/fT19a2ZZ+Atr4lkDEQu0gMVeUjXJPKQrknkIV2TyGPVjAEJCQkJCQmJG5PrS71EQkJCQkJCYtWRjAEJCQkJCYl3OZIxICEhISEh8S5HMgYkJCQkJCTe5UjGgISEhISExLscyRiQkJCQkJB4lyMZAxISEhISEu9yJGNAQkJCQkLiXY5kDEhISEhISLzLkYwBCQkJCQmJdzmSMSAhISEhIfEu56pbGN8oDRlulHnAjTOXG2UecOPM5UaZB9w4c7lR5gE3zlxulHnANRgDEhISEhIrUSgUyOVy8X+DwSA+ny+sfeklJN4OkjEgISEh8TZQKpVs3bqVmpoadu7cyYYNGzh79iw/+tGPOH36NEtLS+EeooTEVSPlDEhISEhcIwqFAr1eT11dHXV1dZSVlZGZmUlWVhb5+floNJpwD1FC4pqIGGNAcLUplUqUSqXodrueYjIS4UMmk13yHpLuH4m1QKPREBsbyy233MLWrVvJyclBqVRiMpnYsGEDOp0u3EN8VyKTyVasARf+k9aCKxP2MIFcLmfDhg3U1NSwe/duysrKWFpaoqenh4GBAUZHR6mvr2d0dBS32x3u4UpEGHq9nujoaMrKysjPzycnJ4cdO3bgdruxWq1897vfZWBggLGxsXAPVeIGIiMjg6qqKsrLy4mLiwv3cN71KJVK0tLSyM7O5rHHHiMjI4PU1FQAlpeXWVxc5F/+5V/o7OxkYmIizKONTMJmDMjlcqKiojCZTOzatYuqqiqqq6vJz8/H6XRiNBpJSUlhfHyc6OhoOjs7mZqaYmBgAL/fTzAYDNfQrwqZTIbZbCYzM5OUlBQA7HY7ra2tLCwshGVMgqdFqVSiUqnQaDQkJiaKJ2qtVguczzqdnp5mYWEBu90elrG+FUqlktjYWMrLy8nKyqKwsJCMjAxSUlIoLS1leXmZ+fl5SktLcblc15UxIJfLCYVCb5n9azAYiI+Pp7i4GKVSyeLiIs3NzSwsLLzldyXeHnK5nMTEREpLS9m8eTPR0dGoVCrxfYfDwcDAAMvLy2Ec5bsHmUyGRqOhpqaG/Px8CgoKqK2tJSkpiYSEBAB8Ph8Oh4OdO3ei0+lYWFjA7XZH/B6y3oTFGBAuYGpqKsXFxXzmM58hISEBvV4PgMlkwmQyUV5ezvLyMvv27aO+vp5z587x1FNPsbCwgNfrDcfQrxqlUklRUREf/OAHue+++wA4d+4cn/vc52hpaQnLmFQqFSqVCr1eT2xsLAkJCdxyyy3o9Xq0Wi0WiwW5XI7f7+fAgQO0trZy7ty5iHxodDodGzZs4HOf+xy7du26yC0bFRVFdHQ0u3fvZnFxkcbGxjCN9NqQy+Wo1eqrykhPSkpi7969/P3f/z0Gg4G2tjY+85nP0NTUJGWzrxFqtZqNGzdyzz338J73vEdcswQmJiY4cOAAi4uLYRrhuwuVSoXZbObTn/405eXl5OXlie8JBrEQvvmLv/gLSkpK6OzsZHx8HI/HE65hRyTrbgzExMQQHx/P/fffT01NDRUVFSQnJ4vWdSgUYmFhgYmJCRITE9FqtSQkJLBr1y4yMzNZXFzk1VdfZWBgICI3KTh/833lK1+hurqampoajEYjdrt93U5rKpUKo9FIWloaGRkZJCcnU1lZSVxcHHq9npiYGPR6PRqNhpiYGDG2rlKpkMlkhEIhamtrmZqaYmhoiIMHD9Le3h4xG6perycnJ4dPfepTbNiwAYVCwcjICGfPnqWvrw+Px0NtbS21tbXs3r2bubk5GhoaGBwcxOfzhXv4FyGXy9HpdBQXF5Obm8vevXs5cuQIZ86coaen55L3uVarpaqqir/9278lISEBhUJBRUUFRUVFWK1WhoaG1n8iNzjCxvOhD32I0tJSDAaDGIcOBAL88Y9/5MiRIwwPD0f8YeV6RyaTodVqueuuu9i9ezc7duwgOjqaYDDI1NQUwWBQXG81Gg0Gg0Hce+Li4piZmYlYYyArK4u8vDx27NhBTk4Oubm5LC0t0dHRwe9//3tOnDixJpUq62YMKBQKzGYz+fn55OXlsWXLFkpKSkRLbmlpifn5eVwuFzabjbGxMRYXF4mLiyM9PZ2YmBgyMjLYvHkz9fX1jIyMRNwDJ5PJMJlMpKamsnHjRoqKikhISCAQCODz+VhegzupGAAAXMFJREFUXl5zA0Ymk1FSUkJKSgr5+fmkpaWRlJREWVkZMTExaLVadDodXq8Xv9+Py+USk+8CgQB6vR69Xo/ZbCYhIYHk5GQ8Hg8qlYqhoSHsdjt+v39N5/BWpKSkkJOTQ3Z2Nna7nampKbq6ujh37hyDg4NoNBqysrKQyWTodDrUanXEGo5wfpNJTU2lpqaGDRs2sGnTJkZGRujr67ts0pNcLsdoNJKVlQWcd4WG83lQKpVoNBri4+NRqVSiEX8hLpcLp9OJx+NhcXERq9V6XXkwUlJSKCwspLCwUDTAAJxOJ3a7nVOnTtHe3o7T6Qzb/RYdHY1Op8NoNOJwOIDzB7ALEZKzo6Ki8Hg8uN1uPB4PTqeTxcXFiDSY34xCoSAhIYGSkhJqa2uJjY1leXmZqakpjh8/jtfrFY0Bg8FAQkICmZmZOByOiE1MVygUpKamUl5eTnV1Ndu2bSMrK4vs7GwcDod4qGxubr5+jQGZTIZer2f79u08/PDD3HTTTcTFxa24IL29vRw8eJChoSExVp2dnU1RURF33XUXycnJxMXF8fDDD/Pb3/6Wjo6OiDMGlEoltbW1PPjgg2zcuBGj0QicXwQXFhaYm5tb8wdNLpfzt3/7t2IM7UK8Xi8+nw+n00lbW5u44SiVStRqNYmJiWRnZ5OdnU1GRgbR0dFER0eTmZlJTk4Oc3NzHDp0KGw5DwI33XQTmzZtQqvV8vOf/5w33niDo0eP4vP5UCqVbNy4kWAwiMlkYnx8nLGxsYj2JBmNRvbu3cuHPvQhampq8Pv9JCYmYjAYrvpnLCwsiMaQ1Wpdw9FeGiHH5z3veQ9JSUkkJydz7733rlh4u7q66OjoYGRkhJMnT/L73/8eh8Nx3eQ33Hzzzbz3ve8lNzcXpfJPS+f4+DinTp3i+9//PjMzM2EcIRQWFpKbm0tdXR2tra0EAgG2bdu24jMGg4Ho6Gjy8/MZGRlhYGCAkZER2traqK+vx2azRbyRptVqqaurY9OmTdTU1AAwPDzM2bNn+eu//usVa1R8fDx5eXk89thjLC0t4fF4InJ+Wq2Whx56iJtvvplt27atCEEZDAYqKirIzMzkhRdeYGpqatV//5oaAyqVCovFwt133011dTVVVVWkpKQQExMjLhB+v5/jx48zNTWFTqfjgQceQK/Xo1ar0Wq1YpLUhUk6wok1kuJyMpmMpKQkysvLuf3224mKigLOhz1eeOEFzp07x+HDh9clkc1gMKBUKpmfn6e7u5uJiQlaW1sZHR3FbrczPz+Pw+HA4/GIngEhj0Nwp9XU1LBx40Z2796NwWAgNTWVW265hTNnzoTNGDAYDOTk5HD77bdTUlLC0NAQ586do6mpCZVKJZ6sH3nkEXJzcwkEArz++uu0t7dHrCEg/G1vvfVWkpOTCQaDLC0t0dfXd9l8DblczqZNmyguLhZfm5qa4te//jWjo6O4XK51G39CQgI7d+5k165dZGdnk5+fj1qtRqPRiM94KBRCJpORlpaGyWQSw2c333wzBw8epKenh+bm5nUb87WiUqnIzc2loqKC8vJy0SMA4Ha76ezs5OWXX8bpdIZtjDExMWRnZ/NXf/VXFBUVYbFYuPXWWwmFQphMJuD8Wjs1NcXc3BwOh4Oenh4CgQCJiYns3LkTu90uGmqtra0cOXIkbPN5OywuLjI+Pn7RM7OwsEBXVxff//738fv9TE9PR1yIQKvVkpiYyGOPPUZqaiparfai50dIhF6rA+WaGQMqlYqYmBjKy8vZvn07GzduJDs7W5ygy+VCrVYD4PF4UKvVJCUlUVhYiMlkEjfTSyG4sHt6eiLmVCGXy0lJSSE9PV0safF4PNhsNhobGzlz5gxtbW3rMpbx8XExWbClpYWRkRHOnTvH8PDwW1YICAlsi4uLKBQKsrOzKSwsRK/Xk5qausIoW29kMpmYXCdUZszOzhIMBsnLyxPzBOrq6pDL5SwsLNDU1MTIyEjYxvxWpKWlUVhYSF5eHgaDAb/fz+TkJDMzM9hstkt+RyaTkZOTQ3Jysvia2+1maGgIh8Ox5qceoZY7NTWVnJwctm3bxo4dO0hOTkYmk+H1evF6vbS2tl70HaVSSUJCAnl5eSQmJuJ2uzEYDLjdbkZHR9cllHatqNVq8vPzSU9PJz4+XlzDgsEgIyMj9Pb20tnZGVZPpVAZVFpaSlFRERqNRrwfBE+Rz+djenqa8fFx8TWNRkNUVBRpaWkYjUbKy8uB8+v32NgYo6OjEeeBvRwLCwuMjo5edP8L60WkVkYBWCwWCgoKyMvLIyoqStzX/H4/y8vLTE5OMj09TV9f35qV2K+ZMWCxWCgvL+f73//+ikoBOD/B3t5eEhMTSUpK4vbbb7+mn11SUoLNZuPEiRMRYwyoVCpuueUWSktLxdf6+vp48cUX2b9//7rVtgYCAb785S8jl8vFkEAgELjqv1MwGMTj8XDq1CmWlpaYm5vjn/7pn9Z20FeJw+GgpaWFf/zHf0SlUjEwMEBxcTG33347TzzxBHl5eSQlJQEwNDREe3s7v/jFL8LiNr9aHnvsMfbu3UtJSQkA8/PzvPrqqwwODl72O3K5nMrKyhWZ0+uJkKD6la98hdraWgoLC5HL5VitVvbv38/09DQTExO89NJLKxZms9lMUlISH//4xyksLCQ/P5+//Mu/xGq10tvby6c+9Sm6urrW1bNxNURHR/Poo49eJCa0vLzM97//fU6dOkVXV1cYR4hYGqxSqQgGg8zNzfGpT32Ko0ePrvic3+9fUZoteAW1Wi179uzh0Ucf5aabbmLjxo3s2bOHT33qUwwMDIRjStdMb28vr7/++nVZ1nnnnXfywAMPoNFoxLU6FAqxuLjI2NgYX/ziFxkdHWVpaWlNQgSwRsaATCajtraWLVu2EB8fj0ajwev10t3dLZ5Qc3Nz6e3tFV1ui4uLzM7O0tfXt8ISNRgMZGRk8PDDD5Oeng5ATU0Ncrmc733ve2sx/LeFTCYjMTFxRbLO4uIivb29uN3udTVahMShYDB4TYbAm1leXhZr1oVFI5yEQiH8fj8TExPodDrS0tJ46KGH2Lp1K4WFhSti7PHx8ZSXl/N//+//ZWRkhMHBQX7729+ysLAQEQlSwoaamppKYmIicP56LS4u8sorr1zWGEhLS6OkpITNmzeLyYNCTorVal2XuRUUFPD+97+fjRs3YjabGR4e5tixY3R3d3Po0CE8Hg8ej4f5+fkV957b7cZms/Gd73yHjIwM8vLy2LRpEykpKRQUFPA3f/M3nDx5kh/96EcR4yGorq6moqKCzZs3Ex8fL76+uLjI5OQkjY2NEeF5stvtnDlzhmeeeYbc3FzS09OZnZ29yB0eCoVW/F2F6+PxeDhz5gw2m42uri6Ki4upra0VY9fr5dV8JyQmJlJSUsLw8HBE5gRcCrVaTUFBARUVFZSUlIiVXcKa63Q6GR8fZ3BwkImJCdGYWwtW3RhQq9WYTCbKysooKysjKioKr9fL/Pw8Z86c4dChQ/T09HDTTTcRCATEjd9qtTI+Pk5zc/OKGzguLo6ysjJuv/120RhIS0uLKJePWq3GaDSSlJQkJg0GAgGcTicTExPr7mZbrd8nzEsujxjVajGmHggEyMjIoLi4mMrKSgKBAG63G6fTKZ6QLBYLd911FyMjI3R0dNDf38/Y2Bg2mw2HwxHWzUatVpOcnExCQoJoQIZCITweD+3t7ZfNFo6Pjxd18M1mM3D+tOf1elleXl4XozMhIYG9e/eSkZGBz+ejq6uL48eP09TURFNT02W/t7y8zNLSEjMzM/T09Igx66qqKtLT06mrq8PlcqFUKsPqmhaqa7RaLSUl/7/23js6rvO88/9Mb8AU9N57IQiAIAl2SiRVHaofSSe2rI0lK453ZcdJnGycs5u1nax3s8naju0kXjuWE8WyTfVCShTFBoIVHURvgzYYlMGgDGYGU+7vD/7uNSGSEiUSmCE1n3NwSIIE+Fzce9/3eZ/yfUrYtGkT6enp0sElGAwyMzNDX18fVquV2dlZAOm5U6lU+Hw+gsGgdG9W+7643W5GR0epq6tjdHSUsrIynE7ndW+KgUCA8fFx6dQpCAKbN29m3bp1eDweurq6buhgcbMJBoO4XC68Xi9+v18SIcvOzl5R0xHuaDQaKisryc3NJSEh4YoDl+i8qdVqqW5gtbipzoCYY/7Sl77Egw8+SGZmJgDd3d00Njby1a9+VVqwGhoaVnytqLj24YdNbHu5fOGWy+UrqnlDTX5+Phs2bGD37t1Ssc7MzAw2m42xsbGwOIl+GjZu3Mhf/MVfYDabsdvtoTZnBWKUYHR0lNbWVnp6erDb7bjdbrZt20ZiYiJxcXEkJCQQGxtLRUUF27dvp6mpiddee4233nrrmjn51UaMIj388MMUFhZisViA30VyXC7XNb3/5ORkNm/eLKlFwqUwdkxMDImJiWtSoKrX60lPT0ej0TA9PU19fT319fX09vZe9/eYnp7G4XAwNDREcXEx7e3tFBYWMjw8HPINR61WYzKZqKmp4eGHH6a2tlbaYEQdlKNHj/Lyyy/jcDjw+XwoFAqqqqpIT08nLy9PchLsdjtdXV1StG61OXfuHOfPn+fAgQOfytkNBoNSH7tcLueLX/wiZWVlnD9/nomJibApvHO73Zw6dYqdO3dSXV1NcnIy6enpbNiwgX/9138Nu1TTtYiNjeXb3/62JGl9+bMvCILUGu71enn33Xf56U9/umq23NQdNTMzk4qKCvbs2UNcXBw+nw+r1coHH3zA+fPnV4T+biSMMzIy8okWntVEo9FIWggqlQq/34/L5eIHP/gBDQ0N2O32kPflf1LkcrkkgBMTE4NMJmNqaorTp0+HtGL6cnw+H6Ojo7z00kscPnwYp9OJ2+3G7/fT1NSEyWTCZDKRlZUlLRRiFCE6OpqkpCRaW1s5dOjQmtuelJRESUkJ991334pe/JaWFs6dO3fNDoKsrCyKioooLS2Vim/hd6eHtYp02O12Dh06xJYtW9Bqtezbt4/MzEypy6S3t5e5uTmpPVWlUjE8PExPTw+9vb1SNbfX62VxcVESiqqvr8fpdIY8RRAfH09hYSHPPfccpaWlUrTP5/Phdrul9si5uTmSkpKwWCxkZGTw6KOPkpCQgMlkYmFhgaWlJWZnZzl//jw9PT0cPnx41W2/Hhnr6/kedrudEydO8OSTT6JWq8MqOgiXbHS73Vy8eJGTJ0/y0EMPkZCQQHV1NX/1V391VadlYWGBoaEhqaU11Ouy2MptNpulKZcf7iAQC28TExOlSOBqcVOcAVHvPi8vj/LyctatW4cgCDidTjo7Ozl//jznz5+/aR6/zWZjZGQk5CcImUyGwWAgPj6e9PR05HI5Xq8Xh8PBq6++ysDAwC1TiXs5CoWCoqIiMjIy0Ov1LC8vMzk5SVNTU9h43H6/n+np6SsKpEQ0Gg16vZ78/Hzy8/NZt24dGRkZxMXFkZaWJikxnjhx4orI02qTkJBAbm6u1B8tCAI+n4+2tjbOnj17hS1KpRKtVktxcTGFhYVkZmauiIwtLS2xtLS0ZnrrU1NTHD9+nNjYWEmDQiwiVCgUnD59msnJSaqrq0lISECn09Ha2kpdXR06nY6uri7m5+eZm5tjcXERu90eFpEncR1LS0ujvLyce++9d0XY1uPxMDc3x+joKC6XC4PBQEFBAZmZmZSVlXH//fevqBkSRb3i4+OJiYlZE2fgZuF0Ouno6MDr9Uo6JOHkEIib5MzMDFarVdIVMZlMfP7zn7+iLiIYDDIyMsKZM2c4ceJEWKxjl69FSqXymvuZTCbDZDJ9ZIfdzeCmOAMmk4nc3Fy+/vWvS60pi4uL9Pf388Mf/pDOzk4mJydvqjMQDnKrYm/7nj17+NznPodWq6W3t1eqxA+HAqhPg1KpXFHh3tXVxdmzZzly5EjIvenrxev1sry8TENDAy0tLbz11lucO3eO7du38/jjj7N+/Xo0Gg19fX0cPHhw1Sp0r0ZlZSUVFRXSn10uFw0NDbz88sscPXp0xXOj1WrJycmhuLiY73znOyQlJa1IEQiCwKuvvsrx48c5f/78mhRODQ8P8+///u+8/fbbWCwWcnJyKCkpITk5maysLEnJUtxAlEol69evp6ysjD/4gz+QhKD6+vr4X//rf4VN+NlgMJCXl8cf//Efs2nTpivyt1arVRqU9sQTT0hdNqITdHm0Bi69R0ajUZKIvlUxGAwUFxczPT0dFpsoXJpNsnv3bp566in27t274mQtnqAvL450Op289957nDt3DpvNFvKDJFw6FKSlpQG/s/XDaYIPf241uWFnQC6Xk5SUxN69e8nMzCQ6OpqlpSWOHDnChQsX6OvrY35+/lNvjCqVitjY2BUnoct1p0NFdHQ0CQkJ3HXXXZSVlREVFSUVqjU2NrK0tHTLVLReTkxMDGlpaZSWlpKUlITf75dkVm8VR0BEEAQCgYBUyNXS0kIgEEChUPDYY4+RmJjI3r17OX369Jo6A6I+uojY/y06kOnp6SQmJq44eefm5pKUlLSiRVesmxgaGmJsbGzNnjcxkiGmZjweD1NTU1LtAlx6b0+dOoXBYJAEiLRaLXq9nvj4eIxGo6TWKW6yHR0dId1sYmNjue+++ygoKFgRkhW1H5RKJVlZWcjlchISEq77pCY6C7cigiCg0+nIysri/PnzoTYH+J3a5f79+ykuLsZgMKxw3C7Xgejv72dgYIDGxkaOHj0aFjUpIjMzM4yPj+NyuaTogNhJAKy4prGxMaanp1fVnht2BhQKBcnJyezdu1caODQ9Pc3hw4epq6tjZGTk0xunVGIwGEhJSZE8v2AwiM/nw+fzhfSmxsTEkJOTw759+yT7+vv7aW9vp7Gxcc3bCW8WCQkJknBJdHQ0LpeL+vp6Ojs7Q23ap0Z0CkTHdG5ujrvuuov09HS2b98uFX2uFRaLZUU4ORAIMD8/j1wux2QyUVxcTElJCbm5uaxfv57MzExJyOpygsEgXq8Xq9UakhntorjQwsICVqt1xd+JKTSVSiWFly0WC3FxcezcuZONGzdSVlbGgw8+SH9/P42NjUxMTEjv9lojk8mIj4/n7rvvJiMjY8VGL7azJiUlkZaW9olkom8HNBoNSUlJV0Q+QkVcXBwFBQXcc889xMTErHC0BEGQnjdBEOjp6eHUqVMcOHBAErUKF6amphgeHmZ6epqYmBjpmZPL5StkvAVBYHR0lKmpqVW154adAZ1OR2pqKlu2bEGlUjE+Ps7rr79OXV3dDQtxbNmyha1bt/Kf//N/JiYmBq/XK40IPXbsWEg32+3bt3P//feTm5uLRqPB7XZLoeiGhoZbsoNAo9Gwa9cunn76acxmM62trbz33nu8//77q+6VrhULCwv09vbi8XhQKBRER0eH/NRmNBrZu3cvxcXFeL1eKioqUKvVKBQKVCrVNe0Te8LPnj1LT0/PGlv90QiCcEWxqdPpxGq10tbWRmpqKoWFhTz77LOUl5ezc+dO0tLSOHfuHK+88gp+v39N3++UlBQyMzNJTk6WDh4iWq2WqqoqaZH+rOFyuejt7Q2bFMHDDz/MPffcQ0JCwop3w+Vy4Xa7pbk3gUCAM2fOSBNLwy1SK0YDn332WTZv3kxhYSEymUyqc7JYLMhkMqneYbXnXtyQMyCTySgqKiInJwe1Wo3T6WRwcJAPPviAycnJTxVWlsvlpKWlUVlZyfbt2ykpKcFisaBUKrHZbLzxxht0dXWFrC1MrOwsLCyUqrqnp6cZHh6mra1tVbWjVxO1Ws327dupqKggIyMDhUKBzWajvr6e+fn5Wy5FcC3ElAFcetbEsbRms3nNtCvm5uZW6AgolUpiYmJQqVQIgrAihXAtBEFgcnJSqsAPx/vz4c08EAhIEzxtNhuBQICzZ88iCAL5+fls3LgRr9fL22+/LbVZrjYqlYqoqCj27t1LTU0NFovlqpLbV/ucIAiMj4/jdrtZXFykubkZjUZDWloaVVVVq17wtZoolUp0Oh1yuZylpSWGh4dDfqoWnffk5GSSk5OlSasej4fm5mYGBweZmpriy1/+spQ6SEhIwGg0hp0jAL9Te+3t7SUQCDAwMCDV2lyuLioIAp2dnVdE3242N+wM1NTUSBK8U1NTdHV18dZbb31qR0Cn01FaWsof/uEfUlVVhclkQqlUEggEsNls/PznP8dqta7KCMfrQdQpLy0tlQrsRkdHOXPmDI2NjWE1POmToNfr2b9/P5s2bSIxMVHyRk+ePBkWxV0ioiDMh5XUPsnXX/57lUpFXFwccXFxa+YMTE1NSTMVxNOmOCFSRGwRExcxsdJdJBgMMjY2xnvvvXdLPnMLCwssLi5y6NAhVCoVd999N7W1tdKsguXl5TVZwLVaLcnJyTz++ONUVlZKmg8fh1g30d3dLckv//CHPyQmJobdu3eTk5NzSzsDonicQqHA5XLR39+/apr414tSqSQhIYH4+Hjp9L+8vIzD4eCVV17h1KlTDA4O8uSTT6LX65HJZBQUFDAwMLAiFx9OiFopo6OjKBQK0tPTKSgokNoKRbsbGxvp7+9fVVtu2BmoqqqiqKgIuOT5+/3+T3wyFk/bOTk5fOc73yE7O5uYmBhpclMwGOTFF1+UhE1CdfJWKBRYLBaeeOIJCgsLpc87nU5GRkbWPLR5s0hLSyM/P597772XhIQEAoEATU1NUv93uHRFGI1GiouLycnJYXl5mZdffvkTfw9RWU58rrxeL0NDQ6vudV/O0aNHcTgcJCcnU11dfdVIwMDAAH19fbz44ovodDoSExP5sz/7MylfLQ4vOXv2bFg5a58EQRBoa2uTplHec8890sZ84MCBNRFQMpvN0mjYT9LH3dvbS2trK3/zN3/DzMyMJAmdkJBAVlZW2OTXPy1VVVV885vfRKfTMTMzI804CSXiYVGv10sdNV1dXTQ0NPCrX/2Kubk5lEolJ06cYN26dRQWFlJdXY3D4aCiooLu7u6QOzQfhVar5YEHHpAOwXBtMb7V4IZrBkRJVbikKna9LTRyuRyDwUB0dDSFhYVkZWVRWFgopQXE3JzH42FyclJqEQtlqEqU5y0tLSUmJgZBEFhcXGRsbIze3t6wDNV+HDKZjNTUVMrLyyUHTBAEJiYmUCqVUvRD7Nv3+XwsLy9fkQ+en5/H5XKtWvrGbDaTmZnJ3r17MZlM2O32T+XtWywWSktL0el0UjX+8vLymjqYDoeDvr4+Dh06hN1uJykpSVIPFDtvxsfHGR0dpampifj4eCnEfjl+vz+sF7frwev1MjU1RUdHB7t27ZKmna5VHYfoHH5UbcbVEFsJLRYLUVFRkpNWXFxMcXHxivZPt9sdNvn26yEpKUlaj8fGxrBarSwtLYX8UBAIBKTpg3Nzc+j1ejweD4uLi8zPz+P1epHL5UxMTEhzO6KiojAajVgslpDXBn0ccrmc2NhYoqKipBkFLpeLmZmZNXHEbjgyIBbdiG0cHzVt7fKvU6lUJCcnk5+fz7PPPitNMfswc3NzUlvIxYsXb8TcG8ZgMJCQkEBNTQ0qlUrS825vb6e+vv6WrBWQy+WUlJSwa9cu9Ho9CoWC5eVlRkdHsVgs7N+/H71eT0xMDJmZmczOzjI7O3vFSbqrq4uRkZFVcwbS0tLYtGkTX/3qV7FarTQ1NX3i7yGG4T73uc9hMpkIBoNrohv/Yebn57l48SIdHR1kZ2eTkpLC9u3bOXjwIN3d3dJUObGFtrCwkOTk5Fsy6nQ9zMzM0NDQIG2YobjOT/p/ms1mqZtIVJSES11G2dnZKwoNZ2dnQ1bj9EmRy+WUlZVRWlpKWloa77zzDg0NDWGRilpeXsZqtWK1WrHZbNKE0stTf8FgELvdLqlhqtVqqeU1nCTsr4ZMJiM6OlpqxYVLUeeenp412Vtuyk9HfJGuZ2a00WjEZDJRUVHBvffey759+4iNjb2ighcuhUrPnDnD97///ZBOBlMoFJhMJp5++ml2794teZhut5tf//rXnD59GofDEXLP+ZOi0+nYvHkze/bsYdeuXdLLolKpeOSRR6QefVE4Rq1WSydUMTTt8/mYnJwkPj6elpYWGhoaVmUxNxgMmEwmYmJisNvtkj3iQJiPQyaTUV5ezq5du3j44YcxmUwMDw/zyiuvrKnGwOWILUN2u53e3l7m5+fxeDwf+/MLBoM0NzfT19e3RpauLj6fj/n5eQKBwJpX6/v9fhYXF5mamiImJua6awbMZjMGg4Gnn34apVIprV+Xt1KKzuahQ4eoq6tbtWu4WSgUCvR6Pffccw+VlZUsLCxw6NChK+bIhBNioZ3FYsHhcCCXy0lJSVnzduGbgUKhICsrC7PZLMkRz8/PMzQ0dOs4AyIpKSlkZWWRlpZ2hb64SqUiLS1NKv6oqKhg/fr1ZGdnX/F9RM3y9vZ22tvbQ168olarSUhIoLCwkOLiYuBSG8vk5CStra3YbLZbKkUgRnTS0tLYvXs3BQUFK14euVxOXFyctPFfHqISK941Gg1+v5/Z2VlGRkZWXRTD5XKxuLiI2+3GYDCQnJxMZWUlfX19zMzMfOQGKs5637RpExUVFcTGxrKwsMDo6CinT58O6alH7NX/pDMfJiYmpGl5tzo6nU7SKFleXl7TOhW3283Y2Bhnz57F5XJRU1MjCcB8FAqFQnqurobf72d+fp7BwcE1qQS/UcR3PjMzk+LiYqKjo+nr65OmfIYrUVFRJCQkSF0gWq12Rf2HOClzeno6rNdovV5PbGwsycnJK3QsnE4nfX19t54zcN9995GTkyNN6xJPj2Lh3Re+8AUyMjKIj4+/6rhG+N140K6uLn7zm99w8eLFkC56crkcvV5PRUUFhYWFZGRk4Pf7sVqtdHR0cOLECSkkdaugUCh48MEH2bdvH3v37l1xGrv8nvh8PhYXF69YnMXCO6fTSW9vLz/+8Y/p7u5e1fskDqcaGBggJyeH2NhYvvnNb/L973+fU6dOfeTLotVqiY+P56tf/Sq5ubnAJWnZhoYGXn311VWzebUQBGFN+o7XiqSkJPbs2UN0dDQTExPSJMC1wOFwUF9fT19fH9XV1XznO98hLy9vRWfHp2FpaYnu7m5eeOEFTp06hc1mu0kWrw5arZby8nL2799PbW0tQ0ND/OY3v2F0dDSs6x10Op2UwtRqtaSmprJjxw6MRiOCIEiTMZubm8O6viYlJYWysjJKSkpWdKFYrVbee++9NbkHN+QMBINBDhw4wJYtW7jjjjvQarUUFhbyZ3/2Z1eEb5VKJUlJSWg0Gmk28+UsLi7icDh4//33aWlp4cSJE0xMTIR8Sl5VVRWVlZX8l//yX0hLS8Pv92O323nllVd48803pfDmrUBmZibZ2dk8+OCDbNmyhezs7BXSnS6Xi9HRUaxWK+fPn2dkZERq47z85C0WTy0uLrK4uMj4+PiqP6yLi4tcvHiR7373u/zJn/wJpaWlbNu2DYVCwT333MOxY8cYGBjAZrNJY7KVSiU1NTVUVlaydetW0tPTkclkzM7O8g//8A9hI6/6WSY9PZ3c3Fyys7PRaDTMzs5SV1e35tGa2dlZGhsb+Yu/+Av27NlDWVkZd99993V9rc1mo6+vj76+PqkG5dixYwwPD2O1WsN+LoFGo+HLX/4ymzdvZsuWLZK+yG9/+9s1a7f9JHzwwQe4XC6ys7Ol4s1vfetbyGQy1Gq1JNkdCAR49913OXPmDIuLi2G9Tufm5rJp0yZpYFEwGMRms2G1WqVOtdXmhpwBsf9Rq9WSl5dHUlISUVFRK9ruPowoJiIOLhIEgZmZGRwOB3a7nbq6Oi5evEhra+uNmHbDyOVy1Go1xcXFVFdXU1JSgiAILC0t0dHRQVtbG52dnbdE0aBYoV1RUUFpaSnbt28nMzMTs9ksSeHOzc0xODjI0NAQ/f39nDt3Thoo43K5rnAGNBrNmoZzA4GAtGA3NTWhUqnIzs6mqKiI2NhYAoEASUlJ0tAb0RkQUwMbN24ELi3c3d3dNDY2MjAwsCa23yiiMM7lERzRqb5VEafOpaamkpaWRnJyMvPz80xMTDAxMbHm0z59Ph8Oh4PGxkb0ej2zs7NER0dfVw3D2NgYfX199PT0SN1Op06dYmZmJuzbPsWTdWVlJTk5OWg0Gk6dOkVrayvDw8Nhub6NjIyg1+uxWq2kpaVhNpspKyuT9hOFQiFNmGxpaaG/vz+sHQFx1oU49wJ+p+ApHrjCvrVQEATefPNNuru7cTqdfPnLXyY9Pf0jv8bj8TA/P8+hQ4ckHfIDBw4wMTHB9PQ0TqczLG6cRqMhPT2dhx56iC1btgBITszf/d3f0dHREfKoxfUSExPDnj17+NrXvkZ5ebm0iQQCAZaWljh58iSnT5/m3/7t36ThMx+F+HVrjcfjYWBggL/927+lqKhImpKZl5fHli1brvrCXB756Ojo4ODBg3zve98Lm+fsehAVL8XCVZlMRkpKyqrPN19NxGK12tpatm3bRkVFBS+//DJ1dXUhO436fD6mp6d57bXXeO211/jbv/3bkNixlmRmZlJZWcn69evxer0cP36c//7f/zsjIyNhO37darUyNzfHiy++yL333suGDRuktI74vo+NjdHY2Mgbb7wRkrkd14s4wCs3N5eqqippWJEoqOT1etesnf6GawZEJbRXX32V0dFRsrKypOLAyyd7LS4ucuTIEfr7+7FarZw+fVoS6RkbG5NGzobLAh0XFyfVQBiNRuBSS5jNZgt5HcMnRVTZ02q1UmGUOM3rP/7jPxgcHGR8fHxNc7U3wtTUFB6Ph7/+67+mvLyc7Oxstm3bRmZmJomJiZKzEwwG6ezsZGpqCpvNxltvvUVPT88NTdEMBTMzM1ecbmJjY1cMO7rVKCoqYvv27Tz66KMkJiZit9t5/fXXuXDhQqhN+0wgk8kwm83s3buXJ598EkEQaGlpkcZ5h3tEw+Vy8cYbb6DValEoFGzduhWFQiENJDt//jxHjhwJW6luEaVSSUpKCqmpqSQnJwO/m0Z64cIFhoaG1s6Wm/FNFhYW6OnpYWFhgbS0NGkUa2pqquSxzc3NcerUKbq6uhgaGqKzszOsF2RRYzw6Ohq1Wi3JRvb29jI1NRXWD9iHEQQBr9eL2+1mfn6e5eVlOjo6aG5u5t1338XpdIb9y385brcbt9vN5OQkU1NTZGRkoFQqcTgcpKamShXegUCAxsZGbDYbIyMjnDhx4pZxeC7H6XQyOjqKx+ORujimp6fDovf70xAVFUV2djZbtmyhuLhY0mdvb28P+6r72wFx7kBJSQkVFRWUlZVx4sQJOjs7aWlpCQu1wY/D5/PR399PW1sbsbGxmM1mSba+vb2dpqYm2tvbr6tVN5TI5XKioqIwGAzodDpJSM3v99PX17e2bc/CdQJc94dcLhcUCsUVH3K5XJDJZJ/oe32aj5txHSkpKcJzzz0ntLW1CR6PR7BarcJzzz0n5OTkrMk1XM+tud7vo9FohPT0dOHb3/628MILLwh//ud/LlRUVAgajWZNruNm3ZNrfchkso985m7mc3cz35Pr/VAoFEJsbKxQX18vtLa2CqdOnRIKCwsFrVYbtvfkWh9KpVK45557hH/6p38SXC6X4HK5hDfffFPYtWuXEBUVdcvck9X6WIvrSEtLE3bv3i309/cLNptN6OvrEzZu3CjEx8evyXXczGu52rsvvvO3wj1RqVRCUVGR8POf/1xwuVyCIAhCMBgU5ubmhG3btglJSUlrdk9WRZIpnE/814vT6eTo0aPY7XaMRiNut5uWlhap8PFWwufzMTMzw6uvvoper8fpdDI2Nha2OcFPirBG2t2hIhgMsri4yHe/+11UKpU09e9Wu3+ifO+TTz7JunXrUCgUHD58mOPHj9PZ2XlLRaduReRyOUajkT179nDnnXcSFxfHiRMneO+99xgaGrolI023+rsvDuCz2WxMTEwQFxdHT08Pra2tWK3WNa2fCW99xhAi9gl3d3eH2pQbJhgMsrS0RGNjY6hNifApEP7/NM/bb78dalNuCLVajclkYvPmzcTFxeFyuTh37hzNzc3Y7fZQm3fbo1AoiIuLo7Kykh07dkhFte+8886a6d9HWEkwGGRubo7h4WG6urpITEzkwoULnDp1SqqNWisizkCECBHWBFEtTqPRMDQ0xPnz5/nlL38ZMjnozxp6vZ49e/ZQUVGBxWLhpz/9KYcPH2ZwcPC2iObeyvzsZz/jF7/4hTRN9WqDyVabiDMQIUKENWFhYYGhoSG++93v4na7sdlszMzM3HIFnbcqHo+HM2fO4HQ6SUxMpKmpKeIIhAl+vz/kReky4ToTLleTDg5XPuqSbpfrgNvnWm6X64Db51pul+uA2+dabpfrgNvnWm6X64BP4AxEiBAhQoQIEW5P1nZeaIQIESJEiBAh7Ig4AxEiRIgQIcJnnIgzECFChAgRInzGiTgDESJEiBAhwmeciDMQIUKECBEifMaJOAMRIkSIECHCZ5yIMxAhQoQIESJ8xok4AxEiRIgQIcJnnIgzECFChAgRInzGiTgDESJEiBAhwmeciDMQIUKECBEifMa57qmFt8tAhtvlOuD2uZbb5Trg9rmW2+U64Pa5ltvlOuD2uZbb5TogEhmIECFChAgRPvNEnIEIESJEiBDhM851pwkifDaRyWRkZ2eTlJREZmYmw8PD2O12+vr6Qm1ahKtgNptJTExk27ZtLC0t4XA4eO+99z42RBjh5qNSqYiOjmbTpk3Ex8ej0WgAcLvddHZ2MjQ0xMzMTIitjBDhEhFnIMJHolAo2LRpE1u2bGH//v289dZbnDlzhsHBQWmDCQaDIbZyJXK5HJlMJuXzBEFAEISws3M1SE1NZcuWLfz4xz9mYmKC5uZm3n//fQKBQKhN+8yh0+nIyMjgG9/4BtXV1ZjNZgCmpqb48Y9/zGuvvRZxBiKEDRFnIMI1SU5OpqCggG984xtkZWVhNBrZu3cvlZWV3HPPPQwODtLd3c0LL7wQalMBsFgsJCYm8oUvfIGysjJyc3Px+Xy0trZy4sQJXn31VZxO5227McpkMu677z62bduGQqEgISGB1NTUUJv1mUImk6FQKMjKyqKmpobnn3+egoICoqOjAVheXsZms/GLX/yCqampEFsbIcLvCBtnQKvVEh0djcFgICYmhpSUFFQqlfT38/PzLCwsMDIywuzsLB6PJ4TWXhuDwYDZbCYzM5O5uTkGBgbweDy3TJhWqVSi0WjIzMwkNzeXiooKMjIysFgsyGQyzGYzGo0Go9FIYmIi8fHxDA4OcvHixZCfcvLz86msrGTz5s3k5uaSnp6Oz+eTnqMLFy4AhNzO1UCn05GcnExxcTG5ubkALC0tsbCwEGLLPjuo1WrMZjMpKSnU1tZSWVlJQUEBUVFRBAIB7HY7Q0NDtLe3Y7fb8Xq9oTb5lkIulxMVFYXZbMZoNJKVlYVSqUShUEj/JhgM4nA4mJubw+FwMD4+jt/vD6HVtw5h4wzExsZSUFBAYWEh1dXV7N+/H7PZLN3otrY2Ojs7eemllzh79iwTExMhtvjqJCUlUV1dze///u/T3t7OT37yEyYmJvD5fKE27bowGAzEx8fz+OOPs27dOtavX4/ZbJZC7iqVCoVCgcViobCwkKqqKnJzc/mrv/orTp06FVLb9+7dy+c//3ny8vKQy+UIgoBSqaSoqIjc3FxOnTqFXC6/LZ2BuLg47rjjDmpraykoKABgZGSEvr6+W8YRvdUxGo2UlJRw77338oUvfIGEhATp7xwOB+fOneOVV16hqakJt9sdQktvTTQaDVlZWVRWVlJSUsIf/MEfEBUVJdViAPj9fs6cOUNraytnz57l1VdfjTjE10lInQGtVovBYKCyspJt27Zx9913ExsbS3R0NEajEbn8d80Oubm5JCcnU1RUxA9+8ANOnz5NV1dXCK2/EqPRSG1tLc8++yxFRUV4PB5MJhNTU1Nh7wxERUXx9NNPU1FRQXFxMenp6RgMBgwGA4FAgLa2Nt555x0uXryIUqkkLy+Pp556ipiYGFQqVVj02zY3N6PVaklISMBkMhETE8O2bdvQaDQolUq+9rWv8corr9DY2BhqU28qogP67LPPkpycDEAgEKC5uZkzZ85EnIFVJjo6moSEBL71rW9RUFBAVlYWMTExBAIBPB4Pb7zxBi0tLbz77rtMTEys2eaUlZVFdnY2DzzwADk5OcTFxQEwMDDA2NgYc3NzWCwW4uLiyM3NRRAE3G43586do6WlhSNHjjA/Px/StJpMJkOpVPLII49QWVnJzp07MZvNREVFYTQaV0QF4FKNU0VFBbm5uezatYtNmzZRX1/PgQMHWF5eDpt3QSaTYTKZMJlMlJSUkJeXR3x8PMPDwywvL+P1eunu7mZmZoaZmRliYmKora3lC1/4Ag6Hg8bGRn74wx/e1DqokDkDCoUCo9FIUlISW7ZsoaamhpKSEvR6PTKZTLpp4q96vR6dTkdUVBRJSUlERUWFyvSrolQqqaqqYv369RQUFGCxWKR0h9VqDdu0BkB6ejqZmZls3bqVkpIScnNz0el0uFwupqamGBgYoKWlhbq6Onp7ezGbzcTGxuL3+6WXVaFQrLhvocBqtUoV3Eajkfj4eKqqqiT7srOzpc3ydiItLY28vDzpvvl8PmZnZ+nt7aWnpyfU5n1qLo9GKZVKjEYjc3NzYXOqlslkpKWlkZqaSl5eHhs2bCA9PR2j0UgwGMTpdNLb2yudVHt6evB6vatayGoymTAajaSkpFBYWEhOTg5btmwhJycHi8UCQEJCAuPj4ywsLEjvck5ODsFgEI/Hg0qlQqvVMjU1RUNDA4uLi6tm78ehVCoxmUxUVFSwefNm1q1bJ6X9xHTx8vIy8/PzUoozJiaG6OhoYmJicLvdLC8v097eTk9PT0ifHblcjslkIioqisTERJKSkoiNjaWoqEhy1jIzM1leXsbj8ZCUlMT09DTT09PExcWxceNGamtrcTgcLC8vExUVhcvlumnOWkicAZlMRlRUFHl5eVRVVfG1r30No9H4sadLmUyGRqORPkK9+VyOVqvl29/+Nnl5eSQkJCCTyaQWr7a2trAOVe3fv5/HHnuM2traFZ720NAQdXV1/PCHP5ROEgBlZWUrHDelUiltuKHMz7W3t9Pe3i79OTo6mocffhi1Wo3BYJA2ldsJmUzGnXfeybZt26TFfnZ2lvPnz3P48GHOnDkTYgs/HaJzqVAoMJvNWCwWampqOHv2LH19fWHRGaJWq3nkkUfYtGkTtbW1JCcnS8+X2+2mo6ODv//7v6euro7p6ek1sam8vJyamhqeeeYZKbr34YOVGDEQET8v5uR37txJfn4+hYWFfO1rXwupM6DX6ykoKGDnzp1s2rRJ+rzL5eLMmTOMjIxgs9k4e/YsMTExJCcns2/fPnJzc6X9RdyAv/3tbzM8PByS65DL5Wi1WjZs2EBZWRmPPPII+fn5xMbGSv/m8v1PvCfLy8u43W70ej0KhQKFQkFMTAw2m43s7Gz6+vpwuVw3xcaQrIxRUVF885vflE6hBoPhY79mcHAQm81Ga2sr58+fZ2JiImwcAbh0s5OTkzGbzQSDQVwuF729vRw6dIj5+flQm/eRBAIBaROfmprCZrNx6NAhuru76ejoYGRkRPKoU1JSyM7OJjs7G61Wy9LSEu3t7bjdblQqVdgU60RHR5OcnIxOp5MW6LGxsTVblNeC2NhY8vLy2Lt3LyUlJQDYbDba2tr43ve+R29vb4gt/GSkp6eTmJhIUVERhYWFxMXFSY6AwWDAaDRy6tQpGhsb+cUvfhGSZ00ulxMbG8vWrVvZvn07+/btIy4uDpPJhEKhwOFw0N/fz6uvvkpHRwdnzpyRnOi1QOyoSUtLY3BwkIWFBYLBIMPDw0xPTzM7OyvV0uTn5zM3N4fT6cTtdhMbG0t6ejp33HEHJpOJ4uJikpKSmJqaCqvDzD/8wz9w9OhRbDYbbrcbr9eL0+mUIhr9/f1oNBrUajXl5eXMzMzQ3NzM7OxsSOw1mUxkZ2fzxBNPsGHDBlJSUkhMTMTj8dDX10dLSwvj4+M4HA4CgQDR0dGYzWaqq6uJiopCp9NJB2HxsGY0GqmoqGBiYuLWdgbUajVbt24lJydnRdhWEAS8Xi+BQACfz0d0dLRUNzA1NUV/fz8nTpzAarWu6Qt2PchkMgwGA2q1GkEQmJ6eZnR0lP7+/rCvGp6dnWVoaIjk5GTGxsbo7+/n+PHjDA8PMzIygsvlkk5iGRkZZGdnk5iYiEqlYm5ujo6OjrBzePR6PTExMdILJAgCVqs1LAtPxZSZqIVwvT9Ls9lMeXk5WVlZUj54bGyM7u5umpqawiI1JUbxoqOj8fl8LC8vMzc3Jy3ccXFxqNVqNBoNOTk5pKamUl5eTllZGXFxcVgsFoxGI2q1GgCn08n8/HxIalSio6MxmUwUFRVRW1vL7t27KSoqQqFQEAwGGR8fZ2hoiObmZk6cOMHQ0BCTk5NrauPS0hJOp5OxsTGampqk9sX+/n4mJiZwOBwIgoBKpWJiYoK5uTlmZmZYWloiKysLr9fL9u3biYqKIjY2VirQCydnoK2tjQ8++AC3273iQKhSqdDr9fh8Pjwej9SBNjc3R39/f0jeB7lcTlZWFuvXr2fHjh3k5+ej0Wiw2WyMjIwwPj7OhQsXGB4eZmpqimAwiNFoxGKx4PP5pM6JtLQ04uPjSUtLAy4Veufn53PixImbFiEPiTOgUqlYt26dtACKCILA0NAQDoeDmZkZduzYgdFoBGB0dJTm5mZ+85vfhFVE4HJkMhlyuRyfz8fx48c5e/Ysdrs91GZ9LIcOHeLMmTMUFBQwPDzM4ODgVYttZDIZ+/fvZ8uWLZSXl7O8vMzIyAj/9E//hNvtDpuoAFyqri8sLCQqKkqKWBw4cICzZ8+G2rQrMBqN3HXXXQQCAebn5zl8+PB1hcHz8vJ4+umnSUhIkKIfhw8f5uTJkzfttHCjpKenk5uby+7du5mammJ4eJg333yTxMREysrK+E//6T+RlZVFRkYGer0epVK5oqX4w/j9/pAV427evJnt27fz5JNPEhcXJ6U2A4EAS0tLfP/736epqYnGxsaQFd4dPXqUxsZGTpw4QWdnJ06nE7j6kJojR46s+PPCwgJJSUkEAgFUKhVGoxG9Xr+iWj8cCAaDBAKBK64pKSmJwsJCfvKTn+D1eunp6eGP/uiPGBsbC8m9UCgU6HQ6vvKVr7B582bKyspwOp20t7fzP/7H/+DixYtSp9nV7s9LL72EQqFAq9Wyd+9e9u3bx5e//GXgUt3Hfffdx9tvv834+DjLy8s3bO+aOQMymQy1Wk1NTQ2bNm2SPP3LEQSB/v5+ybOen5+ntLSUiooK6e/D1RGA39knCAJ2ux2HwxFqk64Ll8sledPi7z/8c05LS6O6upqCggLpFNrS0kJjYyNutzushHx0Oh0FBQXs2LEDpVLJ8vIyCwsL9PX1YbPZQm3eCoqKiigrK+MrX/kKgiAwNjZGfX09S0tLH/kzjY+PJyUlhfT0dNRqNRMTE5w6dYqjR4/S0dGxhldwJVFRUZhMJqqqqti2bRvr1q0jIyMDt9vN/Pw8mzZtIjY2luzsbHJycqQNZ2ZmBqfTidVqlSIkl9eAAPT09DAyMrKmz5vZbObpp59m48aNFBcXk5iYiEajwe/3c/z4cbq6uujo6ODEiRNMT0+zuLgYspqGYDDI4uIi3d3dLC4ufqL1MhzqMD6M1+tlbGyMvr4+SRK9rKyM4eFhjh8/vuL6UlNTqampkQ6QwWCQ+Ph45ubmQhJJFovjKyoqsFgsNDU1cfDgQdrb22lubmZubu6ajgBc2k8CgQBer1cqhBRRq9XEx8cTHR2NRqO5tZwBURGturpaWqSDwSCCIEipAEEQmJmZob+/n1OnTlFcXIxaraaiogKtViudHK7mFYaayyVv/X4/09PTYRc6vxY+nw+fz3fN06ROpyMtLY1t27aRnp5OVFQUHo+Hixcv0t7eHjYRAblcjlKpJCMjg4KCAkpKSlAqlTidToaGhhgbG5NOSqFGLpejUqkoKiqipqaGLVu24Pf76e3tRa1W4/F4rrnhKRQKcnJyyMzMlIoGp6enqa+vp6enJ2SpENHhT0tLIz09ne3bt7Njxw5KS0vRarV4PB48Hg+JiYlYLBaSkpLwer0sLi5KIXabzUZnZyd+vx+Hw8Hp06dX/B8zMzNrstmKOVpRQOzuu++msLCQlJQUqVNAtK+xsZFz585ht9vDwin2+XyfSktDoVBIUt4QHuN5xc6YwcFB0tLSyMzMJD8/nw0bNtDd3c38/Dxut1va+MUwvN/vR6FQhLRo2GKxUF1dTWpqKkqlkp6eHo4fP057e/t1v6OiQ7CwsMDS0pKUEhBT6XDz7tOa/ZRMJhPPPfcce/fuZf369SgUCpaWllhaWiImJmbFBQUCAdxuN2+++SZer5dHHnmE9evXEwgEiIuLY3Z2Nuzy8KIW/vLyMg6Hg9bWVoaGhkJt1g0jl8upqanhrrvu4plnnsFgMDA/P09DQwP//M//THNzc6hNBC6lnnQ6HQkJCfzd3/0dJSUlZGRk4PF4eO+99/jHf/xHurq6wiKPDpdyfgUFBTzzzDNs2rQJuVzO/Pw8DocDn893zc1OpVIRFRXFt771LcrLyzEYDNjtdrq6unj77belvGMo0Ol0lJSU8Ed/9Efs2LGD9PR0qV5DVOMcHR2VCqMEQaCjo4OTJ0/yi1/8gv7+/hV54KtFAtfqEKDT6SgrK+NrX/saO3fuJDY2VjrA9Pb28uKLL/LSSy8xNzeHx+MJm3bHG0Gr1RIbGxsWbcIiYurslVdeYXx8nB07dnD//fezbds2ioqKePnllzl16hTz8/OkpKRQVVWFSqWis7OTd999l97e3pCJjCUmJrJ3717MZjMjIyMcPnyYzs7OT+ysB4NB6uvrycnJAS7tNTabjZdeeone3t6bduhcE2fAZDKRlpZGVVUViYmJCILAwMAAvb29jI6O8sQTT6DT6a74ukAgIC1sYlWxRqNZIUYUDuTl5VFeXo5arWZoaEga5BMup9BPi1hd/NRTT1FeXo5Op6O3t5e2tjZeeuklqbYg1BgMBu68807WrVtHYWEh69atw2w2I5fLpRPmwMBAWNgqEhsby3333UdGRoYk7NTf309rayvLy8vX3NDNZjPZ2dlSVMDv9/Pmm29SX1+P3W5f82tUq9XSteTn55Oenk5lZSUWi4Xx8XHa2tro7++nu7sbh8MhhbC9Xi8Oh4PJyUlGRkYYHh7+2NTIWlFWVkZ+fj6PPvoo1dXVWCwWVCoVVquVoaEh/u3f/o3W1lampqZYXl4OC5tvBmKbMMDi4iIzMzNh00kwNjZGe3s7x44do6SkBLPZzNatW5HL5ZSUlNDX10d1dTUJCQlSXv7gwYMhq51Rq9XodDpJGGlpaYne3t5Pbc/ljrH4+5sdIV91Z0CpVJKcnEx+fj75+fmYzWb8fj8dHR1cuHCBvr4+7r///qvWEGg0GkndTqxKFr3WcEGpVJKbm8uOHTtQq9XYbDbOnDnD5ORk2BRxfRoUCgWJiYlUVlayb98+kpKSAOjq6uLUqVO8+uqrIbbwEmIXx86dOyWHQEQsNBI/RIniUJ94NBqNpEGRlJSESqVieXmZgYEBLl68eM08olwuJyYmhsLCQuLj41Gr1TidTqloLBR5Ua1WS2ZmJvv376empgaLxYJSqcTj8WC1Wjl58iT19fU0NDSwvLyMTCZjcXGR6elp+vv7pXsTDvlqsRe8vLyczZs388ADD6BWq5HJZCwtLdHf38+5c+c4cODACsdFLPJSKpXS2iR2Rd0qjoJ47VFRUcjlcjweD5OTkzidzrBYxxwOB1arlbq6OgwGg1QXpNFoyMvLo6WlhdLSUkwmE2NjYwwMDHDhwoWQRZDVarWU2oZLuhOjo6M3ZM9qr12r6gxotVry8vL40z/9U+644w6SkpKQy+XY7XaeffZZnE4nWq2WBx54gHXr1pGbmyuF22UyGbW1tVRXVwOXdNbFvtlwyVGLuvf3338/X/rSl9BoNExOTtLQ0BB2aYxPgkwmIyUlhc997nN84xvfwGKx4PF4mJmZ4YUXXgib1ABcaiFMSUnh8ccfl/LnIjKZDKPRyP33309GRgZ/+Zd/yejoKEtLSyGy9hI7duxg27Zt1NbWotVq8fv9TE5OcuDAAd5+++2rbiAymYzY2Fh27NjBc889h9lspr29nf/4j//g6NGja97CJpKRkcEf//EfU11dTXx8vLQZulwuXnvtNU6ePElnZ+eKYV11dXVhN1JaJpORnJzMvffeyx/+4R9SWlqKWq0mGAwyNzfHb3/7W9566y3Onj27ojBPrVaTkZFBaWmpVOME8P777zMyMsLIyEgoL+u6EJ+tiooKHnjgAQwGAw6HA4/Hg8/nCwuHJhAIMDo6yt/8zd9QV1fHhg0b+NM//VOSk5NJT09n48aNUkpqaGiIiYmJkKYERWdAVHJ1OBxMT0+HVXTyw6yqM2AwGKipqSErK0uKCIgh28XFRbxer+QczM3NIQgCDodDyoHExcURExMDwPj4uNTzHg4Pp4hSqUStVqNSqZiZmWFycjJsCok+jFarxWQyUVlZuULSc3BwkImJCQKBAEqlEoPBwIMPPkhtbS0mkwmA4eFhDh06FNIc3NVYXl5mcnKS//f//h8ZGRlSp4PYE15SUkJCQgJlZWWkpKRIhTihQPzZ1tbWUlNTg1arZW5uDpvNxptvvkl/f/81FwuVSkVtbS3r168nLS2N8fFxOjo6OHv2rCQsEwrEcCWsLGTS6XTs3bsXi8VCTk4Ox48fl4q9wvHdMBqNko5/Wloacrkch8NBS0sL3d3dvPHGG/T09EjrVHx8PImJidTW1pKdnS1pyyuVSgRBQK/X09TUxIEDB8Lyei9HqVRy5513UlFRgcFgQC6XMz09zfnz58MiKiAi6tB0d3ezsLCAXC6XpHxFZyAYDJKZmSnJ9r7//vssLCys+T0QD7RiobComPtp0Wq1K6LnLpeLvr6+m1qrsirOgBjWj4+Pp7a2lpSUFDQaDU6nk4GBATo6OqTFKxgMMjY2xtTUFC6XSxLCUCqVxMfHY7FYEASBiYkJxsbGQn6quxxRLlUulxMMBpmZmWF6epqZmZmwWgDEh9JisZCZmcnv/d7vSTUaIyMjvPvuu9IGbzAYSExM5KGHHiI3NxeVSsXCwgLd3d28/PLLWK3WsFogfD4fdrudn/zkJ5IAD1xq60lPT6egoACTyYReryc1NZWJiYmQtBfKZDL0ej3JycnSpq5QKJicnJRO+Nc6RSoUCvR6vdSmFxsbS1tbm9SiFMriNZ/Px/T0NAsLC5JImBg2v/vuu6V7MDAwwPDwcFgW2slkMuLj4ykqKuKee+4BwOPxMDExweHDh6mvr+fEiRNSNECpVJKamkp1dTVf/OIXycjIIDU1dcX3FFUT33nnnbCphbgWKpWKO++8k7KyMkk0bXJyktOnT4fVuy4iiqG1tbVxxx13sH37dqqrq6W1ODs7W5K8F7ud1lpS+fL8vkajQafToVKpkMvln+pZiI6OXqHU63K5brqQ0k13BtRqNTExMTzzzDNs3LiRnTt3So7Aj370I44cOUJra6u0KCwvL/Ozn/2Mw4cPk5uby9GjR9Hr9ezcuZPt27dTWFh4s028aahUKqqrq0lJSQGQ+kHDbcEzGo2Ul5fzpS99ifXr15ObmysVYQYCAZaXl5menkan07Fnzx727NlDdXW1NPTmz//8z2lsbKSxsTFsUjSXEwgEmJyc5Pjx49TV1QFIw0DuvPNOSTN+165dBIPBkEy7TE1NZevWrTz//PMUFxdjMBjwer386le/knrVr7VIFBcXU1NTw+///u9jNptxu9388z//My0tLSF3jvv7+/nLv/xL3njjDZKTkzGZTGzYsEEqqs3NzSUtLQ2Xy8Urr7zC22+/HVJ7P4zYPvhf/+t/paamBrgkbGS32/nlL3/JwYMH6erqkhZ3jUbDHXfcwaOPPsrv/d7vER0dfcXkPIDCwkLkcjnPP/88v/zlL0Omif9xiI5beno6MTExCIIgCby99dZbYZvuFASBpaUlbDabpEshfh4upa+Sk5MRBIH333+fn//852u6ds3OzjIxMcHIyAjZ2dno9XpKSkq4ePHiJ5ZFlsvl7Ny584p6qI9qP/403HRnwGAwUFpayrp16yguLkav1+NyubDb7bS2tjI6OrqiFUJsOxJTAHNzc6SlpbFnzx5SUlKkE+zY2BhjY2M329xPjV6vJz4+nk2bNpGenk4wGGRwcFCS/wwX1Go1FouFsrIycnNzSUxMxOl0sry8jFwul0JqYmteaWkphYWFkgiM1Wqlo6OD4eHhsB7DHAwGV4TYA4EAMpmM9vZ2BEEgMzOT1NRUKY2wlsjlch566CFqamqkhUF0xrKyslhYWMBgMDA1NcXi4qK0wYsLXlFREVu2bCE6OppAIMDs7CxWqzVkdQKXI7Z+dXd3Y7PZ0Ov12O120tPTmZubo6ioiMTERMrLy+nt7aWvr4++vr6wOSmbzWYqKyvJz8+XnHpR+vz06dPYbDbpuUpISJBqaSoqKjCbzSgUCkmjo7+/H5VKRWxsLHFxcURHR5OZmYlWqw3lJX4koo5CcnKyJNYzPj7O5ORk2LThXgsxXZOVlSWldaanpxkYGCAxMZHs7GyKi4txu93YbDbq6uqYm5tbk5Sa+O6OjY2RlpZGVFQUpaWlDA8P43Q6r7sQUKlUotfrqa6uJj8/X2r5XI3Wz5vqDIgTlWpra6WQrVgHMDIyQktLy1UHxfh8PqamppiampLCPA8//DDJycmoVCp8Ph/d3d1hNY7VZDKRmZnJnXfeSWxsLIFAgLa2trByWODSCTklJUUSv1CpVFy8eFHSh09PT+fOO++UuiHEbg2v18vg4CDHjh2jp6cn7Jycj0PUwD9z5gw6nY6srCxSUlJWTAlbK+RyOc8884w0TAh+l7qpra0lLy+Pqakp2traGB0dxW63SwV2drud6upq7rjjDjQaDQ6Hg/HxccbHx8OqdfXyk++5c+cwGo3Mz8/z4IMPYrFYKC8vlybMhVO6IC4ujh07dpCVlSUVoI6MjNDe3s7JkydXTPTLzs6mpqaGJ554Qqq6Fxf9yclJPvjgA6Kioli3bh3R0dGo1WoSExOv2ikVLiQmJlJaWkpGRgYmk4lAIBC2MzyuRkZGBuvWrZNqz1pbW3njjTeoqqri/vvvJz8/H5PJRHR0tNTat1ZFfC6Xi4GBASoqKjAajWzcuJHz589jt9uvK+Iik8nQ6XTExcWxdevWFVHy1egquKnOwGOPPcaWLVt4/PHHiY6Oxuv1MjQ0xIkTJ2hqamJsbOwjb4RcLmf//v3s3buX9PR0vF4vDQ0N/OhHP6Kuri4sTkIi27Zt46677iIhIQG1Wo3L5eLkyZN0d3eH2jTgUsGJxWLhr//6rykrKyM+Pp5jx47R1tbGb37zG1QqFXl5edx1111SAaRMJmNhYYGZmRleeuklzp49S11dHU6nM2xOcp8Uv98v9ePOz8+HJKwuCAJtbW3I5XLS0tKkcaQAubm5ZGVlEQgE2LVrl2QvIE2/NJvNmM1mpqeneeutt/jZz34W9s7Z4uIiv/71r5mYmKClpYXnn3+e2tpaEhISeOedd1Z0F4Qb9fX1HDt2TLLPYDBIqYFdu3ZJtRGifPQ777zDL37xC3w+H1VVVRQXFyMIAlNTUxw8eDCsZcmrq6t56qmnpOhFMBjk1KlTXLx4McSWfXKmp6fp7OzkyJEjnDt3jiNHjvC9732P1NRU9uzZwzvvvINGo6GlpWVN7BkcHOSnP/0p+fn5lJaW8vDDD7O0tMS5c+c4fPgwTqfzqtEXmUyGSqWiqqqKjRs3snv3bsrKyoiOjkYQBGZnZ7Hb7QwPD9/UNM5NdQYKCwspLi6WOgDcbrfkZYtiKtdaAESBmy1btlBUVIRKpZIkSpuampiZmQmLtgxx5ndWVhYlJSVSgd3o6Cjj4+NhMU1RLJ7JycmhoKCAhIQEhoeHaWhooKWlBZvNRlJS0orqVvH3YpHn2bNn6ezsDKvOARGz2SyJT83Ozn5kOPPy3txQdRIIgsDRo0cZHh4mPT2d/Px8LBYLMTExLC0toVAoiI+PR6/XXzHTfHl5WWqZam1tpa2tjb6+vrBO2QDSbIHu7m6USiVjY2NER0dLY4q9Xm/YynXHxMSQkpJCamoqGo2GuLg47rjjDkpLS0lMTJRSPMFgUDqg5ObmYjQaKS4uJj4+HrfbzcTEBF1dXSGv67gWarUas9ksXZPL5cLpdErjjsMdlUqFyWQiLi5OShOI7eculwu/3897771HTU0N27dvp6qqCrfbTXd390cKe90s3G43Y2NjnDp1Cq/Xyx133CFFjYxGI729vUxPT+P3+yV7dDodZrOZmJgYybEsKSmR0jZJSUn4fD68Xu9NL0y9qc5AcXExBQUF0uLr8Xjo6uqS9Ls/iry8PO69914eeOAB4uPjCQaDUudBuJy24VIOJyUlhZKSEsrLy5HL5YyOjtLQ0MDIyEhYLHByuZy4uDg2btxIeno6fr+fd999l7fffhur1YparSY9PZ28vLwr2l3EkZrHjh0Li2u5GhkZGcTGxkpe/vV0B4hjpUPhrAWDQX7605+i1+tJSEjgwQcfpLi4mMrKSiYmJtBoNNTW1q5I08DvunLEUPSbb77J2bNnw9JBuxZiiqmlpYV169aRnJxMYWGhNGI2HPjwAaWyshKdTsfo6KiUk3766ael2SgiwWCQkZERUlNT+cpXvkJGRgbR0dFSSLq3t5cLFy6EpTMgk8mk9ltRrdPpdNLT00NfX1/YT1uVy+VSh5BYEG2z2WhqasLn8+H3+3G5XPz93/89jz32GDt27GDfvn1oNBqOHDmCw+FY9cPl8vIyU1NTvPjiiwwODkon/a1bt/L4449z+PBhuru7WVpakmStk5KSKCkpoaSkhJycHBQKBYFAgF//+tckJSVJzsDy8vJNL+5cVZ0Bv98vFatd9T9XKtFoNGRlZbFt2zbuv/9+kpKSmJ+fp7m5mf/7f/9vyCewfZioqCgef/xxSkpK0Ol0yGQyhoaGqKurC4vIhUwmY/369ezevZvnn38ek8nExYsXOXPmjDT06bHHHqO2tpbc3Nwrhnj09PTw7rvv4na7sVgsJCQksLi4yOLiYtjkqLdu3Up1dTW5ubn84Ac/4OTJk1c9yYgLnk6nQxAEDh48SFNTUwgsvoTH42F8fJx///d/l6RKPR4PcrmchIQE4uLiSE1N5amnniIzM5P4+HgA7HY7/f39HDx4MKxyuYmJidL0QVFu+Gohca/Xy7Fjx4iOjiYtLY2CggLsdjt9fX0hsHol4+PjvP7663zuc5+T2gNFWeUNGzZIOiJijcDlqFQqdu/eLdV/qNVq5ufnaW1t5Ve/+hVNTU24XK6wElcS0el0PPTQQ2zcuJGEhATkcjnj4+OcPHmSqampsKnp+CjEEcFRUVHX/Dfz8/NSe2RaWppUO7S4uLhm6/Xw8DB+v5//9t/+G9u3byc/P5+NGzeybds2ampqVoxkVqlUkpql1WrlwoULHD16lOXlZWpra1fVzlV1BrxeL11dXVecAGQyGWazmYSEBBITE6moqKCqqkrSI3A4HJw5c4aurq6wWvzg0gMYGxsrhXTFCWFWqzVs8urp6elS9bzb7ZZ+3ikpKSQlJbF582aKi4tJSEhYcSoSpX0TExNZv349CQkJZGZmMjQ0hNVqDRtnIDs7m7KyMtLT06mpqcHj8XD+/HkWFhbwer0olUop/JmdnS21TM3OzoZUZ13seJiampJ04P1+PzKZjPHxcakuwOv1rthA7HY77e3tTE9Ph9UpMzMzk5ycHDZs2EBaWhrT09PY7Xb8fr80uVPcSMU0iFwup7CwMCwcAfidTGxDQwMymUyasKjVajGbzR/79UajkcXFRWZnZ/H7/YyMjNDQ0EBjYyODg4Nh6QjAJUdm48aNZGZmSgcCl8uFzWa74vkLV0QnTC6X4/V68Xg8V6SiL5eEFlUB1Wr1ms63EVu3L1y4ACB11BkMBmnjFz/gUkG92+2mubmZpqYmzp07R3p6+qp3d6yqMzA7O8uvf/3rK8JwKpWKkpIStm/fztatW6VKabh0g3t7e/mXf/kXRkdHw+K0fTXEau+5uTmGh4elsauhRlzQcnNzgUsPosFgYN++fezatYu0tDSio6Olf+/z+SS1LKVSSUVFBdHR0SwtLUmjgN977z3ee++9K2bLh4ry8nI2btyIIAh8/vOfZ8uWLXznO9+hs7OT8fFx9Ho9lZWVbNu2jfvuuw+j0RgW9+ZyBEGQ8v6CIEjRF7lcjtFolN4HgPb2dl599dWwa/XauXMn27Zt43Of+5yUp52cnGRhYQGn08nx48elnO7OnTtJTExEpVJx9913Mzw8zG9/+9tQX4IkLvR//s//YdeuXfzgBz/4RF8fDAYZGhri3LlzzM/P09TUxCuvvCKN1Q1XdDodjz32mFSUBpeKPsfGxsLuXfk4gsEgs7OzOBwOZmdnw7IwdXFxkebmZpqbm1EoFERFRVFcXExycrKUrhFFhcQBXkePHpUiSx8+uK0GN9UZuHyuAFyqaK+oqGBoaAiPx0NVVRVVVVWUlJSwceNGLBYLRqMRtVrNzMwMIyMjUiXo+Ph42BZJiTO/g8Eg09PTTE5OhnR07OUIgsDx48clBTix2FGsSFer1SwuLtLe3k5fXx/vvPMOVVVVrFu3jjvuuIPU1FRiYmIIBoPSgJZ33nmHhoaGUF+axMjICENDQ2RmZhIXF4fBYOB//s//yezsLC6XC7VaTVxcHHFxcURFRdHf38/58+fp7e0N28pupVLJXXfdxebNm8nMzESv1+P1enn//fc5cuQIDQ0N13wfCgsLSUlJoaysTHoeL1y4IBVRrRbDw8NSRbNWq0Wj0UhaCH6/n+LiYpRKJSqVCrPZjEqlkoq6wqlaXdzQDx06xBe/+EW++MUvUlpaKqVpRHp6eujp6eHFF1+UDili67Qo5724uBj2jsCGDRuoqamROoj8fj8ffPABhw8f5vTp02HndF4Plw8kEzdNhULBPffcw+bNmwG4ePEiLS0tDA0NhTQNIj4nHR0d9PX1oVAoUCqVUrTC7/fj8/lYXFyU1uHLaW5uXpWD2apGBvR6vdRm4/F42LRpE5s2bZIKJMT2HDE81dHRQX19Pd3d3WH7QIpaClqtFkEQcDqd0pyFcEAslBND+kqlkqioKAwGA7Ozs0xNTUmdBd3d3Zw8eRKv14vf72fTpk0YDAbMZjPz8/PY7XYGBwfDLl0zMDBAZ2en5E2bTCbWrVuH1+vF5/OhVCpRKBQoFApcLhdDQ0M0NDTgdDrD5j5djhiVSU1NJSsrC5fLhdvtZmlpifPnz9PX14fD4bjmySA+Pl6K4lgsFqKiohgdHWVsbGxVZVjHxsbo6OiQ6lFE4SqxEBKQUgaiMqfT6eT8+fNYrdZVs+vT4HK5GBsb4/jx4+zatYvU1FTJGQgEAjgcDjo7O7lw4QLHjx9f4QyIld3hjkwmQ61WSzlrMSwdCATo7u5mcHDwlipODQQC0nsijgw2GAy4XC50Oh2xsbFs3ryZ/Px8APr6+ujt7WV+fj7kKV1RrOt6+LAz4HQ6VyXdeVOdAbGNS1y0zGYzjz76KN3d3QSDQb7yla+g0+mkUZ+CIOD3++nt7aW+vp5Dhw5x9OjRsH6xtFot27Ztw2w24/P5wiqX/nHU1dVx4cIFXnzxRex2u1RY8/7779PZ2cm+ffvIzMzEZDJx9uxZ3n33XQ4cOIDNZgur0OGBAwe4ePEiCoWCdevWkZiYKOn3Xz41z+l0cvHiRQ4fPsxvf/tbachMuCFWRotzz9966y3gUmjxhRdeYGZm5pp2y2Qy0tPTSUlJQa1Wk5qaitlsRqlUcvDgwVV1Burq6qivr+df//VfJaezrKyMxMTEqxZ1dXV10dnZKeXXwwlBEHC73VitVnp7e6UWULj0LL399tu88cYb1NfXMzU1FZbP0cehUChITk7mzjvv5LHHHkOpVEp1LKdPnw6bOo7rQeywEdvPS0pKyMrKori4GL/fT3l5OXv27OFLX/oSZrMZQRB4/fXXOXPmTFjvLx/HLTPC+OTJkwQCAfbv349KpZKmFpaUlCAIAjqdTposNT09TVtbGy0tLZw+fZqxsTGsVmtYntwuJxAIMD4+LlWA/uhHP6K/vz/UZq1gdHSU119//Qq7bDYbTqeTiYmJFT9nsYjqT/7kT6SBGmIx2PT0dMi96A9js9lYWlrif//v/y0Nidm0aRNyuRylUklJSQlHjhzh3XffZWRkhImJCWZmZsI2dBsMBllYWODgwYOcPn1a+rw42vij6mYEQeDkyZM0NDRIs9PFwSxrIdIlbiY+nw+fz0dLSwsajeaKLhW4pPMgjiAP58305Zdf5vjx4/zjP/6jVCQ8NjaG3W7/RFKy4YYYgVKpVJIq4uzsLCMjIzQ3NzM6OhpiC68f8SA5OzuLzWajqKiIrVu3kpycjMPhIC4ujvT0dPR6PVarlTNnztDc3Mz4+HioTQ9bbqozcPHiRQwGA+vXr0ev16PT6UhOTgaQiu38fj9er5fOzk7OnDnD2bNnaWxsZGFh4ZZoZ/H7/YyPjyOXy/H7/VL7UDixuLgoacBfD+LmcezYsdU17CYhhtHn5ubo6+sjPj5eqsrXaDQsLy9TX1/P+++/H9ZOgIhYTDg0NPSpvj7Ui7j48w0EAmGvjHg9iLUBtxsKhYK4uLgVCphTU1N0dnYyMTGx5pP9bhRRrntgYIAdO3aQmppKQkICPp9PysNPTk7S0dHBiRMnGB8fD2k3UbhzU52BY8eOcfHiRbq7u0lISCAvL4+vf/3ryGQyFhcXefnll7HZbIyNjfHiiy/i9XpXpBVuBdxuN0ePHiUlJeVTj6OMcOOIUr0ulwur1bpC1Eos7ryVnqsIEVabqKgoHn74YfLy8qTPHT16lB//+Me3nCMgcvjwYXp6eqQZGGJF/uTkJIODg/zLv/wLbW1tNDQ0RNaDj+Gm1wzMzc3R2NiIVqulsbGRjo4OZDIZy8vLDA4OsrS0JBXchfuJ7WosLS3x/vvvS4JD4drx8FnjVnyWIkRYK5KSkigoKGD37t2kpaVJzvTc3Bzz8/O37Pvj8XgYHR3l61//+gr9AI/Hw8LCAl1dXWHbbhhu3PRuAq/Xu2KCmSi0cLuwvLwcdqqIESJEiPBRiF03er2e+fl55ufnmZ2dZWJiApfLdctuln6/n7m5OX71q1+F2pRVxe1243A4GB4eZmZmZlUiOTLhOp+CD7c3hDMfdUm3y3XA7XMtt8t1wO1zLbfLdcDtcy03ch2XSyZf/n+JrZ83m8g9ubnI5XKpDuJyTYVPwsfek4gzEL5EXqjwI3JPwo/IPQk/Ivck/Pi4e7J2As0RIkSIECFChLDkuiMDESJEiBAhQoTbk0hkIEKECBEiRPiME3EGIkSIECFChM84EWcgQoQIESJE+IwTcQYiRIgQIUKEzzgRZyBChAgRIkT4jBNxBiJEiBAhQoTPOBFnIEKECBEiRPiME3EGIkSIECFChM84EWcgQoQIESJE+Izz/wHeDByvVtdoKAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9660; Run the following cell to gather the training and testing dataset.\n"
      ],
      "metadata": {
        "id": "SLbwp3V-vxg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = get_mnist_train_data()  # Get the training dataset\n",
        "x_test, y_test = get_mnist_test_data()     # Get the test dataset"
      ],
      "metadata": {
        "id": "ZY8RrHx4Fegk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9660; Run the following to normalize the input dataset to have a mean of 0 and standard deviation of 1."
      ],
      "metadata": {
        "id": "d4cTK2RDv5wL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_mean = x_train.mean()\n",
        "x_std = x_train.std()\n",
        "\n",
        "x_train = (x_train - x_mean)/(x_std)\n",
        "x_test = (x_test - x_mean)/(x_std)"
      ],
      "metadata": {
        "id": "n7RKsVNmfTx7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9660; Run the following cell to check the dimensions of the data."
      ],
      "metadata": {
        "id": "LfRlRMS9PTZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N, dim = x_train.shape\n",
        "N_test, _ = x_test.shape\n",
        "print(f\"Number of training sample {N} with {dim} pixels per image\")\n",
        "print(f\"Number of training sample {N_test} with {dim} pixels per image\")"
      ],
      "metadata": {
        "id": "59jB-sjwQNVL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f80a93be-7a1a-41c0-f4e4-84f3ecb6d809"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sample 20000 with 784 pixels per image\n",
            "Number of training sample 10000 with 784 pixels per image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Put code in the following cell to split the `x_train` and `y_train` arrays to training and validations sets with an 80-20 split ratio. Place the split arrays in to the `DATA` dictionary. This dictionary will be used to feed data into the `Solver`."
      ],
      "metadata": {
        "id": "QEggmFxlkHYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform training and validation dataset splits\n",
        "\n",
        "# PUT YOUR CODE BELOW\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    x_train, y_train, test_size=0.8, random_state=42)\n",
        "\n",
        "DATA = {\"X_train\": X_train,      # Replace with the value here\n",
        "        \"X_val\" : X_val,       # Replace with the value here\n",
        "        \"Y_train\" : y_train,     # Replace with the value here\n",
        "        \"Y_val\" : y_val}       # Replace with the value here\n"
      ],
      "metadata": {
        "id": "-ZUHh5UJkHYV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Implement and Evaluate ML Models\n",
        "\n",
        "We will follow a common organization for our code implementation.\n",
        "The `Solver` class is used to orchestrate the\n",
        "overall training steps,\n",
        "such as loading the data,\n",
        "doing the forward pass,\n",
        "computing the gradients with\n",
        "the backward pass,\n",
        "and updating the weights.\n",
        "The `Solver` class\n",
        "uses a *model*\n",
        "object which contains the actual weights,\n",
        "and implements the forward and backward passes.\n",
        "\n",
        "Note that we do not further randomize (shuffle) the datasets.\n",
        "We are pretty sure that they are already pre-shuffled."
      ],
      "metadata": {
        "id": "TDV7xaD_BkEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9660; Run the following cell to define the stochastic gradient descent algorithm that we will use to optimize our models."
      ],
      "metadata": {
        "id": "xXdYUcfTa78v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sgd(w, dw, lr=1e-2):\n",
        "    \"\"\"\n",
        "    Performs vanilla stochastic gradient descent.\n",
        "\n",
        "    config format:\n",
        "    - learning_rate: Scalar learning rate.\n",
        "    \"\"\"\n",
        "\n",
        "    w -= lr * dw\n",
        "    return w"
      ],
      "metadata": {
        "id": "elsI_qFOa8HB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9660; Run the following cell to define the `Solver` class."
      ],
      "metadata": {
        "id": "DyQdB2T4r9No"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Solver(object):\n",
        "    \"\"\"\n",
        "    Solver class for the learnable models using\n",
        "    mini-batch gradient descent.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 model,\n",
        "                 data,\n",
        "                 learning_rate=1e-3,\n",
        "                 num_epochs=50,\n",
        "                 batch_size=200,\n",
        "                 validation_frequency=16):\n",
        "        \"\"\"\n",
        "        Construct a new Solver instance.\n",
        "\n",
        "        Inputs:\n",
        "          model: Python class equiped with forward, backward, predict methods and a params dictionary\n",
        "          data: Dictionary with X_train, X_val,  Y_train, Y_val keys\n",
        "          learning_rate: Float, step size of the optimizer\n",
        "          num_epochs: Int, Number of times to completely traverse X_train\n",
        "          batch_size: Int, The number of samples in update\n",
        "          validation_frequency: Int, Solver performs validation loop every validation_frequency batches.\n",
        "                               Set this to a high number if num_epochs is large\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "\n",
        "        self.num_epochs = num_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.validation_frequency = validation_frequency\n",
        "\n",
        "        self.num_training = data[\"X_train\"].shape[0]\n",
        "        self.input_dim = data[\"X_train\"].shape[1]\n",
        "\n",
        "        # List of the index where each batch ends.\n",
        "        intervals = list(range(0, self.num_training, batch_size))[1:]\n",
        "\n",
        "        self.X_train = np.array_split(data[\"X_train\"], intervals, axis=0)\n",
        "        self.y_train = np.array_split(data[\"Y_train\"], intervals)\n",
        "\n",
        "        self.num_batches_in_training = len(self.X_train)\n",
        "\n",
        "        self.X_val = data[\"X_val\"]\n",
        "        self.y_val = data[\"Y_val\"]\n",
        "\n",
        "        self.update_rule = sgd\n",
        "        self.loss_history = []\n",
        "        self.validation_history = []\n",
        "\n",
        "        self.iteration_num = 0\n",
        "\n",
        "\n",
        "    def _step(self, batch_id):\n",
        "        \"\"\"\n",
        "        Make a single gradient update. This is called by train() and should not\n",
        "        be called manually.\n",
        "        \"\"\"\n",
        "        # Make a minibatch of training data\n",
        "        X_batch = self.X_train[batch_id]\n",
        "        y_batch = self.y_train[batch_id]\n",
        "\n",
        "        # Compute loss and gradient\n",
        "        score, cache = self.model.forward(X_batch)\n",
        "        loss, dL = self.model.loss(score, y_batch)\n",
        "        # dL is the upstream derivative to backward.\n",
        "        _, grads = self.model.backward(dL, cache)\n",
        "\n",
        "        self.loss_history.append(loss)\n",
        "\n",
        "        # Perform a parameter update\n",
        "        for p, w in self.model.params.items():\n",
        "            # print (p, w)\n",
        "            dw = grads[p]\n",
        "\n",
        "            next_w = self.update_rule(w, dw, self.learning_rate)\n",
        "            self.model.params[p] = next_w\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Optimization to train the model\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        for epoch in range(self.num_epochs):\n",
        "            for batch_id in range(self.num_batches_in_training):\n",
        "\n",
        "                self._step(batch_id)\n",
        "\n",
        "                self.iteration_num += 1\n",
        "\n",
        "                if (self.iteration_num % self.validation_frequency == 0):\n",
        "                    self.validate()\n",
        "\n",
        "        self.validate()\n",
        "\n",
        "\n",
        "    def validate(self):\n",
        "        \"\"\"\n",
        "        Checks the validation error of the model at the time it is being called.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        N = self.y_val.shape[0]\n",
        "        predictions = self.model.predict(self.X_val)\n",
        "\n",
        "        accuracy = np.count_nonzero(predictions == self.y_val.astype(int))\n",
        "\n",
        "        # added this line of code to append validation accuracies in\n",
        "        # validation_history\n",
        "        self.validation_history.append(accuracy)\n",
        "\n",
        "        print(f\"The validation accuracy at iteration {self.iteration_num}  is \\\n",
        "              {(float(accuracy)/N)*100}%\")"
      ],
      "metadata": {
        "id": "kQP6qra2bpOL"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will implement two different classifiers for the (MNIST) dataset.\n",
        "Each classifier will be a member of the implicit model\n",
        "class.\n",
        "(In this code we don't have an actual model class.)\n",
        "The models will both be linear,\n",
        "but will use different loss functions.\n",
        "The first will use the multiclass SVM loss,\n",
        "and the second will use the softmax  loss.\n",
        "\n",
        "The classifiers will be implemented using a common base class\n",
        "that implements training and prediction methods shared by the linear classifiers.\n",
        "Each of the two linear classifiers will be then derive\n",
        "from the base class,\n",
        "but override the loss function."
      ],
      "metadata": {
        "id": "vZfssCcKavEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658;\n",
        "In the following cell,\n",
        "complete the definition of the `LinearClassifier` class\n",
        "by implementing the `__init__()`, `forward()`, `backward()`, and `predict()` methods.\n",
        "\n",
        "- The `__init__()` method initializes the class. You must generate a random weight matrix of shape `(input_dim+1, num_classes)`  \n",
        "- The `forward()` method generates the scores for given an input sample, by applying a `linear_forward()` transformation on the inputs `x` and weights matrix `self.params['W1']`\n",
        "- The `backward()` method returns the gradients with respect to the inputs and weights, using the `linear_backward()` method.\n",
        "Make sure the key for the returned dictionary `weights_gradient` matches the `self.params` dictionary.\n",
        "- The `predict()` method returns the labels predicted from the scores returned using the `self.forward()` method."
      ],
      "metadata": {
        "id": "y4b6y_Oj1qr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearClassifier(object):\n",
        "    \"\"\"\n",
        "    The base class for the linear classifier.\n",
        "\n",
        "    Note that this class does not implement gradient descent; instead, it\n",
        "    is directed by a separate Solver object that is responsible for optimization.\n",
        "\n",
        "    The learnable parameters of the model are stored in the dictionary\n",
        "    self.params that maps parameter names to numpy arrays.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_dim=784,\n",
        "                 num_classes=10):\n",
        "        self.params = {}\n",
        "        self.input_features = input_dim\n",
        "        self.num_classes = 10\n",
        "\n",
        "        # PUT YOUR CODE BELOW:\n",
        "        # Initialize the weights of the linear classifier. Weights should be\n",
        "        # initialized from a Gaussian centered at 0.0 with standard deviation\n",
        "        # equal to 1e-3, and biases should be initialized to zero.\n",
        "        # Store in the self.params dictionary with key name 'W1'\n",
        "        weights = np.random.normal(0.0, 1e-3, (input_dim, num_classes))\n",
        "        biases = np.zeros((1, num_classes))\n",
        "        self.params[\"W1\"] = np.concatenate([weights, biases], axis=0)\n",
        "\n",
        "        # The lines below do not need to be changed in the method\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Train this linear classifier using stochastic gradient descent.\n",
        "\n",
        "        Inputs:\n",
        "        - x: A numpy array of shape (N, D) containing training data; there are N\n",
        "          training samples each of dimension D.\n",
        "\n",
        "        Outputs:\n",
        "        A list containing the value of the loss function at each training iteration.\n",
        "        \"\"\"\n",
        "        num_train, dim = x.shape\n",
        "        num_classes = self.num_classes\n",
        "        out = None\n",
        "        cache = None\n",
        "\n",
        "        # PUT YOUR CODE BELOW:\n",
        "        # Implement this method. Generate the scores in out and store the old\n",
        "        # values into the cache.\n",
        "\n",
        "        out, cache = linear_forward(x, self.params[\"W1\"])\n",
        "\n",
        "        # The lines below do not need to be changed\n",
        "\n",
        "\n",
        "        return out, cache\n",
        "\n",
        "    def backward(self, dout, cache):\n",
        "        weight_gradients = {}\n",
        "        dx = None\n",
        "\n",
        "        # PUT YOUR CODE BELOW:\n",
        "        # Implement this method. Generate the gradients with respect to x from\n",
        "        # cache and set it dx, the upstream error signal.\n",
        "        # Store the gradient with respect to the weights in the weights_gradients\n",
        "        # dictionary. Make sure the key matches the ket of the params dictionary\n",
        "        dx, dW = linear_backward(dout, cache)\n",
        "        weight_gradients[\"W1\"] = dW\n",
        "\n",
        "        # The lines below do not need to be changed\n",
        "\n",
        "        return (dx, weight_gradients)\n",
        "\n",
        "    def predict(self, x):\n",
        "        \"\"\"\n",
        "        Use the trained weights of this linear classifier to predict labels for\n",
        "        data points.\n",
        "\n",
        "        Inputs:\n",
        "        - x: A numpy array of shape (N, D) containing training data; there are N\n",
        "          training samples each of dimension D.\n",
        "\n",
        "        Returns:\n",
        "        - y_pred: Predicted labels for the data in X. y_pred is a 1-dimensional\n",
        "          array of length N, and each element is an integer giving the predicted\n",
        "          class.\n",
        "        \"\"\"\n",
        "        y_pred = np.zeros(x.shape[0])\n",
        "\n",
        "        # PUT YOUR CODE BELOW:\n",
        "        # Implement this method. Store the predicted labels in y_pred.\n",
        "        out, cache = self.forward(x)\n",
        "        for i in range(x.shape[0]):\n",
        "          y_pred[i] = np.argmax(out[i])\n",
        "\n",
        "        # The lines below do not need to be changed\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "    def loss(self, scores, y_batch):\n",
        "        \"\"\"\n",
        "        Compute the loss function and its derivative.\n",
        "        Subclasses will override this.\n",
        "\n",
        "        Inputs:\n",
        "        - scores: A numpy array of shape (N, C) containing a minibatch of N\n",
        "          data points; each point has dimension C, where C is the number of classes.\n",
        "        - y_batch: A numpy array of shape (N,) containing labels for the minibatch.\n",
        "        - reg: (float) regularization strength.\n",
        "\n",
        "        Returns: A tuple containing:\n",
        "        - loss as a single float\n",
        "        - gradient with respect to scores; an array of the same shape as scores\n",
        "        \"\"\"\n",
        "        # The lines below do not need to be changed\n",
        "        # Do not implement anything here. The subclasses will override this method\n",
        "        pass"
      ],
      "metadata": {
        "id": "oLgT_g66T71G"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.1 Support Vector Machine\n",
        "\n",
        "The `LinearSVM` class defines an SVM-based linear classifier.\n",
        "The classifier uses the multiclass hinge loss to optimize the model parameters.\n",
        "The multiclass hinge loss for an input sample $x$ (a vector) is given by:\n",
        "\n",
        "$$\n",
        "L = \\sum_{j \\neq y_i} \\text{max}(0, s_{ij}-s_{iy_i}+1)\n",
        "$$\n",
        "\n",
        "\n",
        "Where, $y_i$ is the label of the $i$-th sample.  The label is the correct class label where $0 \\leq y_i \\lt C$, where C is the number of classes. The scalar $s_{iy_i}$ is the $y_i$-th element of the $i$-th score vector. The loss over a set of samples is taken by simply averaging the losses of the samples.  \n",
        "\n",
        "\n",
        "The per-sample gradient of the loss w.r.t. the score $s_{ij}$ is given by:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial  L_i}{\\partial s_{ij}} = \\left \\{\n",
        "\\begin{array}{ll}\n",
        "0 & s_{ij}-s_{iy_i}+1 \\leq 0    \\\\\n",
        "1 & j \\neq s_{y_i} \\text{ and } s_{ij}-s_{iy_i}+1 > 0 \\\\\n",
        "-\\sum_{k \\neq j}\\frac{\\partial L_i}{\\partial s_{ik}} & j = s_{y_i}\n",
        "\\end{array}\n",
        "\\right.\n",
        "$$\n",
        "\n",
        "\n",
        "**Implement** the `svm_loss` function in the following cell. Store the average loss the `loss` variable and the gradient w.r.t `scores` in the `dy` variable. This is the loss over multiple samples, therefor you should take the mean of the loss.\n"
      ],
      "metadata": {
        "id": "rS6qcaqUcyqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement the `svm_loss(scores, y_batch)` function in the following cell.\n",
        "Store the average loss the `loss` variable and the gradient w.r.t `scores` in the `dy` variable.\n",
        "This is the loss over multiple samples, therefore you should take the mean of the loss."
      ],
      "metadata": {
        "id": "fVJxsGOYTgxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def svm_loss(scores, y_batch):\n",
        "    \"\"\"\n",
        "    Returns hinge loss of the scores and y_batch.\n",
        "\n",
        "    Inputs:\n",
        "    - scores: A numpy array of shape (N, C) containing a minibatch of N\n",
        "      data points; each point has dimension C, where C is the number of classes.\n",
        "    - y_batch: A numpy array of shape (N,) containing labels for the minibatch.\n",
        "    - reg: (float) regularization strength.\n",
        "\n",
        "    Returns: A tuple containing:\n",
        "    - loss as a single float\n",
        "    - gradient with respect to scores; an array of the same shape as scores\n",
        "    \"\"\"\n",
        "    loss = 0\n",
        "    dy = np.zeros(scores.shape)\n",
        "    # PUT YOUR CODE BELOW:\n",
        "    # Implement the structured SVM loss, storing the\n",
        "    # result in loss. Make sure to take the mean of the loss.\n",
        "    # Hint: The intermediate results  maybe useful for the gradient calculation\n",
        "    temp = np.zeros_like(y_batch)\n",
        "    diff = np.zeros_like(scores)\n",
        "    for i in range(temp.shape[0]):\n",
        "      for j in range(scores.shape[1]):\n",
        "        diff[i][j] = scores[i][j] - scores[i][y_batch[i]] + 1\n",
        "        if diff[i][j] <= 0:\n",
        "          dy[i][j] += 0\n",
        "\n",
        "        if y_batch[i] != j:\n",
        "          temp[i] += max(0, diff[i][j])\n",
        "\n",
        "          if diff[i][j] > 0:\n",
        "            dy[i][j] += 1\n",
        "\n",
        "        elif y_batch[i] == j:\n",
        "          dy[i][j] -= np.sum(scores[i] > 0)\n",
        "\n",
        "\n",
        "    loss = sum(temp) / len(temp)\n",
        "\n",
        "\n",
        "    # PUT YOUR CODE BELOW:\n",
        "    # Implement the gradient for the SVM loss, storing the result\n",
        "    # in dy.\n",
        "    #\n",
        "    # Hint: Instead of computing the gradient from scratch, it may be easier\n",
        "    # to reuse some of the intermediate values that you used to compute the\n",
        "    # loss.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # The lines below do not need to be changed.\n",
        "    return loss, dy"
      ],
      "metadata": {
        "id": "S-_mC08N89UC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9660; Run the following cell to define the `LinearSVM` class with your implementation of the `svm_loss`"
      ],
      "metadata": {
        "id": "MMaObHBhamT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearSVM(LinearClassifier):\n",
        "    \"\"\" A subclass that uses the Multiclass SVM loss function \"\"\"\n",
        "\n",
        "    def loss(self, scores, y_batch):\n",
        "        return svm_loss(scores, y_batch)"
      ],
      "metadata": {
        "id": "VD43ltPTcw-B"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.1.1 SVM Experiments\n",
        "\n",
        "In the next few cells run the `Solver` with SVM models on the training and validation data you've defined previously. Use the `DATA` dictionary you defined previously as the data parameter.\n",
        "\n",
        "As you have seen with previous assignments, optimizations can be highly dependent on the hyperparameters of the model. You should try multiple models with different learning rates. You may also increase the amount of time you train by increasing the number of epochs.\n",
        "\n",
        "Keep the top 5 best performing models and the worst performing model on the validation set."
      ],
      "metadata": {
        "id": "DNPZ7RoU2Oyv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement hyperparameter validation loop in the next cell to train multiple models with different hyperparameters.\n",
        "Keep the top 5 best performing models on the validation set.\n",
        "You can try different learning rates.\n",
        "You may change the num_epochs, but be wary of timeouts."
      ],
      "metadata": {
        "id": "DD7et1xEF9h6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_models = 10\n",
        "model_accuracies = []\n",
        "models = []\n",
        "\n",
        "lr = 0.001\n",
        "num_epochs = 50\n",
        "for i in range(num_models):\n",
        "  lin_cls = LinearSVM()\n",
        "  solver_obj = Solver(lin_cls, DATA, learning_rate=lr, num_epochs=num_epochs)\n",
        "  solver_obj.train()\n",
        "\n",
        "  model_accuracies.append(solver_obj.validation_history[-1])\n",
        "  models.append(solver_obj)\n",
        "\n",
        "  top_5_model = models[np.argsort(model_accuracies).reverse()[:5]]\n"
      ],
      "metadata": {
        "id": "US364cOjGC5p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1d740ce9-be98-41ca-ae6a-54c1318caf3f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The validation accuracy at iteration 16  is               68.6875%\n",
            "The validation accuracy at iteration 32  is               60.4375%\n",
            "The validation accuracy at iteration 48  is               43.15%\n",
            "The validation accuracy at iteration 64  is               56.99375%\n",
            "The validation accuracy at iteration 80  is               45.75625%\n",
            "The validation accuracy at iteration 96  is               41.675000000000004%\n",
            "The validation accuracy at iteration 112  is               71.28125%\n",
            "The validation accuracy at iteration 128  is               66.14999999999999%\n",
            "The validation accuracy at iteration 144  is               45.49375%\n",
            "The validation accuracy at iteration 160  is               69.94375000000001%\n",
            "The validation accuracy at iteration 176  is               48.3125%\n",
            "The validation accuracy at iteration 192  is               44.043749999999996%\n",
            "The validation accuracy at iteration 208  is               49.9375%\n",
            "The validation accuracy at iteration 224  is               45.043749999999996%\n",
            "The validation accuracy at iteration 240  is               51.43124999999999%\n",
            "The validation accuracy at iteration 256  is               61.61875%\n",
            "The validation accuracy at iteration 272  is               48.375%\n",
            "The validation accuracy at iteration 288  is               52.168749999999996%\n",
            "The validation accuracy at iteration 304  is               66.64999999999999%\n",
            "The validation accuracy at iteration 320  is               72.89999999999999%\n",
            "The validation accuracy at iteration 336  is               47.15%\n",
            "The validation accuracy at iteration 352  is               49.475%\n",
            "The validation accuracy at iteration 368  is               46.550000000000004%\n",
            "The validation accuracy at iteration 384  is               70.45625%\n",
            "The validation accuracy at iteration 400  is               73.38125%\n",
            "The validation accuracy at iteration 416  is               51.3625%\n",
            "The validation accuracy at iteration 432  is               61.662499999999994%\n",
            "The validation accuracy at iteration 448  is               53.5625%\n",
            "The validation accuracy at iteration 464  is               43.925%\n",
            "The validation accuracy at iteration 480  is               65.77499999999999%\n",
            "The validation accuracy at iteration 496  is               64.59375%\n",
            "The validation accuracy at iteration 512  is               55.643750000000004%\n",
            "The validation accuracy at iteration 528  is               73.36875%\n",
            "The validation accuracy at iteration 544  is               59.2875%\n",
            "The validation accuracy at iteration 560  is               42.50625%\n",
            "The validation accuracy at iteration 576  is               62.5625%\n",
            "The validation accuracy at iteration 592  is               48.493750000000006%\n",
            "The validation accuracy at iteration 608  is               42.662499999999994%\n",
            "The validation accuracy at iteration 624  is               52.275000000000006%\n",
            "The validation accuracy at iteration 640  is               34.86875%\n",
            "The validation accuracy at iteration 656  is               67.2625%\n",
            "The validation accuracy at iteration 672  is               60.931250000000006%\n",
            "The validation accuracy at iteration 688  is               45.7625%\n",
            "The validation accuracy at iteration 704  is               60.12499999999999%\n",
            "The validation accuracy at iteration 720  is               72.61875%\n",
            "The validation accuracy at iteration 736  is               49.3125%\n",
            "The validation accuracy at iteration 752  is               67.1375%\n",
            "The validation accuracy at iteration 768  is               59.275%\n",
            "The validation accuracy at iteration 784  is               53.293749999999996%\n",
            "The validation accuracy at iteration 800  is               47.475%\n",
            "The validation accuracy at iteration 816  is               63.275000000000006%\n",
            "The validation accuracy at iteration 832  is               44.768750000000004%\n",
            "The validation accuracy at iteration 848  is               47.54375%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-c71904074ade>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mlin_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0msolver_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlin_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0msolver_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mmodel_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-8bef3a3aa6e9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_in_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-8bef3a3aa6e9>\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, batch_id)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# Compute loss and gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;31m# dL is the upstream derivative to backward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-536ed25a63be>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, scores, y_batch)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msvm_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-4a0b5bb93c90>\u001b[0m in \u001b[0;36msvm_loss\u001b[0;34m(scores, y_batch)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m           \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement the testing performance of your top 5 performing models on the test set and print the results."
      ],
      "metadata": {
        "id": "Dl4R1tyz4VpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model in top_5_model:\n",
        "  for i in range(len(x_test)):\n",
        "    test_img = x_test[i]\n",
        "    y_pred = model.predict([test_img])\n"
      ],
      "metadata": {
        "id": "71qBuIr75ArL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement the next cell to visualize the weights corresponding to each sample in the *best* performing SVM models. You should have ten 28x28 images.\n",
        "\n",
        "Make sure to rescale the  weights to be between 0 and 255.\n",
        "\n",
        "Depending on your learning rate and weights, it might not look so great. If all the images look the same but you have good accuracy, try subtracting the average of weights from weights of each class.\n",
        "\n",
        "You can add additional cells below."
      ],
      "metadata": {
        "id": "srNp8XPEbVAt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hVDxnLZCbVQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.2 Cross-Entropy Loss\n",
        "\n",
        "The `CrossEntropy` class defines the cross-entropy loss for training and prediction methods like the previous the linear classifiers.\n",
        "Because the cross-entropy is defined on probability distributions,\n",
        "the softmax function is usually applied to the output of a linear\n",
        "classifier to transform the raw scores into values that can be interpreted as probabilities.\n",
        "(Though, be cautious about actually using them as such.)\n",
        "However,\n",
        "we commonly refer to it just as the cross-entropy loss,\n",
        "with the implicit understanding that for deep learning,\n",
        "the cross-entropy is not computed on the raw scores,\n",
        "but rather the softmax of the raw scores.\n",
        "\n",
        "For a score vector $s$, the softmax activation of the $j$-th element is given by,\n",
        "\n",
        "$$\n",
        "\\sigma_j = \\frac{e^{s_{j}}}{\\sum^{M}_{k=1}e^{s_k}}\n",
        "$$\n",
        "\n",
        "A simple implementation of the softmax function can result in overflow.\n",
        "See\n",
        "[here](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/#:~:text=Computing%20softmax%20and%20numerical%20stability)\n",
        "for how to avoid this problem.\n",
        "\n",
        "The cross-entropy is a measure of the difference between two probability distributions.\n",
        "In the general case,\n",
        "the cross-entropy $H$ between the true probability distribution $P$ and the estimated probability distribution $Q$ is given by:\n",
        "\n",
        "$$\n",
        "H(P, Q)=-\\sum_{x \\in \\mathcal{X}} P(x) \\log Q(x)\n",
        "$$\n",
        "\n",
        "where $\\mathcal{X}$ is the event space.\n",
        "It is a measure of how \"far off\" our estimated distribution $Q$ is from $P$.\n",
        "(Note that because $P$ and $Q$ are actually functions,\n",
        "$H$ in this case is a function operating on functions, also known as an *operator*.)\n",
        "\n",
        "In our case,\n",
        "$P$ is zero except for the correct label,\n",
        "and thus the cross-entropy reduces to simply the negative logarithm of the score corresponding to the correct class,\n",
        "which is just\n",
        "\n",
        "$$\n",
        "L_i = -\\log(\\sigma_{y_i}))\n",
        "$$\n",
        "\n",
        "where $y_i$ is the correct label of the $x_i$ input sample,\n",
        "and $\\sigma_{y_i}$ is the softmax output of the corresponding correct label. $L$ is then just the average over the $L_i$.\n",
        "\n",
        "The derivative of the softmax is given by\n",
        "\n",
        "$$\n",
        "\\frac{\\partial\\sigma_i}{\\partial s_j} = \\left \\{\n",
        "\\begin{array}{ll}\n",
        "\\sigma_i(1 - \\sigma_{j}) & i = j     \\\\\n",
        "-\\sigma_i\\sigma_j & i \\neq j  \\\\\n",
        "\\end{array}\n",
        "\\right. .\n",
        "$$\n",
        "\n",
        "Details on the derivation can be found [here](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/).\n",
        "\n",
        "The derivative of the negative logarithm is given by\n",
        "\n",
        "$$\n",
        "\\frac{\\partial (-\\log)}{\\partial \\sigma_{y_i}} = -\\frac{1}{\\sigma_{y_i}}.\n",
        "$$"
      ],
      "metadata": {
        "id": "nhA92akOczjV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VUIJTZq3Qge_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement the `cross_entropy_loss(scores, y_batch)` function in the following cell,\n",
        "consisting of the softmax followed by cross-entropy,\n",
        "as explained above.\n",
        "The function returns a tuple of `(loss, dy)` where\n",
        "`loss` is the cross-entropy loss based on the inputs\n",
        "and `dy` is the gradient of the loss with respect to the `scores` input.\n",
        "This is the loss over multiple samples,\n",
        "therefore you should take the mean of the loss."
      ],
      "metadata": {
        "id": "XJDqbXH4yxZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_loss(scores, y_batch):\n",
        "    \"\"\"\n",
        "    Computes the cross-entropy layer\n",
        "\n",
        "    Inputs:\n",
        "    - scores: A numpy array containing the scores, of shape (N, C)\n",
        "    - y_batch: A numpy array containing the labels, of shape (N, 1)\n",
        "\n",
        "    Returns: A tuple containing:\n",
        "    - loss as a single float\n",
        "    - gradient with respect to scores; an array of the same shape as scores\n",
        "    \"\"\"\n",
        "\n",
        "    loss = 0\n",
        "    dy = np.zeros(scores.shape)\n",
        "\n",
        "    # PUT YOUR CODE BELOW:\n",
        "    # Implement the cross-entropy loss, storing the\n",
        "    # result in loss. Make sure to take the mean of the loss.\n",
        "    # Hint: The intermediate results maybe useful for the gradient calculation\n",
        "    def stablesoftmax(x):\n",
        "      \"\"\"Compute the softmax of vector x in a numerically stable way.\"\"\"\n",
        "      shiftx = x - np.max(x)\n",
        "      exps = np.exp(shiftx)\n",
        "      return exps / np.sum(exps)\n",
        "\n",
        "    softmax_res = np.zeros_like(scores)\n",
        "    for i in range(scores.shape[0]):\n",
        "      softmax_res[i] = stablesoftmax(scores[i])\n",
        "      loss += np.log(softmax_res[i][y_batch[i]])*(-1)\n",
        "\n",
        "    loss = loss/scores.shape[0]\n",
        "\n",
        "    # PUT YOUR CODE BELOW:\n",
        "    # Implement the gradient for the cross-entropy loss, storing the result\n",
        "    # in dy.\n",
        "    #\n",
        "    # Hint: Instead of computing the gradient from scratch, it may be easier\n",
        "    # to reuse some of the intermediate values that you used to compute the\n",
        "    # loss.\n",
        "\n",
        "    for i in range(scores.shape[0]):\n",
        "      for j in range(scores.shape[1]):\n",
        "        if i!=j:\n",
        "          dy[i][j] = (-1)/(softmax_res[i][j] - softmax_res[i][j]*softmax_res[i])[y_batch[i]]\n",
        "        else:\n",
        "          dy[i][j] = (-1)/((-1)*softmax_res[i][j])\n",
        "\n",
        "\n",
        "    # The lines below do not need to be changed.\n",
        "    return loss, dy"
      ],
      "metadata": {
        "id": "5hIEv5fl9llO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9660;\n",
        "Run the following cell to define the `CrossEntropy` classifier class."
      ],
      "metadata": {
        "id": "8h0EQF-yuu8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossEntropy(LinearClassifier):\n",
        "    \"\"\" A subclass that uses the Softmax + Cross-entropy loss function \"\"\"\n",
        "\n",
        "    def loss(self, scores, y_batch):\n",
        "        return cross_entropy_loss(scores, y_batch)"
      ],
      "metadata": {
        "id": "RKYgCIcHczy1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.2.1 Cross-Entropy Experiments\n",
        "\n",
        "In the next few cells run the `Solver` with softmax models on the training and validation data you've defined previously,\n",
        "similarly to the SVM experiments.\n",
        "Use the `DATA` dictionary you defined previously as the data parameter.\n",
        "\n",
        "Keep the top 5 best performing models and the worst performing model on the validation set."
      ],
      "metadata": {
        "id": "Ug02WvIg5DT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement the hyperparameter validation loop in the next cell to train multiple models with different hyperparameters.\n",
        "Keep the top 5 best performing models on the validation set.\n",
        "You can try different learning rates.\n",
        "You may change the number of epochs, but be wary of timeouts."
      ],
      "metadata": {
        "id": "qRFvUnysFwvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_models = 10\n",
        "model_accuracies = []\n",
        "models = []\n",
        "\n",
        "lr = 0.0001\n",
        "num_epochs = 100\n",
        "for i in range(num_models):\n",
        "  ce_model = CrossEntropy()\n",
        "  solver_obj = Solver(ce_model, DATA, learning_rate=lr, num_epochs=num_epochs)\n",
        "  solver_obj.train()\n",
        "\n",
        "  model_accuracies.append(solver_obj.validation_history[-1])\n",
        "  models.append(solver_obj)"
      ],
      "metadata": {
        "id": "05Od5fTg5Dqz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "68a4e9a6-f5f6-4964-de7e-0dbf15001667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The validation accuracy at iteration 16  is               10.53125%\n",
            "The validation accuracy at iteration 32  is               10.337499999999999%\n",
            "The validation accuracy at iteration 48  is               10.68125%\n",
            "The validation accuracy at iteration 64  is               10.56875%\n",
            "The validation accuracy at iteration 80  is               10.44375%\n",
            "The validation accuracy at iteration 96  is               10.543750000000001%\n",
            "The validation accuracy at iteration 112  is               10.481250000000001%\n",
            "The validation accuracy at iteration 128  is               10.45%\n",
            "The validation accuracy at iteration 144  is               10.50625%\n",
            "The validation accuracy at iteration 160  is               10.13125%\n",
            "The validation accuracy at iteration 176  is               10.19375%\n",
            "The validation accuracy at iteration 192  is               10.15625%\n",
            "The validation accuracy at iteration 208  is               10.18125%\n",
            "The validation accuracy at iteration 224  is               10.33125%\n",
            "The validation accuracy at iteration 240  is               10.08125%\n",
            "The validation accuracy at iteration 256  is               10.30625%\n",
            "The validation accuracy at iteration 272  is               10.1125%\n",
            "The validation accuracy at iteration 288  is               10.125%\n",
            "The validation accuracy at iteration 304  is               10.25625%\n",
            "The validation accuracy at iteration 320  is               10.037500000000001%\n",
            "The validation accuracy at iteration 336  is               10.237499999999999%\n",
            "The validation accuracy at iteration 352  is               10.075000000000001%\n",
            "The validation accuracy at iteration 368  is               10.15625%\n",
            "The validation accuracy at iteration 384  is               10.29375%\n",
            "The validation accuracy at iteration 400  is               10.15625%\n",
            "The validation accuracy at iteration 416  is               10.1875%\n",
            "The validation accuracy at iteration 432  is               10.0875%\n",
            "The validation accuracy at iteration 448  is               10.237499999999999%\n",
            "The validation accuracy at iteration 464  is               10.39375%\n",
            "The validation accuracy at iteration 480  is               10.2875%\n",
            "The validation accuracy at iteration 496  is               10.29375%\n",
            "The validation accuracy at iteration 512  is               10.0875%\n",
            "The validation accuracy at iteration 528  is               10.2%\n",
            "The validation accuracy at iteration 544  is               10.40625%\n",
            "The validation accuracy at iteration 560  is               10.174999999999999%\n",
            "The validation accuracy at iteration 576  is               10.2875%\n",
            "The validation accuracy at iteration 592  is               10.10625%\n",
            "The validation accuracy at iteration 608  is               10.10625%\n",
            "The validation accuracy at iteration 624  is               10.1875%\n",
            "The validation accuracy at iteration 640  is               10.125%\n",
            "The validation accuracy at iteration 656  is               10.1875%\n",
            "The validation accuracy at iteration 672  is               10.0%\n",
            "The validation accuracy at iteration 688  is               10.15%\n",
            "The validation accuracy at iteration 704  is               10.137500000000001%\n",
            "The validation accuracy at iteration 720  is               10.09375%\n",
            "The validation accuracy at iteration 736  is               10.14375%\n",
            "The validation accuracy at iteration 752  is               9.98125%\n",
            "The validation accuracy at iteration 768  is               10.05%\n",
            "The validation accuracy at iteration 784  is               10.21875%\n",
            "The validation accuracy at iteration 800  is               10.03125%\n",
            "The validation accuracy at iteration 816  is               10.15%\n",
            "The validation accuracy at iteration 832  is               9.93125%\n",
            "The validation accuracy at iteration 848  is               9.95625%\n",
            "The validation accuracy at iteration 864  is               10.1625%\n",
            "The validation accuracy at iteration 880  is               10.01875%\n",
            "The validation accuracy at iteration 896  is               10.100000000000001%\n",
            "The validation accuracy at iteration 912  is               9.91875%\n",
            "The validation accuracy at iteration 928  is               9.90625%\n",
            "The validation accuracy at iteration 944  is               10.20625%\n",
            "The validation accuracy at iteration 960  is               10.06875%\n",
            "The validation accuracy at iteration 976  is               10.13125%\n",
            "The validation accuracy at iteration 992  is               9.9125%\n",
            "The validation accuracy at iteration 1008  is               9.85%\n",
            "The validation accuracy at iteration 1024  is               10.174999999999999%\n",
            "The validation accuracy at iteration 1040  is               10.0625%\n",
            "The validation accuracy at iteration 1056  is               10.06875%\n",
            "The validation accuracy at iteration 1072  is               9.99375%\n",
            "The validation accuracy at iteration 1088  is               9.9%\n",
            "The validation accuracy at iteration 1104  is               10.10625%\n",
            "The validation accuracy at iteration 1120  is               10.08125%\n",
            "The validation accuracy at iteration 1136  is               10.1625%\n",
            "The validation accuracy at iteration 1152  is               9.93125%\n",
            "The validation accuracy at iteration 1168  is               9.8625%\n",
            "The validation accuracy at iteration 1184  is               10.10625%\n",
            "The validation accuracy at iteration 1200  is               10.100000000000001%\n",
            "The validation accuracy at iteration 1216  is               10.19375%\n",
            "The validation accuracy at iteration 1232  is               9.95625%\n",
            "The validation accuracy at iteration 1248  is               9.88125%\n",
            "The validation accuracy at iteration 1264  is               10.14375%\n",
            "The validation accuracy at iteration 1280  is               10.06875%\n",
            "The validation accuracy at iteration 1296  is               10.16875%\n",
            "The validation accuracy at iteration 1312  is               9.93125%\n",
            "The validation accuracy at iteration 1328  is               9.88125%\n",
            "The validation accuracy at iteration 1344  is               10.174999999999999%\n",
            "The validation accuracy at iteration 1360  is               10.100000000000001%\n",
            "The validation accuracy at iteration 1376  is               10.037500000000001%\n",
            "The validation accuracy at iteration 1392  is               9.86875%\n",
            "The validation accuracy at iteration 1408  is               9.975000000000001%\n",
            "The validation accuracy at iteration 1424  is               10.19375%\n",
            "The validation accuracy at iteration 1440  is               10.11875%\n",
            "The validation accuracy at iteration 1456  is               10.16875%\n",
            "The validation accuracy at iteration 1472  is               9.85625%\n",
            "The validation accuracy at iteration 1488  is               9.975000000000001%\n",
            "The validation accuracy at iteration 1504  is               10.212499999999999%\n",
            "The validation accuracy at iteration 1520  is               10.2%\n",
            "The validation accuracy at iteration 1536  is               10.1875%\n",
            "The validation accuracy at iteration 1552  is               9.9625%\n",
            "The validation accuracy at iteration 1568  is               9.99375%\n",
            "The validation accuracy at iteration 1584  is               10.3125%\n",
            "The validation accuracy at iteration 1600  is               10.237499999999999%\n",
            "The validation accuracy at iteration 1616  is               10.274999999999999%\n",
            "The validation accuracy at iteration 1632  is               10.01875%\n",
            "The validation accuracy at iteration 1648  is               10.012500000000001%\n",
            "The validation accuracy at iteration 1664  is               10.299999999999999%\n",
            "The validation accuracy at iteration 1680  is               10.2625%\n",
            "The validation accuracy at iteration 1696  is               10.225%\n",
            "The validation accuracy at iteration 1712  is               10.04375%\n",
            "The validation accuracy at iteration 1728  is               10.00625%\n",
            "The validation accuracy at iteration 1744  is               10.299999999999999%\n",
            "The validation accuracy at iteration 1760  is               10.25625%\n",
            "The validation accuracy at iteration 1776  is               10.362499999999999%\n",
            "The validation accuracy at iteration 1792  is               10.08125%\n",
            "The validation accuracy at iteration 1808  is               10.0%\n",
            "The validation accuracy at iteration 1824  is               10.30625%\n",
            "The validation accuracy at iteration 1840  is               10.2625%\n",
            "The validation accuracy at iteration 1856  is               10.35625%\n",
            "The validation accuracy at iteration 1872  is               10.0875%\n",
            "The validation accuracy at iteration 1888  is               9.975000000000001%\n",
            "The validation accuracy at iteration 1904  is               10.23125%\n",
            "The validation accuracy at iteration 1920  is               10.18125%\n",
            "The validation accuracy at iteration 1936  is               10.31875%\n",
            "The validation accuracy at iteration 1952  is               10.0625%\n",
            "The validation accuracy at iteration 1968  is               9.975000000000001%\n",
            "The validation accuracy at iteration 1984  is               10.14375%\n",
            "The validation accuracy at iteration 2000  is               10.23125%\n",
            "The validation accuracy at iteration 2000  is               10.23125%\n",
            "The validation accuracy at iteration 16  is               12.61875%\n",
            "The validation accuracy at iteration 32  is               12.71875%\n",
            "The validation accuracy at iteration 48  is               12.562499999999998%\n",
            "The validation accuracy at iteration 64  is               12.525%\n",
            "The validation accuracy at iteration 80  is               12.525%\n",
            "The validation accuracy at iteration 96  is               12.14375%\n",
            "The validation accuracy at iteration 112  is               11.96875%\n",
            "The validation accuracy at iteration 128  is               11.7875%\n",
            "The validation accuracy at iteration 144  is               11.837499999999999%\n",
            "The validation accuracy at iteration 160  is               11.61875%\n",
            "The validation accuracy at iteration 176  is               11.43125%\n",
            "The validation accuracy at iteration 192  is               11.537500000000001%\n",
            "The validation accuracy at iteration 208  is               11.375%\n",
            "The validation accuracy at iteration 224  is               11.44375%\n",
            "The validation accuracy at iteration 240  is               11.2875%\n",
            "The validation accuracy at iteration 256  is               11.18125%\n",
            "The validation accuracy at iteration 272  is               11.15625%\n",
            "The validation accuracy at iteration 288  is               11.10625%\n",
            "The validation accuracy at iteration 304  is               11.25%\n",
            "The validation accuracy at iteration 320  is               11.075%\n",
            "The validation accuracy at iteration 336  is               11.1375%\n",
            "The validation accuracy at iteration 352  is               11.06875%\n",
            "The validation accuracy at iteration 368  is               10.975%\n",
            "The validation accuracy at iteration 384  is               11.118749999999999%\n",
            "The validation accuracy at iteration 400  is               11.04375%\n",
            "The validation accuracy at iteration 416  is               10.925%\n",
            "The validation accuracy at iteration 432  is               10.95%\n",
            "The validation accuracy at iteration 448  is               10.84375%\n",
            "The validation accuracy at iteration 464  is               10.925%\n",
            "The validation accuracy at iteration 480  is               10.881250000000001%\n",
            "The validation accuracy at iteration 496  is               10.85%\n",
            "The validation accuracy at iteration 512  is               10.825%\n",
            "The validation accuracy at iteration 528  is               10.725%\n",
            "The validation accuracy at iteration 544  is               10.75%\n",
            "The validation accuracy at iteration 560  is               10.756250000000001%\n",
            "The validation accuracy at iteration 576  is               10.64375%\n",
            "The validation accuracy at iteration 592  is               10.63125%\n",
            "The validation accuracy at iteration 608  is               10.475%\n",
            "The validation accuracy at iteration 624  is               10.58125%\n",
            "The validation accuracy at iteration 640  is               10.6625%\n",
            "The validation accuracy at iteration 656  is               10.543750000000001%\n",
            "The validation accuracy at iteration 672  is               10.44375%\n",
            "The validation accuracy at iteration 688  is               10.4%\n",
            "The validation accuracy at iteration 704  is               10.44375%\n",
            "The validation accuracy at iteration 720  is               10.56875%\n",
            "The validation accuracy at iteration 736  is               10.4%\n",
            "The validation accuracy at iteration 752  is               10.4125%\n",
            "The validation accuracy at iteration 768  is               10.23125%\n",
            "The validation accuracy at iteration 784  is               10.39375%\n",
            "The validation accuracy at iteration 800  is               10.43125%\n",
            "The validation accuracy at iteration 816  is               10.3875%\n",
            "The validation accuracy at iteration 832  is               10.36875%\n",
            "The validation accuracy at iteration 848  is               10.21875%\n",
            "The validation accuracy at iteration 864  is               10.362499999999999%\n",
            "The validation accuracy at iteration 880  is               10.375%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-7adb6e87102e>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mce_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0msolver_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mce_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0msolver_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mmodel_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-821aced95869>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration_num\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_frequency\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-821aced95869>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-7a3b75d17924>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# PUT YOUR CODE BELOW:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# Implement this method. Store the predicted labels in y_pred.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m           \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-7a3b75d17924>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# values into the cache.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# The lines below do not need to be changed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-f80b5bada23c>\u001b[0m in \u001b[0;36mlinear_forward\u001b[0;34m(X, W)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mbias_trick_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_trick_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement the next cell to visualize the weights corresponding to each sample in the *best* performing softmax models.\n",
        "You should have ten 28x28 images.\n",
        "\n",
        "You can add additional cells below.\n",
        "\n",
        "Depending on your learning rate and weights, it might not look so great. If all the images look the same but you have good accuracy, try subtracting the average of weights from weights of each class."
      ],
      "metadata": {
        "id": "s8j9KoxfXgY5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0SEDP9m-EZNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement the testing performance of your top 5 performing softmax models on the test set and print the results."
      ],
      "metadata": {
        "id": "4GdpbgYg5D8W"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oxuJHeU45EVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Deeper Neural Networks (Very Slightly)"
      ],
      "metadata": {
        "id": "A7mX-suZStG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Up to now, we have been working with linear classification models.\n",
        "Linear classification models are very adept at modelling data that have nice linear boundaries.\n",
        "In practice, real world data is rarely linear.\n",
        "Multilayer, fully-connected neural networks with non-linear activation functions on the other hand can model non-linear data-label relationships.\n",
        "Such models are a powerful extension to linear models and are the building blocks of modern deep learning.\n",
        "\n",
        "In this section,\n",
        "you will be implementing a two-layer, fully-connected neural network.\n",
        "You will also implement your own version of the rectified linear unit fuction (commonly referred to as ReLU),\n",
        "a non-linear activation function."
      ],
      "metadata": {
        "id": "j60wKxwhXu2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 ReLU Function\n",
        "\n",
        "The ReLU function is given by:\n",
        "\n",
        "$$\n",
        "f(x) = \\max(0, x)\n",
        "$$"
      ],
      "metadata": {
        "id": "gP_YgE1JWj1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement the following cell to complete the definition of the `ReLU_forward` function."
      ],
      "metadata": {
        "id": "SF20M-YOWSdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ReLU_forward(x):\n",
        "    \"\"\"\n",
        "    Computes the forward pass for a ReLU actiivation.\n",
        "\n",
        "    The input x has shape (N, D) and contains a minibatch of N\n",
        "    examples, where each sample x[i] has shape (D).  (For generality, D here does\n",
        "    not mean the number of features, but is just some arbitrary constant.)\n",
        "    This function will then just evalute the ReLU() function for each\n",
        "    element.  The output will thus again be a matrix of shape (N, D).\n",
        "\n",
        "    Inputs:\n",
        "    - x: A numpy array containing input data, of shape (N, D)\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - out: output, of shape (N, D)\n",
        "    - cache: (x)\n",
        "    \"\"\"\n",
        "    out = None\n",
        "\n",
        "    # PUT YOUR CODE BELOW: Implement the ReLU forward pass. Store the result in\n",
        "    # out. You will need to reshape the input into rows.\n",
        "    out = np.zeros_like(x)\n",
        "    for i in range(x.shape[0]):\n",
        "      for j in range(x.shape[1]):\n",
        "        if x[i][j] > 0:\n",
        "          out[i][j] = x[i][j]\n",
        "        else:\n",
        "          out[i][j] = 0\n",
        "\n",
        "\n",
        "    # The lines below do not need to be changed.\n",
        "\n",
        "    cache = (x,)\n",
        "    return out, cache"
      ],
      "metadata": {
        "id": "tQ-CcTqJStgz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The derivative of the ReLU function is given by:\n",
        "\n",
        "$$\n",
        "\\frac{d \\mathrm{ReLU}(x)}{dx} = \\left\\{\n",
        "\\begin{array}{ll}\n",
        "      0 & x \\leq 0 \\\\\n",
        "      1 & x > 0 \\\\\n",
        "\\end{array}\n",
        "\\right.\n",
        "$$"
      ],
      "metadata": {
        "id": "g3LU7V4Ib4xj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement the following cell to complete the definition of the `ReLU_backward(d_upstream, cache)` function."
      ],
      "metadata": {
        "id": "ScME_zhFWXsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ReLU_backward(d_upstream, cache):\n",
        "    \"\"\"\n",
        "    Computes the backward pass for an linear layer.\n",
        "\n",
        "    Inputs:\n",
        "    - d_upstream: Upstream derivative, of shape (N, D)\n",
        "    - cache: Tuple of:\n",
        "      - x: Input data, of shape (N, D)\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - dx: Gradient with respect to x, of shape (N, D)\n",
        "    \"\"\"\n",
        "    x,  = cache\n",
        "    dx = None\n",
        "\n",
        "    # PUT YOUR CODE BELOW: Implement the ReLU backward pass.\n",
        "    dx = np.zeros_like(x)\n",
        "    for i in range(x.shape[0]):\n",
        "      for j in range(x.shape[1]):\n",
        "        if x[i][j] > 0:\n",
        "          dx[i][j] = 1\n",
        "\n",
        "    # The lines below do not need to be changed.\n",
        "\n",
        "    return (dx, )"
      ],
      "metadata": {
        "id": "fTn6t0FaVBSs"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Two-layer Neural Network\n",
        "\n",
        "We will now implement the model for the two-layer NN.\n",
        "\n",
        "&#9658; Implement the definition of the two-layer neural network below.\n",
        "\n",
        "Similar to the `LinearClassifier` class, you should write the `__init__`, `forward`, `backward`, and `predict` methods. We will be using the cross-entropy loss for this network.\n",
        "\n",
        "Complete the following:\n",
        "- The `__init__()` method initializes the class. You must generate two random weight matrices. We will be using the bias trick, so the bias should concatenated to the weight matrix. They are initialized differently.\n",
        "\n",
        "- The `forward()` method generates the scores\n",
        "for given an input sample,\n",
        "by applying a combination of `linear_forward()` and `ReLU_forward()` with appropriate inputs.Make sure to store and return the cache for the intermediate steps.\n",
        "\n",
        "- The `backward()` method returns the gradients with respect to the inputs and weights, using a combination of `linear_backward()` and `ReLU_backward()`. Make sure the keys for the returned dictionary `weights_gradient` matches the keys in the `self.params` dictionary.\n",
        "\n",
        "- The `predict()` method returns the labels predicted from the scores returned using the `self.forward()` method."
      ],
      "metadata": {
        "id": "jYDMTehxYP75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TwoLayerNet(object):\n",
        "    \"\"\"\n",
        "    A two-layer fully-connected neural network with ReLU nonlinearity and\n",
        "    softmax loss that uses a modular layer design. We assume an input dimension\n",
        "    of D, a hidden dimension of H, and perform classification over C classes.\n",
        "\n",
        "    The architecure should be transform - relu - transform - softmax.\n",
        "\n",
        "    Note that this class does not implement gradient descent; instead, it\n",
        "    will interact with a separate Solver object that is responsible for running\n",
        "    optimization.\n",
        "\n",
        "    The learnable parameters of the model are stored in the dictionary\n",
        "    self.params that maps parameter names to numpy arrays.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 hidden_dim=100,\n",
        "                 num_classes=10,\n",
        "                 weight_scale=1e-3):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "\n",
        "        self.params = {}\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.input_dim = input_dim\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # PUT YOUR CODE BELOW: Initialize the weights of the two-layer net. Weights should be\n",
        "        # initialized from a Gaussian centered at 0.0 with standard deviation\n",
        "        # equal to weight_scale, and biases should be initialized to zero.\n",
        "        # All weights should be stored in the dictionary self.params, with first\n",
        "        # layer weights and using the keys 'W1' and second layer weights and using\n",
        "        # the keys 'W2'. Make sure to concatenate the weights and biases to make a\n",
        "        # a single matrix for the bias trick!\n",
        "        W1 = np.random.normal(0.0, weight_scale, (input_dim, hidden_dim))\n",
        "        b1 = np.zeros((1, hidden_dim))\n",
        "        self.params[\"W1\"] = np.concatenate([W1, b1], axis=0)\n",
        "\n",
        "        W2 = np.random.normal(0.0, weight_scale, (hidden_dim, num_classes))\n",
        "        b2 = np.zeros((1, num_classes))\n",
        "        self.params[\"W2\"] = np.concatenate([W2, b2], axis=0)\n",
        "\n",
        "\n",
        "        # The lines below do not need to be changed in this method.\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Implement the forward pass of the neural network and return the scores\n",
        "\n",
        "        Inputs:\n",
        "        - x: A numpy array containing input data, of shape (N, self.input_dim)\n",
        "\n",
        "\n",
        "        Returns a tuple of:\n",
        "        - out: output, of shape (N, D)\n",
        "        - Tuple of tuples:\n",
        "          - cache_lin_1: A tuple (x, w1)\n",
        "            - x: data, of shape (N, self.input_dim)\n",
        "            - w1: Weight of linear layer 1 of shape (self.input_dim+1, self.hidden_dim)\n",
        "          - cache_relu_1: A tuple (h, )\n",
        "            - h : data, of shape (N, self.hidden_dim)\n",
        "          - cache_lin_2:  A tuple (h, w2)\n",
        "            - h: data, of shape (N, self.hidden_dim)\n",
        "            - w2: weight of linear 2 of shape (self.hidden_dim+1, C)\n",
        "        \"\"\"\n",
        "        out = None\n",
        "        N, feature_dim = x.shape\n",
        "        cache_lin_1, cache_relu_1, cache_lin_2 = None, None, None\n",
        "\n",
        "        if (feature_dim != self.input_dim):\n",
        "            raise Exception(f\"The input feature dimension of {feature_dim} does \\\n",
        "                            not match the expected feature dimension of \\\n",
        "                            {self.input_dim} \")\n",
        "\n",
        "\n",
        "        # PUT YOUR CODE BELOW: Perform a forward pass of the two-layer net.\n",
        "        # The architecture is transform - relu - transform\n",
        "        # Make to store the appropriate cache in the appropriate variables\n",
        "        def stablesoftmax(x):\n",
        "          \"\"\"Compute the softmax of vector x in a numerically stable way.\"\"\"\n",
        "          shiftx = x - np.max(x)\n",
        "          exps = np.exp(shiftx)\n",
        "          return exps / np.sum(exps)\n",
        "\n",
        "        l1, l1_cache = linear_forward(x, self.params[\"W1\"])\n",
        "        relu_l1, relu_cache = ReLU_forward(l1)\n",
        "        cache_lin_1 = l1_cache\n",
        "        cache_relu_1 = relu_cache\n",
        "\n",
        "        l2, l2_cache = linear_forward(relu_l1, self.params[\"W2\"])\n",
        "        cache_lin_2 = l2_cache\n",
        "        out = stablesoftmax(l2)\n",
        "\n",
        "        # The lines below do not need to be changed in this method.\n",
        "\n",
        "        return out, (cache_lin_1, cache_relu_1, cache_lin_2)\n",
        "\n",
        "\n",
        "    def backward(self, dout, cache):\n",
        "        \"\"\"\n",
        "        Implement the backward pass of the neural network and return the\n",
        "        gradients w.r.t the input, and the weights\n",
        "\n",
        "        Inputs:\n",
        "        - dout: Upstream derivative, of shape (N, C)\n",
        "        - cache: Tuple of tuples:\n",
        "          - cache_lin_1: A tuple (x, w1)\n",
        "            - x: data, of shape (N, self.input_dim)\n",
        "            - w1: Weight of linear layer 1 of shape (self.input_dim+1, self.hidden_dim)\n",
        "          - cache_relu_1: A tuple (h, )\n",
        "            - h : data, of shape (N, self.hidden_dim)\n",
        "          - cache_lin_2:  A tuple (h, w2)\n",
        "            - h: data, of shape (N, self.hidden_dim)\n",
        "            - w2: weight of linear 2 of shape (self.hidden_dim+1, C)\n",
        "\n",
        "        Returns a tuple of:\n",
        "          - dx: A numpy array of the gradient with respect to x, of shape (N, D)\n",
        "          - weight_gradients: A dictionary of numpy arrays containing the\n",
        "              gradients with respect to the weights.\n",
        "        \"\"\"\n",
        "\n",
        "        weight_gradients = {}\n",
        "        dx = None\n",
        "\n",
        "        N, classes = dout.shape\n",
        "\n",
        "        cache_lin_1, cache_relu_1, cache_lin_2 = cache\n",
        "\n",
        "        if (classes != self.num_classes):\n",
        "            raise Exception(f\"The output class dimension of {classes} does \\\n",
        "                            not match the expected number of classes \\\n",
        "                            {self.num_classes} \")\n",
        "\n",
        "        # PUT YOUR CODE BELOW: Perform a backward pass of the two-layer net.\n",
        "        dx, dW2 = linear_backward(dout, cache_lin_2)\n",
        "        dx = ReLU_backward(dx, cache_relu_1)\n",
        "        dx, dW1 = linear_backward(dx[0], cache_lin_1)\n",
        "\n",
        "        weight_gradients[\"W1\"] = dW1\n",
        "        weight_gradients[\"W2\"] = dW2\n",
        "\n",
        "        # The lines below do not need to be changed in this method.\n",
        "        return (dx, weight_gradients)\n",
        "\n",
        "    def predict(self, x):\n",
        "\n",
        "        \"\"\"\n",
        "        Implement the predictions from the forward pass of the neural network and\n",
        "        returns it.\n",
        "\n",
        "        Inputs:\n",
        "        - x: Input data, of shape (N, self.input_dim)\n",
        "\n",
        "        Returns a tuple of:\n",
        "          - predictions: A numpy array of shape (N, ) of the predicted class per sample\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        y_pred = None\n",
        "\n",
        "\n",
        "        # PUT YOUR CODE BELOW: Predict the classes of using the two-layer net.\n",
        "        y_pred = np.zeros((x.shape[0],))\n",
        "\n",
        "        out, cache = self.forward(x)\n",
        "        for i in range(x.shape[0]):\n",
        "          y_pred[i] = np.argmax(out[i])\n",
        "\n",
        "        print(y_pred)\n",
        "\n",
        "        # The lines below do not need to be changed in this method.\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    def loss(self, scores, y_batch):\n",
        "        \"\"\"\n",
        "        Compute the loss using the cross_entropy_loss function and its\n",
        "        derivative: -1/np.sqrt(input_dim).\n",
        "        Inputs:\n",
        "        - scores: A numpy array of shape (N, C) containing a minibatch of N\n",
        "          data points; each point has dimension C, where C is the number of classes.\n",
        "        - y_batch: A numpy array of shape (N,) containing labels for the minibatch.\n",
        "\n",
        "        Returns: A tuple containing:\n",
        "        - loss as a single float\n",
        "        - gradient with respect to scores; an array of the same shape as W\n",
        "        \"\"\"\n",
        "        # The lines below do not need to be changed in this method.\n",
        "        return cross_entropy_loss(scores, y_batch)"
      ],
      "metadata": {
        "id": "dSr_3dSiYQOf"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Experiments\n",
        "\n",
        "Similar to the linear classifiers,\n",
        "you also want to identify the configuration of hyperparameters that perform the best for your dataset.\n",
        "E.g.,\n",
        "you can vary the learning rate for your solver.\n",
        "You should use the `Solver` class for these models as well.\n",
        "Use the `DATA` dictionary you defined previously as the data parameter.\n",
        "\n",
        "Additionaly, the neural network provides another hyperparameter to vary, the the number of neurons in the hidden layer.\n",
        "\n",
        "Adding a large of number of neurons may cause a large degradation in performance, the linear transformation scales as $O(N^3)$ with the number of neurons."
      ],
      "metadata": {
        "id": "yovrIeNablvV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement a hyperparameter validation loop in the next cell to train multiple models with different hyperparameters. Keep the top-5 best performing models on the validation set. You may change learning rate, and hidden dims. You may change the num_epochs, but be wary of timeouts."
      ],
      "metadata": {
        "id": "N8zQgNiK-I9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_models = 10\n",
        "model_accuracies = []\n",
        "models = []\n",
        "\n",
        "lr = 0.0001\n",
        "num_epochs = 100\n",
        "for i in range(num_models):\n",
        "  two_layer_model = TwoLayerNet(input_dim=784)\n",
        "  solver_obj = Solver(two_layer_model, DATA, learning_rate=lr, num_epochs=num_epochs)\n",
        "  solver_obj.train()\n",
        "\n",
        "  model_accuracies.append(solver_obj.validation_history[-1])\n",
        "  models.append(solver_obj)"
      ],
      "metadata": {
        "id": "qwZysCge-Js5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "b9080101-136e-4ad4-d6f6-c8189a895fac"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. ... 1. 1. 1.]\n",
            "The validation accuracy at iteration 16  is               11.331249999999999%\n",
            "[1. 1. 1. ... 1. 1. 1.]\n",
            "The validation accuracy at iteration 32  is               11.331249999999999%\n",
            "[1. 1. 1. ... 1. 1. 1.]\n",
            "The validation accuracy at iteration 48  is               11.331249999999999%\n",
            "[1. 1. 1. ... 1. 1. 1.]\n",
            "The validation accuracy at iteration 64  is               11.331249999999999%\n",
            "[1. 1. 1. ... 1. 1. 1.]\n",
            "The validation accuracy at iteration 80  is               11.331249999999999%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-4a7cc2a8954b>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mtwo_layer_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTwoLayerNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0msolver_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwo_layer_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0msolver_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mmodel_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-d63ec5fb498a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_in_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-d63ec5fb498a>\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, batch_id)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# Compute loss and gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# dL is the upstream derivative to backward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-54-4c1ee1e3647b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mrelu_l1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelu_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReLU_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mcache_lin_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml1_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mcache_relu_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-84f9e325cf23>\u001b[0m in \u001b[0;36mReLU_forward\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     26\u001b[0m           \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m           \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement the testing performance of your top-5 performing NN models on the test set and print the results. You can add additional cells below."
      ],
      "metadata": {
        "id": "zi1hTKxU-Kap"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QL6IbrNo-PTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement visualization for the `W1` weights of the *best* performing NN models. There are `hidden_dim` many of them per model. You should visualize a subset of the weights. You can select the columns at random.\n",
        "\n",
        "You can add additional cells below."
      ],
      "metadata": {
        "id": "qC8IL-RNdCOY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R-CGHrOtdCb9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}